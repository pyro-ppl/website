<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>&lt;no title&gt; &mdash; Pyro Tutorials 1.8.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/pyro.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="&lt;no title&gt;" href="cvae.html" />
    <link rel="prev" title="&lt;no title&gt;" href="vae.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html">
            <img src="_static/pyro_logo_wide.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                1.8.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Practical Pyro and PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="svi_horovod.html">Example: distributed training via Horovod</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deep Generative Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cevae.html">Example: Causal Effect VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_gamma.html">Example: Sparse Gamma Deep Exponential Family</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Discrete Latent Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="toy_mixture_model_discrete_enumeration.html">Example: Toy Mixture Model With Discrete Enumeration</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm.html">Example: Hidden Markov Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="capture_recapture.html">Example: Capture-Recapture Models (CJS Models)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mixed_hmm.html">Example: hierarchical mixed-effect hidden Markov models</a></li>
<li class="toctree-l1"><a class="reference internal" href="einsum.html">Example: Discrete Factor Graph Inference with Plated Einsum</a></li>
<li class="toctree-l1"><a class="reference internal" href="lda.html">Example: Amortized Latent Dirichlet Allocation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Customizing Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="neutra.html">Example: Neural MCMC with NeuTraReparam</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_regression.html">Example: Sparse Bayesian Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="autoname_examples.html">Example: reducing boilerplate with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.autoname</span></code></a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Time Series</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="forecast_simple.html">Multivariate Forecasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="timeseries.html">Example: Gaussian Process Time Series Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Gaussian Processes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dkl.html">Example: Deep Kernel Learning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Epidemiology</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="epi_sir.html">Example: Univariate epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="epi_regional.html">Example: Regional epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="sir_hmc.html">Example: Epidemiological inference via HMC</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Biological sequences</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mue_profile.html">Example: Constant + MuE (Profile HMM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mue_factor.html">Example: Probabilistic PCA + MuE (FactorMuE)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Inference Algorithms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="baseball.html">Example: analyzing baseball stats with MCMC</a></li>
<li class="toctree-l1"><a class="reference internal" href="mcmc.html">Example: Inference with Markov Chain Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="lkj.html">Example: MCMC with an LKJ prior over covariances</a></li>
<li class="toctree-l1"><a class="reference internal" href="smcfilter.html">Example: Sequential Monte Carlo Filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="inclined_plane.html">Example: importance sampling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Understanding Pyro's Internals</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="minipyro.html">Mini-Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm_funsor.html">Example: hidden Markov models with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">pyroapi</span></code></a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pyro Tutorials</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>&lt;no title&gt;</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/ss-vae.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<dl>
<dt>{</dt><dd><dl>
<dt>“cells”: [</dt><dd><dl>
<dt>{</dt><dd><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“# The Semi-Supervised VAEn”,
“n”,
“## Introductionn”,
“n”,
“Most of the models we’ve covered in the tutorials are unsupervised:n”,
“n”,
“- [Variational Autoencoder (VAE)](vae.ipynb)n”,
“- [DMM](dmm.ipynb)n”,
“- [Attend-Infer-Repeat](air.ipynb)n”,
“n”,
“We’ve also covered a simple supervised model:n”,
“n”,
“- [Bayesian Regression](bayesian_regression.ipynb)n”,
“n”,
“The semi-supervised setting represents an interesting intermediate case where some of the data is labeled and some is not. It is also of great practical importance, since we often have very little labeled data and much more unlabeled data. We’d clearly like to leverage labeled data to improve our models of the unlabeled data. n”,
“n”,
“The semi-supervised setting is also well suited to generative models, where missing data can be accounted for quite naturally&amp;mdash;at least conceptually.n”,
“As we will see, in restricting our attention to semi-supervised generative models, there will be no shortage of different model variants and possible inference strategies. n”,
“Although we’ll only be able to explore a few of these variants in detail, hopefully you will come away from the tutorial with a greater appreciation for the abstractions and modularity offered by probabilistic programming.n”,
“n”,
“So let’s go about building a generative model. We have a dataset n”,
“$\mathcal{D}$ with $N$ datapoints,n”,
“n”,
“$$ \mathcal{D} = \{ ({\bf x}_i, {\bf y}_i) \} $$n”,
“n”,
“where the $\{ {\bf x}_i \}$ are always observed and the labels $\{ {\bf y}_i \}$ are only observed for some subset of the data. Since we want  to be able to model complex variations in the data, we’re going to make this a latent variable model with a local latent variable ${\bf z}_i$ private to each pair $({\bf x}_i, {\bf y}_i)$. Even with this set of choices, a number of model variants are possible: we’re going to focus on the model variant depicted in Figure 1 (this is model M2 in reference [1]).”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “raw”,
“metadata”: {</p>
<blockquote>
<div><p>“raw_mimetype”: “text/html”</p>
</div></blockquote>
<p>},
“source”: [</p>
<blockquote>
<div><p>“&lt;center&gt;&lt;figure&gt;&lt;img src=&quot;_static/img/ss_vae_m2.png&quot; style=&quot;width: 180px;&quot;&gt;&lt;center&gt;&lt;figcaption&gt; &lt;font size=&quot;+1&quot;&gt;&lt;b&gt;Figure 1&lt;/b&gt;: our semi-supervised generative model &lt;/font&gt;(c.f. model M2 in reference [1])&lt;/figcaption&gt;&lt;/center&gt;&lt;/figure&gt;&lt;/center&gt;”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“For convenience&amp;mdash;and since we’re going to model MNIST in our experiments below&amp;mdash;let’s suppose the $\{ {\bf x}_i \}$ are images and the $\{ {\bf y}_i \}$ are digit labels. In this model setup, the latent random variable ${\bf z}_i$ and the (partially observed) digit label _jointly_ generate the observed image.n”,
“The ${\bf z}_i$ represents _everything <a href="#id9"><span class="problematic" id="id10">but_</span></a> the digit label, possibly handwriting style or position.n”,
“Let’s sidestep asking when we expect this particular factorization of $({\bf x}_i, {\bf y}_i, {\bf z}_i)$ to be appropriate, since the answer to that question will depend in large part on the dataset in question (among other things). Let’s instead highlight some of the ways that inference in this model will be challenging as well as some of the solutions that we’ll be exploring in the rest of the tutorial.n”,
“n”,
“## The Challenges of Inferencen”,
“n”,
“For concreteness we’re going to continue to assume that the partially-observed $\{ {\bf y}_i \}$ are discrete labels; we will also assume that the $\{ {\bf z}_i \}$ are continuous.n”,
“n”,
“- If we apply the general recipe for stochastic variational inference to our model (see [SVI Part I](svi_part_i.ipynb)) we would be sampling the discrete (and thus non-reparameterizable) variable ${\bf y}_i$ whenever it’s unobserved. As discussed in [SVI Part III](svi_part_iii.ipynb) this will generally lead to high-variance gradient estimates. n”,
“- A common way to ameliorate this problem&amp;mdash;and one that we’ll explore below&amp;mdash;is to forego sampling and instead sum out all ten values of the class label ${\bf y}_i$ when we calculate the ELBO for an unlabeled datapoint ${\bf x}_i$. This is more expensive per step, but can help us reduce the variance of our gradient estimator and thereby take fewer steps.n”,
“- Recall that the role of the guide is to ‘fill in’ _latent_ random variables. Concretely, one component of our guide will be a digit classifier $q_\phi({\bf y} | {\bf x})$ that will randomly ‘fill in’ labels $\{ {\bf y}_i \}$ given an image $\{ {\bf x}_i \}$. Crucially, this means that the only term in the ELBO that will depend on $q_\phi(\cdot | {\bf x})$ is the term that involves a sum over _unlabeled_ datapoints. This means that our classifier $q_\phi(\cdot | {\bf x})$&amp;mdash;which in many cases will be the primary object of interest&amp;mdash;will not be learning from the labeled datapoints (at least not directly).n”,
“- This seems like a potential problem. Luckily, various fixes are possible. Below we’ll follow the approach in reference [1], which involves introducing an additional objective function for the classifier to ensure that the classifier learns directly from the labeled data.n”,
“n”,
“We have our work cut out for us so let’s get started!”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## First Variant: Standard objective function, naive estimatorn”,
“n”,
“As discussed in the introduction, we’re considering the model depicted in Figure 1. In more detail, the model has the following structure:n”,
“n”,
“- $p({\bf y}) = Cat({\bf y}~|~{\bf \pi})$: multinomial (or categorical) prior for the class label n”,
“- $p({\bf z}) = \mathcal{N}({\bf z}~|~{\bf 0,I})$: unit normal prior for the latent code $\bf z$n”,
“- $p_{\theta}({\bf x}~|~{\bf z,y}) = Bernoulli\left({\bf x}~|~\mu\left({\bf z,y}\right)\right)$: parameterized Bernoulli likelihood function; $\mu\left({\bf z,y}\right)$ corresponds to <cite>decoder</cite> in the coden”,
“n”,
“We structure the components of our guide $q_{\phi}(.)$ as follows:n”,
“n”,
“- $q_{\phi}({\bf y}~|~{\bf x}) = Cat({\bf y}~|~{\bf \alpha}_{\phi}\left({\bf x}\right))$: parameterized multinomial (or categorical) distribution; ${\bf \alpha}_{\phi}\left({\bf x}\right)$ corresponds to <cite>encoder_y</cite> in the coden”,
“- $q_{\phi}({\bf z}~|~{\bf x, y}) = \mathcal{N}({\bf z}~|~{\bf \mu}_{\phi}\left({\bf x, y}\right), {\bf \sigma^2_{\phi}\left(x, y\right)})$: parameterized normal distribution; ${\bf \mu}_{\phi}\left({\bf x, y}\right)$ and ${\bf \sigma^2_{\phi}\left(x, y\right)}$ correspond to the neural digit classifier <cite>encoder_z</cite> in the code “</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“These choices reproduce the structure of model M2 and its corresponding inference network in reference [1].n”,
“n”,
“We translate this model and guide pair into Pyro code below. Note that:n”,
“n”,
“- The labels <cite>ys</cite>, which are represented with a one-hot encoding, are only partially observed (<cite>None</cite> denotes unobserved values).n”,
“n”,
“- <cite>model()</cite> handles both the observed and unobserved case.n”,
“n”,
“- The code assumes that <cite>xs</cite> and <cite>ys</cite> are mini-batches of images and labels, respectively, with the size of each batch denoted by <cite>batch_size</cite>. “</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: null,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“def model(self, xs, ys=None):n”,
”    # register this pytorch module and all of its sub-modules with pyron”,
”    pyro.module(&quot;ss_vae&quot;, self)n”,
”    batch_size = xs.size(0)n”,
“n”,
”    # inform Pyro that the variables in the batch of xs, ys are conditionally independentn”,
”    with pyro.plate(&quot;data&quot;):n”,
“n”,
”        # sample the handwriting style from the constant prior distributionn”,
”        prior_loc = xs.new_zeros([batch_size, self.z_dim])n”,
”        prior_scale = xs.new_ones([batch_size, self.z_dim])n”,
”        zs = pyro.sample(&quot;z&quot;, dist.Normal(prior_loc, prior_scale).to_event(1))n”,
“n”,
”        # if the label y (which digit to write) is supervised, sample from then”,
”        # constant prior, otherwise, observe the value (i.e. score it against the constant prior)n”,
”        alpha_prior = xs.new_ones([batch_size, self.output_size]) / (1.0 * self.output_size)n”,
”        ys = pyro.sample(&quot;y&quot;, dist.OneHotCategorical(alpha_prior), obs=ys)n”,
“n”,
”        # finally, score the image (x) using the handwriting style (z) andn”,
”        # the class label y (which digit to write) against then”,
”        # parametrized distribution p(x|y,z) = bernoulli(decoder(y,z))n”,
”        # where <cite>decoder</cite> is a neural networkn”,
”        loc = self.decoder([zs, ys])n”,
”        pyro.sample(&quot;x&quot;, dist.Bernoulli(loc).to_event(1), obs=xs)n”,
“n”,
“def guide(self, xs, ys=None):n”,
”    with pyro.plate(&quot;data&quot;):n”,
”        # if the class label (the digit) is not supervised, samplen”,
”        # (and score) the digit with the variational distributionn”,
”        # q(y|x) = categorical(alpha(x))n”,
”        if ys is None:n”,
”            alpha = self.encoder_y(xs)n”,
”            ys = pyro.sample(&quot;y&quot;, dist.OneHotCategorical(alpha))n”,
“n”,
”        # sample (and score) the latent handwriting-style with the variationaln”,
”        # distribution q(z|x,y) = normal(loc(x,y),scale(x,y))n”,
”        loc, scale = self.encoder_z([xs, ys])n”,
”        pyro.sample(&quot;z&quot;, dist.Normal(loc, scale).to_event(1))”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“### Network Definitionsn”,
“n”,
“In our experiments we use the same network configurations as used in reference [1]. The encoder and decoder networks have one hidden layer with $500$ hidden units and softplus activation functions. We use softmax as the activation function for the output of <cite>encoder_y</cite>, sigmoid as the output activation function for <cite>decoder</cite> and exponentiation for the scale part of the output of <cite>encoder_z</cite>. The latent dimension is 50.n”,
“n”,
“n”,
“### MNIST Pre-Processingn”,
“n”,
“We normalize the pixel values to the range $[0.0, 1.0]$. We use the [MNIST data loader](<a class="reference external" href="http://pytorch.org/docs/master/torchvision/datasets.html#torchvision.datasets.MNIST">http://pytorch.org/docs/master/torchvision/datasets.html#torchvision.datasets.MNIST</a>) from the <cite>torchvision</cite> library. The testing set consists of $10000$ examples. The default training set consists of $60000$ examples. We use the first $50000$ examples for training (divided into supervised and un-supervised parts) and the remaining $10000$ images for validation. For our experiments, we use $4$ configurations of supervision in the training set, i.e. we consider $3000$, $1000$, $600$ and $100$ supervised examples selected randomly (while ensuring that each class is balanced).”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“### The Objective Functionn”,
“n”,
“The objective function for this model has the two terms (c.f. Eqn. 8 in reference [1]):n”,
“n”,
“$$\mathcal{J} = \!\!\sum_{({\bf x,y}) \in \mathcal{D}_{supervised} } \!\!\!\!\!\!\!\!\mathcal{L}\big({\bf x,y}\big) +\!\!\! \sum_{{\bf x} \in \mathcal{D}_{unsupervised}} \!\!\!\!\!\!\!\mathcal{U}\left({\bf x}\right)n”,
“$$n”,
“n”,
“To implement this in Pyro, we setup a single instance of the <cite>SVI</cite> class. The two different terms in the objective functions will emerge automatically depending on whether we pass the <cite>step</cite> method labeled or unlabeled data. We will alternate taking steps with labeled and unlabeled mini-batches, with the number of steps taken for each type of mini-batch depending on the total fraction of data that is labeled. For example, if we have 1,000 labeled images and 49,000 unlabeled ones, then we’ll take 49 steps with unlabeled mini-batches for each labeled mini-batch. (Note that there are different ways we could do this, but for simplicity we only consider this variant.) The code for this setup is given below:”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: null,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“from pyro.infer import SVI, Trace_ELBO, TraceEnum_ELBO, config_enumeraten”,
“from pyro.optim import Adamn”,
“n”,
“# setup the optimizern”,
“adam_params = {&quot;lr&quot;: 0.0003}n”,
“optimizer = Adam(adam_params)n”,
“n”,
“# setup the inference algorithmn”,
“svi = SVI(model, guide, optimizer, loss=Trace_ELBO())”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“When we run this inference in Pyro, the performance seen during test time is degraded by the noise inherent in the sampling of the categorical variables (see Figure 2 and Table 1 at the end of this tutorial). To deal with this we’re going to need a better ELBO gradient estimator.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “raw”,
“metadata”: {</p>
<blockquote>
<div><p>“raw_mimetype”: “text/html”</p>
</div></blockquote>
<p>},
“source”: [</p>
<blockquote>
<div><p>“&lt;center&gt;&lt;figure&gt;n”,
”    &lt;table&gt;n”,
”        &lt;tr&gt;n”,
”            &lt;td style=&quot;width: 450px&quot;&gt; n”,
”                &lt;img src=&quot;_static/img/exp_1_losses_24_3000.png?2&quot;  style=&quot;width: 450px;&quot;&gt; n”,
”            &lt;/td&gt;n”,
”            &lt;td style=&quot;width: 450px&quot;&gt; n”,
”                &lt;img src=&quot;_static/img/exp_1_acc_24_3000.png?2&quot; style=&quot;width: 450px;&quot;&gt; n”,
”            &lt;/td&gt;n”,
”        &lt;/tr&gt;n”,
”    &lt;/table&gt; n”,
”    &lt;figcaption&gt; n”,
”        &lt;font size=&quot;+1&quot;&gt;&lt;b&gt;Figure 2:&lt;/b&gt; Variant 1&lt;/font&gt; &lt;b&gt;(Left)&lt;/b&gt; Training losses for the case with 3000 supervised examples.n”,
”        &lt;b&gt;(Right)&lt;/b&gt; Test and validation accuracies.n”,
”    &lt;/figcaption&gt;n”,
“&lt;/figure&gt;&lt;/center&gt;”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Interlude: Summing Out Discrete Latentsn”,
“n”,
“As highlighted in the introduction, when the discrete latent labels ${\bf y}$ are not observed, the ELBO gradient estimates rely on sampling from $q_\phi({\bf y}|{\bf x})$. These gradient estimates can be very high-variance, especially early in the learning process when the guessed labels are often incorrect. A common approach to reduce variance in this case is to sum out discrete latent variables, replacing the Monte Carlo expectation n”,
“n”,
“$$\mathbb E_{{\bf y}\sim <a href="#id11"><span class="problematic" id="id12">q_</span></a>\phi(\cdot|{\bf x})}\nabla\operatorname{ELBO}$$n”,
“n”,
“with an explicit sum n”,
“n”,
“$$\sum_{\bf y} <a href="#id13"><span class="problematic" id="id14">q_</span></a>\phi({\bf y}|{\bf x})\nabla\operatorname{ELBO}$$n”,
“n”,
“This sum is usually implemented by hand, as in [1], but Pyro can automate this in many cases. To automatically sum out all discrete latent variables (here only ${\bf y}$), we simply wrap the guide in <cite>config_enumerate()</cite>:n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;svi</span> <span class="pre">=</span> <span class="pre">SVI(model,</span> <span class="pre">config_enumerate(guide),</span> <span class="pre">optimizer,</span> <span class="pre">loss=TraceEnum_ELBO(max_plate_nesting=1))\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“In this mode of operation, each <cite>svi.step(…)</cite> computes a gradient term for each of the ten latent states of $y$. Although each step is thus $10\times$ more expensive, we’ll see that the lower-variance gradient estimate outweighs the additional cost.n”,
“n”,
“Going beyond the particular model in this tutorial, Pyro supports summing over arbitrarily many discrete latent variables. Beware that the cost of summing is exponential in the number of discrete variables, but is cheap(er) if multiple independent discrete variables are packed into a single tensor (as in this tutorial, where the discrete labels for the entire mini-batch are packed into the single tensor ${\bf y}$). To use this parallel form of <cite>config_enumerate()</cite>, we must inform Pyro that the items in a minibatch are indeed independent by wrapping our vectorized code in a <cite>with pyro.plate(&quot;name&quot;)</cite> block.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Second Variant: Standard Objective Function, Better Estimatorn”,
“n”,
“Now that we have the tools to sum out discrete latents, we can see if doing so helps our performance. First, as we can see from Figure 3, the test and validation accuracies now evolve much more smoothly over the course of training. More importantly, this single modification improved test accuracy from around <cite>20%</cite> to about <cite>90%</cite> for the case of $3000$ labeled examples. See Table 1 for the full results. This is great, but can we do better?”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “raw”,
“metadata”: {</p>
<blockquote>
<div><p>“raw_mimetype”: “text/html”</p>
</div></blockquote>
<p>},
“source”: [</p>
<blockquote>
<div><p>“&lt;center&gt;&lt;figure&gt;n”,
”    &lt;table&gt;n”,
”        &lt;tr&gt;n”,
”            &lt;td&gt; n”,
”                &lt;img src=&quot;_static/img/exp_2_losses_56_3000.png?2&quot;  style=&quot;width: 450px;&quot;&gt;n”,
”            &lt;/td&gt;n”,
”            &lt;td&gt; n”,
”                &lt;img src=&quot;_static/img/exp_2_acc_56_3000.png?2&quot; style=&quot;width: 450px;&quot;&gt;n”,
”            &lt;/td&gt;n”,
”        &lt;/tr&gt;n”,
”    &lt;/table&gt; n”,
”    &lt;figcaption&gt; n”,
”        &lt;font size=&quot;+1&quot;&gt;&lt;b&gt;Figure 3:&lt;/b&gt; Variant 2&lt;/font&gt; &lt;b&gt;(Left)&lt;/b&gt; Training losses for the case with 3000 supervised examples.n”,
”        &lt;b&gt;(Right)&lt;/b&gt; Test and validation accuracies.n”,
”    &lt;/figcaption&gt;n”,
“&lt;/figure&gt;&lt;/center&gt;”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Third Variant: Adding a Term to the Objectiven”,
“n”,
“For the two variants we’ve explored so far, the classifier $q_{\phi}({\bf y}~|~ {\bf x})$ doesn’t learn directly from labeled data. As we discussed in the introduction, this seems like a potential problem. One approach to addressing this problem is to add an extra term to the objective so that the classifier learns directly from labeled data. Note that this is exactly the approach adopted in reference [1] (see their Eqn. 9). The modified objective function is given by:n”,
“n”,
“\begin{align}n”,
“\mathcal{J}^{\alpha} &amp;= \mathcal{J} + \alpha \mathop{\mathbb{E}}_{\tilde{p_l}({\bf x,y})} \big[-\log\big(q_{\phi}({\bf y}~|~ {\bf x})\big)\big] \\n”,
“&amp;= \mathcal{J} + \alpha’ \sum_{({\bf x,y}) \in \mathcal{D}_{\text{supervised}}}  \big[-\log\big(q_{\phi}({\bf y}~|~ {\bf x})\big)\big]n”,
“\end{align}n”,
“n”,
“n”,
“where $\tilde{p_l}({\bf x,y})$ is the empirical distribution over the labeled (or supervised) data and $\alpha’ \equiv \frac{\alpha}{<a href="#id1"><span class="problematic" id="id2">|\\mathcal{D}_{\\text{supervised}}|</span></a>}$. Note that we’ve introduced an arbitrary hyperparameter $\alpha$ that modulates the importance of the new term.n”,
“n”,
“To learn using this modified objective in Pyro we do the following: n”,
“n”,
“- We use a new model and guide pair (see the code snippet below) that corresponds to scoring the observed label ${\bf y}$ for a given image ${\bf x}$ against the predictive distribution $q_{\phi}({\bf y}~|~ {\bf x})$ n”,
“n”,
“- We specify the scaling factor $\alpha’$ (<cite>aux_loss_multiplier</cite> in the code) in the <cite>pyro.sample</cite> call by making use of <cite>poutine.scale</cite>. Note that <cite>poutine.scale</cite> was used to similar effect in the [Deep Markov Model](dmm.ipynb) to implement KL annealing.n”,
“n”,
“- We create a new <cite>SVI</cite> object and use it to take gradient steps on the new objective term”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: null,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“def model_classify(self, xs, ys=None):n”,
”    pyro.module(&quot;ss_vae&quot;, self)n”,
”    with pyro.plate(&quot;data&quot;):n”,
”        # this here is the extra term to yield an auxiliary lossn”,
”        # that we do gradient descent onn”,
”        if ys is not None:n”,
”            alpha = self.encoder_y(xs)n”,
”            with pyro.poutine.scale(scale=self.aux_loss_multiplier):n”,
”                pyro.sample(&quot;y_aux&quot;, dist.OneHotCategorical(alpha), obs=ys)n”,
“n”,
“def guide_classify(xs, ys):n”,
”    # the guide is trivial, since there are no n”,
”    # latent random variablesn”,
”    passn”,
“n”,
“svi_aux = SVI(model_classify, guide_classify, optimizer, loss=Trace_ELBO())”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“When we run inference in Pyro with the additional term in the objective, we outperform both previous inference setups. For example, the test accuracy for the case with $3000$ labeled examples improves from <cite>90%</cite> to <cite>96%</cite> (see Figure 4 below and Table 1 in the next section). Note that we used validation accuracy to select the hyperparameter $\alpha’$. “</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “raw”,
“metadata”: {</p>
<blockquote>
<div><p>“raw_mimetype”: “text/html”</p>
</div></blockquote>
<p>},
“source”: [</p>
<blockquote>
<div><p>“&lt;center&gt;&lt;figure&gt;n”,
”    &lt;table&gt;n”,
”        &lt;tr&gt;n”,
”            &lt;td&gt; n”,
”                &lt;img src=&quot;_static/img/exp_3_losses_112_3000.png?2&quot;  style=&quot;width: 450px;&quot;&gt;n”,
”            &lt;/td&gt;n”,
”            &lt;td&gt; n”,
”                &lt;img src=&quot;_static/img/exp_3_acc_112_3000.png?2&quot; style=&quot;width: 450px;&quot;&gt;n”,
”            &lt;/td&gt;n”,
”        &lt;/tr&gt;n”,
”    &lt;/table&gt; n”,
”    &lt;figcaption&gt; n”,
”        &lt;font size=&quot;+1&quot;&gt;&lt;b&gt;Figure 4:&lt;/b&gt; Variant 3&lt;/font&gt; &lt;b&gt;(Left)&lt;/b&gt; Training losses for the case with 3000 supervised examples.n”,
”        &lt;b&gt;(Right)&lt;/b&gt; Test and validation accuracies.n”,
”    &lt;/figcaption&gt;n”,
“&lt;/figure&gt;&lt;/center&gt;”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Resultsn”,
“n”,
“| Supervised data  | First variant  | Second variant | Third variant  | Baseline classifier | n”,
“<a href="#id3"><span class="problematic" id="id4">|------------------|</span></a>—————-<a href="#id5"><span class="problematic" id="id6">|----------------|</span></a>—————-<a href="#id7"><span class="problematic" id="id8">|---------------------|</span></a> n”,
“| 100              | 0.2007(0.0353) | 0.2254(0.0346) | 0.9319(0.0060) | 0.7712(0.0159)      | n”,
“| 600              | 0.1791(0.0244) | 0.6939(0.0345) | 0.9437(0.0070) | 0.8716(0.0064)      | n”,
“| 1000             | 0.2006(0.0295) | 0.7562(0.0235) | 0.9487(0.0038) | 0.8863(0.0025)      | n”,
“| 3000             | 0.1982(0.0522) | 0.8932(0.0159) | 0.9582(0.0012) | 0.9108(0.0015)      | n”,
“n”,
“n”,
“n”,
“&lt;center&gt; &lt;b&gt;Table 1:&lt;/b&gt; Result accuracies (with 95% confidence bounds) for different inference methods&lt;/center&gt;n”,
“n”,
“Table 1 collects our results from the three variants explored in the tutorial. For comparison, we also show results from a simple classifier baseline, which only makes use of the supervised data (and no latent random variables). Reported are mean accuracies (with 95% confidence bounds in parentheses) across five random selections of supervised data.n”,
“n”,
“We first note that the results for the third variant&amp;mdash;where we summed out the discrete latent random variable $\bf y$ and made use of the additional term in the objective function&amp;mdash;reproduce the results reported in reference [1]. This is encouraging, since it means that the abstractions in Pyro proved flexible enough to accomodate the required modeling and inference setup. Significantly, this flexibility was evidently necessary to outperform the baseline. It’s also worth emphasizing that the gap between the baseline and third variant of our generative model setup increases as the number of labeled datapoints decreases (maxing out at about 15% for the case with only 100 labeled datapoints). This is a tantalizing result because it’s precisely in the regime where we have few labeled data points that semi-supervised learning is particularly attractive.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“### Latent Space Visualization”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “raw”,
“metadata”: {</p>
<blockquote>
<div><p>“raw_mimetype”: “text/html”</p>
</div></blockquote>
<p>},
“source”: [</p>
<blockquote>
<div><p>“&lt;center&gt;&lt;figure&gt;n”,
”    &lt;table&gt;n”,
”        &lt;tr&gt;n”,
”            &lt;td&gt; n”,
”                &lt;img src=&quot;_static/img/third_embedding.png?3&quot; style=&quot;width: 450px;&quot;&gt;n”,
”            &lt;/td&gt;n”,
”        &lt;/tr&gt;n”,
”    &lt;/table&gt; &lt;center&gt;n”,
”    &lt;figcaption&gt; n”,
”        &lt;font size=&quot;+1&quot;&gt;&lt;b&gt;Figure 5:&lt;/b&gt; Latent space embedding for variant 3 with 3000 supervised examples&lt;/font&gt; n”,
”    &lt;/figcaption&gt; &lt;/center&gt;n”,
“&lt;/figure&gt;&lt;/center&gt;”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“We use &lt;a href=&quot;<a class="reference external" href="https://lvdmaaten.github.io/tsne/">https://lvdmaaten.github.io/tsne/</a>&quot;&gt; T-SNE&lt;/a&gt; to reduce the dimensionality of the latent $\bf z$ from $50$ to $2$ and visualize the 10 digit classes in Figure 5. Note that the structure of the embedding is quite different than that in the [VAE](vae.ipynb) case, where the digits are clearly separated from one another in the embedding. This make sense, since for the semi-supervised case the latent $\bf z$ is free to use its representational capacity to model, e.g., handwriting style, since the variation between digits is provided by the (partially observed) labels.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“### Conditional image generation”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “raw”,
“metadata”: {</p>
<blockquote>
<div><p>“raw_mimetype”: “text/html”</p>
</div></blockquote>
<p>},
“source”: [</p>
<blockquote>
<div><p>“&lt;center&gt;&lt;figure&gt;n”,
”    &lt;table&gt;n”,
”        &lt;tr&gt;n”,
”            &lt;td&gt; n”,
”                &lt;img src=&quot;_static/img/conditional_samples/0.jpg&quot;  style=&quot;width: 200px;&quot;&gt;n”,
”            &lt;/td&gt;n”,
”            &lt;td&gt; n”,
”                &lt;img src=&quot;_static/img/conditional_samples/1.jpg&quot; style=&quot;width: 200px;&quot;&gt;n”,
”            &lt;/td&gt;n”,
”            &lt;td&gt; n”,
”                &lt;img src=&quot;_static/img/conditional_samples/2.jpg&quot;  style=&quot;width: 200px;&quot;&gt;n”,
”            &lt;/td&gt;n”,
”            &lt;td&gt; n”,
”                &lt;img src=&quot;_static/img/conditional_samples/3.jpg&quot; style=&quot;width: 200px;&quot;&gt;n”,
”            &lt;/td&gt;n”,
”            &lt;td&gt; n”,
”                &lt;img src=&quot;_static/img/conditional_samples/4.jpg&quot;  style=&quot;width: 200px;&quot;&gt;n”,
”            &lt;/td&gt;n”,
”        &lt;/tr&gt;n”,
”        &lt;tr&gt;n”,
”            &lt;td&gt; n”,
”                &lt;img src=&quot;_static/img/conditional_samples/5.jpg&quot;  style=&quot;width: 200px;&quot;&gt;n”,
”            &lt;/td&gt;n”,
”            &lt;td&gt; n”,
”                &lt;img src=&quot;_static/img/conditional_samples/6.jpg&quot; style=&quot;width: 200px;&quot;&gt;n”,
”            &lt;/td&gt;n”,
”            &lt;td&gt; n”,
”                &lt;img src=&quot;_static/img/conditional_samples/7.jpg&quot;  style=&quot;width: 200px;&quot;&gt;n”,
”            &lt;/td&gt;n”,
”            &lt;td&gt; n”,
”                &lt;img src=&quot;_static/img/conditional_samples/8.jpg&quot; style=&quot;width: 200px;&quot;&gt;n”,
”            &lt;/td&gt;n”,
”            &lt;td&gt; n”,
”                &lt;img src=&quot;_static/img/conditional_samples/9.jpg&quot;  style=&quot;width: 200px;&quot;&gt;n”,
”            &lt;/td&gt;n”,
”        &lt;/tr&gt;n”,
”    &lt;/table&gt; &lt;center&gt;n”,
”    &lt;figcaption&gt; n”,
”        &lt;font size=&quot;+1&quot;&gt;&lt;b&gt;Figure 6:&lt;/b&gt; Conditional samples obtained by fixing the class label and varying &lt;b&gt;z&lt;/b&gt; (for variant 3 with 3000 supervised examples)&lt;/font&gt; n”,
”    &lt;/figcaption&gt; &lt;/center&gt;n”,
“&lt;/figure&gt;&lt;/center&gt;”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“We sampled $100$ images for each class label ($0$ to $9$) by sampling different values of the latent variable ${\bf z}$. The diversity of handwriting styles exhibited by each digit is consistent with what we saw in the T-SNE visualization, suggesting that the representation learned by $\bf z$ is disentangled from the class labels.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Final thoughtsn”,
“n”,
“We’ve seen that generative models offer a natural approach to semi-supervised machine learning. One of the most attractive features of generative models is that we can explore a large variety of models in a single unified setting. In this tutorial we’ve only been able to explore a small fraction of the possible model and inference setups that are possible. There is no reason to expect that one variant is best; depending on the dataset and application, there will be reason to prefer one over another. And there are a lot of variants (see Figure 7)!”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “raw”,
“metadata”: {</p>
<blockquote>
<div><p>“raw_mimetype”: “text/html”</p>
</div></blockquote>
<p>},
“source”: [</p>
<blockquote>
<div><p>“&lt;center&gt;&lt;figure&gt;&lt;img src=&quot;_static/img/ss_vae_zoo.png&quot; style=&quot;width: 300px;&quot;&gt;&lt;figcaption&gt; &lt;center&gt;&lt;font size=&quot;+1&quot;&gt;&lt;b&gt;Figure 7&lt;/b&gt;: A zoo of semi-supervised generative models &lt;/font&gt; &lt;/center&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/center&gt;”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Some of these variants clearly make more sense than others, but a priori it’s difficult to know which ones are worth trying out. This is especially true once we open the door to more complicated setups, like the two models at the bottom of the figure, which include an always latent random variable $\tilde{\bf y}$ in addition to the partially observed label ${\bf y}$. (Incidentally, this class of models&amp;mdash;see reference [2] for similar variants&amp;mdash;offers another potential solution to the ‘no training’ problem that we identified above.)n”,
“n”,
“The reader probably doesn’t need any convincing that a systematic exploration of even a fraction of these options would be incredibly time-consuming and error-prone if each model and each inference procedure were coded up by scratch. It’s only with the modularity and abstraction made possible by a probabilistic programming system that we can hope to explore the landscape of generative models with any kind of nimbleness&amp;mdash;and reap any awaiting rewards.n”,
“n”,
“See the full code on [Github](<a class="reference external" href="https://github.com/pyro-ppl/pyro/blob/dev/examples/vae/ss_vae_M2.py).n">https://github.com/pyro-ppl/pyro/blob/dev/examples/vae/ss_vae_M2.py).n</a>”,
“n”,
“## Referencesn”,
“n”,
“[1] <cite>Semi-supervised Learning with Deep Generative Models</cite>,&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;n”,
“Diederik P. Kingma, Danilo J. Rezende, Shakir Mohamed, Max Wellingn”,
“n”,
“[2] <cite>Learning Disentangled Representations with Semi-Supervised Deep Generative Models</cite>,n”,
“&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;n”,
“N. Siddharth, Brooks Paige, Jan-Willem Van de Meent, Alban Desmaison, Frank Wood, &lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;n”,
“Noah D. Goodman, Pushmeet Kohli, Philip H.S. Torr”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>],
“metadata”: {</p>
<blockquote>
<div><p>“anaconda-cloud”: {},
“celltoolbar”: “Raw Cell Format”,
“kernelspec”: {</p>
<blockquote>
<div><p>“display_name”: “Python 3”,
“language”: “python”,
“name”: “python3”</p>
</div></blockquote>
<p>},
“language_info”: {</p>
<blockquote>
<div><dl class="simple">
<dt>“codemirror_mode”: {</dt><dd><p>“name”: “ipython”,
“version”: 3</p>
</dd>
</dl>
<p>},
“file_extension”: “.py”,
“mimetype”: “text/x-python”,
“name”: “python”,
“nbconvert_exporter”: “python”,
“pygments_lexer”: “ipython3”,
“version”: “3.7.10”</p>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p>},
“nbformat”: 4,
“nbformat_minor”: 2</p>
</dd>
</dl>
<p>}</p>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="vae.html" class="btn btn-neutral float-left" title="&lt;no title&gt;" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="cvae.html" class="btn btn-neutral float-right" title="&lt;no title&gt;" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Pyro Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>