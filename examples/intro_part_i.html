<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>&lt;no title&gt; &mdash; Pyro Tutorials 1.8.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/pyro.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="&lt;no title&gt;" href="intro_part_ii.html" />
    <link rel="prev" title="Example: hidden Markov models with pyro.contrib.funsor and pyroapi" href="hmm_funsor.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html">
            <img src="_static/pyro_logo_wide.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                1.8.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Practical Pyro and PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="svi_horovod.html">Example: distributed training via Horovod</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deep Generative Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cevae.html">Example: Causal Effect VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_gamma.html">Example: Sparse Gamma Deep Exponential Family</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Discrete Latent Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="toy_mixture_model_discrete_enumeration.html">Example: Toy Mixture Model With Discrete Enumeration</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm.html">Example: Hidden Markov Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="capture_recapture.html">Example: Capture-Recapture Models (CJS Models)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mixed_hmm.html">Example: hierarchical mixed-effect hidden Markov models</a></li>
<li class="toctree-l1"><a class="reference internal" href="einsum.html">Example: Discrete Factor Graph Inference with Plated Einsum</a></li>
<li class="toctree-l1"><a class="reference internal" href="lda.html">Example: Amortized Latent Dirichlet Allocation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Customizing Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="neutra.html">Example: Neural MCMC with NeuTraReparam</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_regression.html">Example: Sparse Bayesian Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="autoname_examples.html">Example: reducing boilerplate with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.autoname</span></code></a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Time Series</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="forecast_simple.html">Multivariate Forecasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="timeseries.html">Example: Gaussian Process Time Series Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Gaussian Processes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dkl.html">Example: Deep Kernel Learning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Epidemiology</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="epi_sir.html">Example: Univariate epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="epi_regional.html">Example: Regional epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="sir_hmc.html">Example: Epidemiological inference via HMC</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Biological sequences</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mue_profile.html">Example: Constant + MuE (Profile HMM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mue_factor.html">Example: Probabilistic PCA + MuE (FactorMuE)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Inference Algorithms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="baseball.html">Example: analyzing baseball stats with MCMC</a></li>
<li class="toctree-l1"><a class="reference internal" href="mcmc.html">Example: Inference with Markov Chain Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="lkj.html">Example: MCMC with an LKJ prior over covariances</a></li>
<li class="toctree-l1"><a class="reference internal" href="smcfilter.html">Example: Sequential Monte Carlo Filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="inclined_plane.html">Example: importance sampling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Understanding Pyro's Internals</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="minipyro.html">Mini-Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm_funsor.html">Example: hidden Markov models with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">pyroapi</span></code></a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pyro Tutorials</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>&lt;no title&gt;</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/intro_part_i.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<dl>
<dt>{</dt><dd><dl>
<dt>“cells”: [</dt><dd><dl>
<dt>{</dt><dd><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“# (DEPRECATED) An Introduction to Models in Pyron”,
“n”,
“## WARNINGn”,
“<strong>*This tutorial has been deprecated*</strong> in favor of the updated [Introduction to Pyro](<a class="reference external" href="https://pyro.ai/examples/intro_long.html">https://pyro.ai/examples/intro_long.html</a>). It may be removed in the future.***n”,
“n”,
“The basic unit of probabilistic programs is the _stochastic <a href="#id1"><span class="problematic" id="id2">function_</span></a>. n”,
“This is an arbitrary Python callable that combines two ingredients:n”,
“n”,
“- deterministic Python code; andn”,
“- primitive stochastic functions that call a random number generatorn”,
“n”,
“Concretely, a stochastic function can be any Python object with a <cite>__call__()</cite> method, like a function, a method, or a PyTorch <cite>nn.Module</cite>.n”,
“n”,
“Throughout the tutorials and documentation, we will often call stochastic functions <em>models</em>, since stochastic functions can be used to represent simplified or abstract descriptions of a process by which data are generated.  Expressing models as stochastic functions means that models can be composed, reused, imported, and serialized just like regular Python callables. “</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 1,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“import torchn”,
“import pyron”,
“n”,
“pyro.set_rng_seed(101)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Primitive Stochastic Functionsn”,
“n”,
“Primitive stochastic functions, or distributions, are an important class of stochastic functions for which we can explicitly compute the probability of the outputs given the inputs.  As of PyTorch 0.4 and Pyro 0.2, Pyro uses PyTorch’s [distribution library](<a class="reference external" href="http://pytorch.org/docs/master/distributions.html">http://pytorch.org/docs/master/distributions.html</a>). You can also create custom distributions using [transforms](<a class="reference external" href="http://pytorch.org/docs/master/distributions.html#module-torch.distributions.transforms).n">http://pytorch.org/docs/master/distributions.html#module-torch.distributions.transforms).n</a>”,
“n”,
“Using primitive stochastic functions is easy. For example, to draw a sample <cite>x</cite> from the unit normal distribution $\mathcal{N}(0,1)$ we do the following:”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 2,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“sample tensor(-1.3905)n”,
“log prob tensor(-1.8857)n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“loc = 0.   # mean zeron”,
“scale = 1. # unit variancen”,
“normal = torch.distributions.Normal(loc, scale) # create a normal distribution objectn”,
“x = normal.rsample() # draw a sample from N(0,1)n”,
“print(&quot;sample&quot;, x)n”,
“print(&quot;log prob&quot;, normal.log_prob(x)) # score the sample from N(0,1)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Here, <cite>torch.distributions.Normal</cite> is an instance of the <cite>Distribution</cite> class that takes parameters and provides sample and score methods. Pyro’s distribution library <cite>pyro.distributions</cite> is a thin wrapper around <cite>torch.distributions</cite> because we want to make use of PyTorch’s fast tensor math and autograd capabilities during inference.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## A Simple Modeln”,
“n”,
“All probabilistic programs are built up by composing primitive stochastic functions and deterministic computation. Since we’re ultimately interested in probabilistic programming because we want to model things in the real world, let’s start with a model of something concrete. n”,
“n”,
“Let’s suppose we have a bunch of data with daily mean temperatures and cloud cover. We want to reason about how temperature interacts with whether it was sunny or cloudy. A simple stochastic function that describes how that data might have been generated is given by:”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 3,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“def weather():n”,
”    cloudy = torch.distributions.Bernoulli(0.3).sample()n”,
”    cloudy = ‘cloudy’ if cloudy.item() == 1.0 else ‘sunny’n”,
”    mean_temp = {‘cloudy’: 55.0, ‘sunny’: 75.0}[cloudy]n”,
”    scale_temp = {‘cloudy’: 10.0, ‘sunny’: 15.0}[cloudy]n”,
”    temp = torch.distributions.Normal(mean_temp, scale_temp).rsample()n”,
”    return cloudy, temp.item()”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Let’s go through this line-by-line. First, in lines 2 we define a binary random variable ‘cloudy’, which is given by a draw from the Bernoulli distribution with a parameter of <cite>0.3</cite>. Since the Bernoulli distributions return <cite>0`s or `1`s, in line 3 we convert the value `cloudy</cite> to a string so that return values of <cite>weather</cite> are easier to parse. So according to this model 30% of the time it’s cloudy and 70% of the time it’s sunny.n”,
“n”,
“In lines 4-5 we define the parameters we’re going to use to sample the temperature in lines 6. These parameters depend on the particular value of <cite>cloudy</cite> we sampled in line 2. For example, the mean temperature is 55 degrees (Fahrenheit) on cloudy days and 75 degrees on sunny days. Finally we return the two values <cite>cloudy</cite> and <cite>temp</cite> in line 7.n”,
“n”,
“However, <cite>weather</cite> is entirely independent of Pyro - it only calls PyTorch. We need to turn it into a Pyro program if we want to use this model for anything other than sampling fake data.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## The <cite>pyro.sample</cite> Primitiven”,
“n”,
“To turn <cite>weather</cite> into a Pyro program, we’ll replace the <cite>torch.distribution`s with `pyro.distribution`s and the `.sample()</cite> and <cite>.rsample()</cite> calls with calls to <cite>pyro.sample</cite>, one of the core language primitives in Pyro. Using <cite>pyro.sample</cite> is as simple as calling a primitive stochastic function with one important difference:”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 4,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“tensor(-0.8152)n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“x = pyro.sample(&quot;my_sample&quot;, pyro.distributions.Normal(loc, scale))n”,
“print(x)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Just like a direct call to <cite>torch.distributions.Normal().rsample()</cite>, this returns a sample from the unit normal distribution. The crucial difference is that this sample is _named_. Pyro’s backend uses these names to uniquely identify sample statements and _change their behavior at <a href="#id3"><span class="problematic" id="id4">runtime_</span></a> depending on how the enclosing stochastic function is being used. As we will see, this is how Pyro can implement the various manipulations that underlie inference algorithms.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Now that we’ve introduced <cite>pyro.sample</cite> and <cite>pyro.distributions</cite> we can rewrite our simple model as a Pyro program:”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 5,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“(‘cloudy’, 64.5440444946289)n”,
“(‘sunny’, 94.37557983398438)n”,
“(‘sunny’, 72.5186767578125)n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“def weather():n”,
”    cloudy = pyro.sample(‘cloudy’, pyro.distributions.Bernoulli(0.3))n”,
”    cloudy = ‘cloudy’ if cloudy.item() == 1.0 else ‘sunny’n”,
”    mean_temp = {‘cloudy’: 55.0, ‘sunny’: 75.0}[cloudy]n”,
”    scale_temp = {‘cloudy’: 10.0, ‘sunny’: 15.0}[cloudy]n”,
”    temp = pyro.sample(‘temp’, pyro.distributions.Normal(mean_temp, scale_temp))n”,
”    return cloudy, temp.item()n”,
“n”,
“for _ in range(3):n”,
”    print(weather())”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Procedurally, <cite>weather()</cite> is still a non-deterministic Python callable that returns two random samples. Because the randomness is now invoked with <cite>pyro.sample</cite>, however, it is much more than that. In particular <cite>weather()</cite> specifies a joint probability distribution over two named random variables: <cite>cloudy</cite> and <cite>temp</cite>. As such, it defines a probabilistic model that we can reason about using the techniques of probability theory. For example we might ask: if I observe a temperature of 70 degrees, how likely is it to be cloudy? How to formulate and answer these kinds of questions will be the subject of the next tutorial.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Universality: Stochastic Recursion, Higher-order Stochastic Functions, and Random Control Flown”,
“n”,
“We’ve now seen how to define a simple model. Building off of it is easy. For example:”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 6,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“def ice_cream_sales():n”,
”    cloudy, temp = weather()n”,
”    expected_sales = 200. if cloudy == ‘sunny’ and temp &gt; 80.0 else 50.n”,
”    ice_cream = pyro.sample(‘ice_cream’, pyro.distributions.Normal(expected_sales, 10.0))n”,
”    return ice_cream”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“This kind of modularity, familiar to any programmer, is obviously very powerful. But is it powerful enough to encompass all the different kinds of models we’d like to express?n”,
“n”,
“It turns out that because Pyro is embedded in Python, stochastic functions can contain arbitrarily complex deterministic Python and randomness can freely affect control flow. For example, we can construct recursive functions that terminate their recursion nondeterministically, provided we take care to pass <cite>pyro.sample</cite> unique sample names whenever it’s called. For example we can define a geometric distribution that counts the number of failures until the first success like so:”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 7,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“0n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“def geometric(p, t=None):n”,
”    if t is None:n”,
”        t = 0n”,
”    x = pyro.sample(&quot;x_{}&quot;.format(t), pyro.distributions.Bernoulli(p))n”,
”    if x.item() == 1:n”,
”        return 0n”,
”    else:n”,
”        return 1 + geometric(p, t + 1)n”,
”    n”,
“print(geometric(0.5))”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Note that the names <cite>x_0</cite>, <cite>x_1</cite>, etc., in <cite>geometric()</cite> are generated dynamically and that different executions can have different numbers of named random variables. n”,
“n”,
“We are also free to define stochastic functions that accept as input or produce as output other stochastic functions:”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 8,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“tensor(2.1493)n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“def normal_product(loc, scale):n”,
”    z1 = pyro.sample(&quot;z1&quot;, pyro.distributions.Normal(loc, scale))n”,
”    z2 = pyro.sample(&quot;z2&quot;, pyro.distributions.Normal(loc, scale))n”,
”    y = z1 * z2n”,
”    return yn”,
“n”,
“def make_normal_normal():n”,
”    mu_latent = pyro.sample(&quot;mu_latent&quot;, pyro.distributions.Normal(0, 1))n”,
”    fn = lambda scale: normal_product(mu_latent, scale)n”,
”    return fnn”,
“n”,
“print(make_normal_normal()(1.))”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Here <cite>make_normal_normal()</cite> is a stochastic function that takes one argument and which, upon execution, generates three named random variables.n”,
“n”,
“The fact that Pyro supports arbitrary Python code like this&amp;mdash;iteration, recursion, higher-order functions, etc.&amp;mdash;in conjuction with random control flow means that Pyro stochastic functions are _universal_, i.e. they can be used to represent any computable probability distribution. As we will see in subsequent tutorials, this is incredibly powerful. n”,
“n”,
“It is worth emphasizing that this is one reason why Pyro is built on top of PyTorch: dynamic computational graphs are an important ingredient in allowing for universal models that can benefit from GPU-accelerated tensor math.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Next Stepsn”,
“n”,
“We’ve shown how we can use stochastic functions and primitive distributions to represent models in Pyro. In order to learn models from data and reason about them we need to be able to do inference. This is the subject of the [next tutorial](intro_part_ii.ipynb).”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>],
“metadata”: {</p>
<blockquote>
<div><dl class="simple">
<dt>“kernelspec”: {</dt><dd><p>“display_name”: “Python 3”,
“language”: “python”,
“name”: “python3”</p>
</dd>
</dl>
<p>},
“language_info”: {</p>
<blockquote>
<div><dl class="simple">
<dt>“codemirror_mode”: {</dt><dd><p>“name”: “ipython”,
“version”: 3</p>
</dd>
</dl>
<p>},
“file_extension”: “.py”,
“mimetype”: “text/x-python”,
“name”: “python”,
“nbconvert_exporter”: “python”,
“pygments_lexer”: “ipython3”,
“version”: “3.7.6”</p>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p>},
“nbformat”: 4,
“nbformat_minor”: 2</p>
</dd>
</dl>
<p>}</p>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="hmm_funsor.html" class="btn btn-neutral float-left" title="Example: hidden Markov models with pyro.contrib.funsor and pyroapi" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="intro_part_ii.html" class="btn btn-neutral float-right" title="&lt;no title&gt;" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Pyro Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>