<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>&lt;no title&gt; &mdash; Pyro Tutorials 1.8.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/pyro.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="&lt;no title&gt;" href="boosting_bbvi.html" />
    <link rel="prev" title="&lt;no title&gt;" href="easyguide.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html">
            <img src="_static/pyro_logo_wide.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                1.8.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Practical Pyro and PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="svi_horovod.html">Example: distributed training via Horovod</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deep Generative Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cevae.html">Example: Causal Effect VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_gamma.html">Example: Sparse Gamma Deep Exponential Family</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Discrete Latent Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="toy_mixture_model_discrete_enumeration.html">Example: Toy Mixture Model With Discrete Enumeration</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm.html">Example: Hidden Markov Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="capture_recapture.html">Example: Capture-Recapture Models (CJS Models)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mixed_hmm.html">Example: hierarchical mixed-effect hidden Markov models</a></li>
<li class="toctree-l1"><a class="reference internal" href="einsum.html">Example: Discrete Factor Graph Inference with Plated Einsum</a></li>
<li class="toctree-l1"><a class="reference internal" href="lda.html">Example: Amortized Latent Dirichlet Allocation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Customizing Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="neutra.html">Example: Neural MCMC with NeuTraReparam</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_regression.html">Example: Sparse Bayesian Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="autoname_examples.html">Example: reducing boilerplate with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.autoname</span></code></a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Time Series</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="forecast_simple.html">Multivariate Forecasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="timeseries.html">Example: Gaussian Process Time Series Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Gaussian Processes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dkl.html">Example: Deep Kernel Learning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Epidemiology</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="epi_sir.html">Example: Univariate epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="epi_regional.html">Example: Regional epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="sir_hmc.html">Example: Epidemiological inference via HMC</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Biological sequences</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mue_profile.html">Example: Constant + MuE (Profile HMM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mue_factor.html">Example: Probabilistic PCA + MuE (FactorMuE)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Inference Algorithms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="baseball.html">Example: analyzing baseball stats with MCMC</a></li>
<li class="toctree-l1"><a class="reference internal" href="mcmc.html">Example: Inference with Markov Chain Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="lkj.html">Example: MCMC with an LKJ prior over covariances</a></li>
<li class="toctree-l1"><a class="reference internal" href="smcfilter.html">Example: Sequential Monte Carlo Filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="inclined_plane.html">Example: importance sampling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Understanding Pyro's Internals</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="minipyro.html">Mini-Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm_funsor.html">Example: hidden Markov models with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">pyroapi</span></code></a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pyro Tutorials</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>&lt;no title&gt;</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/custom_objectives.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<dl>
<dt>{</dt><dd><dl>
<dt>“cells”: [</dt><dd><dl>
<dt>{</dt><dd><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“# Custom SVI Objectivesn”,
“n”,
“Pyro provides support for various optimization-based approaches to Bayesian inference, with <cite>Trace_ELBO</cite> serving as the basic implementation of SVI (stochastic variational inference).n”,
“See the [docs](<a class="reference external" href="http://docs.pyro.ai/en/dev/inference_algos.html#module-pyro.infer.svi">http://docs.pyro.ai/en/dev/inference_algos.html#module-pyro.infer.svi</a>) for more information on the various SVI implementations and SVI n”,
“tutorials [I](<a class="reference external" href="http://pyro.ai/examples/svi_part_i.html">http://pyro.ai/examples/svi_part_i.html</a>), n”,
“[II](<a class="reference external" href="http://pyro.ai/examples/svi_part_ii.html">http://pyro.ai/examples/svi_part_ii.html</a>), n”,
“and [III](<a class="reference external" href="http://pyro.ai/examples/svi_part_iii.html">http://pyro.ai/examples/svi_part_iii.html</a>) for background on SVI.n”,
“n”,
“In this tutorial we show how advanced users can modify and/or augment the variationaln”,
“objectives (alternatively: loss functions) provided by Pyro to support special use cases.”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“1. [Basic SVI Usage](#Basic-SVI-Usage)n”,
”    1. [A Lower Level Pattern](#A-Lower-Level-Pattern)n”,
“2. [Example: Custom Regularizer](#Example:-Custom-Regularizer)n”,
“3. [Example: Scaling the Loss](#Example:-Scaling-the-Loss)n”,
“4. [Example: Beta VAE](#Example:-Beta-VAE)n”,
“5. [Example: Mixing Optimizers](#Example:-Mixing-Optimizers)n”,
“6. [Example: Custom ELBO](#Example:-Custom-ELBO)n”,
“7. [Example: KL Annealing](#Example:-KL-Annealing)n”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Basic SVI Usagen”,
“n”,
“We first review the basic usage pattern of <cite>SVI</cite> objects in Pyro. We assume that the usern”,
“has defined a <cite>model</cite> and a <cite>guide</cite>.  The user then creates an optimizer and an <cite>SVI</cite> object:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;optimizer</span> <span class="pre">=</span> <span class="pre">pyro.optim.Adam({\&quot;lr\&quot;:</span> <span class="pre">0.001,</span> <span class="pre">\&quot;betas\&quot;:</span> <span class="pre">(0.90,</span> <span class="pre">0.999)})\n&quot;,</span>
<span class="pre">&quot;svi</span> <span class="pre">=</span> <span class="pre">pyro.infer.SVI(model,</span> <span class="pre">guide,</span> <span class="pre">optimizer,</span> <span class="pre">loss=pyro.infer.Trace_ELBO())\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“n”,
“Gradient steps can then be taken with a call to <cite>svi.step(…)</cite>. The arguments to <cite>step()</cite> are thenn”,
“passed to <cite>model</cite> and <cite>guide</cite>.n”,
“n”,
“n”,
“### A Lower-Level Patternn”,
“n”,
“The nice thing about the above pattern is that it allows Pyro to take care of various n”,
“details for us, for example:n”,
“n”,
“- <cite>pyro.optim.Adam</cite> dynamically creates a new <cite>torch.optim.Adam</cite> optimizer whenever a new parameter is encountered n”,
“- <cite>SVI.step()</cite> zeros gradients between gradient stepsn”,
“n”,
“If we want more control, we can directly manipulate the differentiable loss method of n”,
“the various <cite>ELBO</cite> classes. For example, (assuming we know all the parameters in advance) n”,
“this is equivalent to the previous code snippet:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;#</span> <span class="pre">define</span> <span class="pre">optimizer</span> <span class="pre">and</span> <span class="pre">loss</span> <span class="pre">function\n&quot;,</span>
<span class="pre">&quot;optimizer</span> <span class="pre">=</span> <span class="pre">torch.optim.Adam(my_parameters,</span> <span class="pre">{\&quot;lr\&quot;:</span> <span class="pre">0.001,</span> <span class="pre">\&quot;betas\&quot;:</span> <span class="pre">(0.90,</span> <span class="pre">0.999)})\n&quot;,</span>
<span class="pre">&quot;loss_fn</span> <span class="pre">=</span> <span class="pre">pyro.infer.Trace_ELBO().differentiable_loss\n&quot;,</span>
<span class="pre">&quot;#</span> <span class="pre">compute</span> <span class="pre">loss\n&quot;,</span>
<span class="pre">&quot;loss</span> <span class="pre">=</span> <span class="pre">loss_fn(model,</span> <span class="pre">guide,</span> <span class="pre">model_and_guide_args)\n&quot;,</span>
<span class="pre">&quot;loss.backward()\n&quot;,</span>
<span class="pre">&quot;#</span> <span class="pre">take</span> <span class="pre">a</span> <span class="pre">step</span> <span class="pre">and</span> <span class="pre">zero</span> <span class="pre">the</span> <span class="pre">parameter</span> <span class="pre">gradients\n&quot;,</span>
<span class="pre">&quot;optimizer.step()\n&quot;,</span>
<span class="pre">&quot;optimizer.zero_grad()\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“n”,
“## Example: Custom Regularizern”,
“n”,
“Suppose we want to add a custom regularization term to the SVI loss. Using the above n”,
“usage pattern, this is easy to do. First we define our regularizer:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;def</span> <span class="pre">my_custom_L2_regularizer(my_parameters):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">reg_loss</span> <span class="pre">=</span> <span class="pre">0.0\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">for</span> <span class="pre">param</span> <span class="pre">in</span> <span class="pre">my_parameters:\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">reg_loss</span> <span class="pre">=</span> <span class="pre">reg_loss</span> <span class="pre">+</span> <span class="pre">param.pow(2.0).sum()\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">return</span> <span class="pre">reg_loss</span>&#160; <span class="pre">\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“n”,
“Then the only change we need to make is:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`diff\n&quot;,</span>
<span class="pre">&quot;-</span> <span class="pre">loss</span> <span class="pre">=</span> <span class="pre">loss_fn(model,</span> <span class="pre">guide)\n&quot;,</span>
<span class="pre">&quot;+</span> <span class="pre">loss</span> <span class="pre">=</span> <span class="pre">loss_fn(model,</span> <span class="pre">guide)</span> <span class="pre">+</span> <span class="pre">my_custom_L2_regularizer(my_parameters)\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“n”,
“## Example: Clipping Gradientsn”,
“n”,
“For some models the loss gradient can explode during training, leading to overflow and n”,
“<cite>NaN</cite> values. One way to protect against this is with gradient clipping. The optimizersn”,
“in <cite>pyro.optim</cite> take an optional dictionary of <cite>clip_args</cite> which allows clipping eithern”,
“the gradient norm or the gradient value to fall within the given limit.n”,
“n”,
“To change the basic example above:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`diff\n&quot;,</span>
<span class="pre">&quot;-</span> <span class="pre">optimizer</span> <span class="pre">=</span> <span class="pre">pyro.optim.Adam({\&quot;lr\&quot;:</span> <span class="pre">0.001,</span> <span class="pre">\&quot;betas\&quot;:</span> <span class="pre">(0.90,</span> <span class="pre">0.999)})\n&quot;,</span>
<span class="pre">&quot;+</span> <span class="pre">optimizer</span> <span class="pre">=</span> <span class="pre">pyro.optim.Adam({\&quot;lr\&quot;:</span> <span class="pre">0.001,</span> <span class="pre">\&quot;betas\&quot;:</span> <span class="pre">(0.90,</span> <span class="pre">0.999)},</span> <span class="pre">{\&quot;clip_norm\&quot;:</span> <span class="pre">10.0})\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“n”,
“n”,
“## Example: Scaling the Lossn”,
“n”,
“Depending on the optimization algorithm, the scale of the loss may or not matter. Suppose n”,
“we want to scale our loss function by the number of datapoints before we differentiate it.n”,
“This is easily done:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`diff\n&quot;,</span>
<span class="pre">&quot;-</span> <span class="pre">loss</span> <span class="pre">=</span> <span class="pre">loss_fn(model,</span> <span class="pre">guide)\n&quot;,</span>
<span class="pre">&quot;+</span> <span class="pre">loss</span> <span class="pre">=</span> <span class="pre">loss_fn(model,</span> <span class="pre">guide)</span> <span class="pre">/</span> <span class="pre">N_data\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“n”,
“Note that in the case of SVI, where each term in the loss function is a log probability n”,
“from the model or guide, this same effect can be achieved using [poutine.scale](<a class="reference external" href="http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.scale">http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.scale</a>). For n”,
“example we can use the <cite>poutine.scale</cite> decorator to scale both the model and guide:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;&#64;poutine.scale(scale=1.0/N_data)\n&quot;,</span>
<span class="pre">&quot;def</span> <span class="pre">model(...):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">pass\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160; <span class="pre">\n&quot;,</span>
<span class="pre">&quot;&#64;poutine.scale(scale=1.0/N_data)\n&quot;,</span>
<span class="pre">&quot;def</span> <span class="pre">guide(...):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">pass\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“n”,
“## Example: Beta VAEn”,
“n”,
“We can also use [poutine.scale](<a class="reference external" href="http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.scale)n">http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.scale)n</a>”,
“to construct non-standard ELBO variational objectives in which, for example, the KL divergence is scaled differently relative to the expected log likelihood. In particular for the Beta VAE the KL divergence is scaled by a factor <cite>beta</cite>:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;def</span> <span class="pre">model(data,</span> <span class="pre">beta=0.5):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">z_loc,</span> <span class="pre">z_scale</span> <span class="pre">=</span> <span class="pre">...\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">with</span> <span class="pre">pyro.poutine.scale(scale=beta)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">z</span> <span class="pre">=</span> <span class="pre">pyro.sample(\&quot;z\&quot;,</span> <span class="pre">dist.Normal(z_loc,</span> <span class="pre">z_scale))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">pyro.sample(\&quot;obs\&quot;,</span> <span class="pre">dist.Bernoulli(...),</span> <span class="pre">obs=data)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160; <span class="pre">\n&quot;,</span>
<span class="pre">&quot;def</span> <span class="pre">guide(data,</span> <span class="pre">beta=0.5):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">with</span> <span class="pre">pyro.poutine.scale(scale=beta)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">z_loc,</span> <span class="pre">z_scale</span> <span class="pre">=</span> <span class="pre">...\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">z</span> <span class="pre">=</span> <span class="pre">pyro.sample(\&quot;z\&quot;,</span> <span class="pre">dist.Normal(z_loc,</span> <span class="pre">z_scale))\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“n”,
“With this choice of model and guide the log densities corresponding to the latent variable <cite>z</cite> that enter into constructing the variational objective vian”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`\n&quot;,</span>
<span class="pre">&quot;svi</span> <span class="pre">=</span> <span class="pre">pyro.infer.SVI(model,</span> <span class="pre">guide,</span> <span class="pre">optimizer,</span> <span class="pre">loss=pyro.infer.Trace_ELBO())\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“n”,
“will be scaled by a factor of <cite>beta</cite>, resulting in a KL divergence that is likewise scaled by <cite>beta</cite>.n”,
“n”,
“n”,
“## Example: Mixing Optimizersn”,
“n”,
“The various optimizers in <cite>pyro.optim</cite> allow the user to specify optimization settings (e.g. learning rates) onn”,
“a per-parameter basis. But what if we want to use different optimization algorithms for different parameters? n”,
“We can do this using Pyro’s <cite>MultiOptimizer</cite> (see below), but we can also achieve the same thing if we directly manipulate <cite>differentiable_loss</cite>:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;adam</span> <span class="pre">=</span> <span class="pre">torch.optim.Adam(adam_parameters,</span> <span class="pre">{\&quot;lr\&quot;:</span> <span class="pre">0.001,</span> <span class="pre">\&quot;betas\&quot;:</span> <span class="pre">(0.90,</span> <span class="pre">0.999)})\n&quot;,</span>
<span class="pre">&quot;sgd</span> <span class="pre">=</span> <span class="pre">torch.optim.SGD(sgd_parameters,</span> <span class="pre">{\&quot;lr\&quot;:</span> <span class="pre">0.0001})\n&quot;,</span>
<span class="pre">&quot;loss_fn</span> <span class="pre">=</span> <span class="pre">pyro.infer.Trace_ELBO().differentiable_loss\n&quot;,</span>
<span class="pre">&quot;#</span> <span class="pre">compute</span> <span class="pre">loss\n&quot;,</span>
<span class="pre">&quot;loss</span> <span class="pre">=</span> <span class="pre">loss_fn(model,</span> <span class="pre">guide)\n&quot;,</span>
<span class="pre">&quot;loss.backward()\n&quot;,</span>
<span class="pre">&quot;#</span> <span class="pre">take</span> <span class="pre">a</span> <span class="pre">step</span> <span class="pre">and</span> <span class="pre">zero</span> <span class="pre">the</span> <span class="pre">parameter</span> <span class="pre">gradients\n&quot;,</span>
<span class="pre">&quot;adam.step()\n&quot;,</span>
<span class="pre">&quot;sgd.step()\n&quot;,</span>
<span class="pre">&quot;adam.zero_grad()\n&quot;,</span>
<span class="pre">&quot;sgd.zero_grad()\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“n”,
“For completeness, we also show how we can do the same thing using [MultiOptimizer](<a class="reference external" href="http://docs.pyro.ai/en/dev/optimization.html?highlight=multi%20optimizer#module-pyro.optim.multi">http://docs.pyro.ai/en/dev/optimization.html?highlight=multi%20optimizer#module-pyro.optim.multi</a>), which allowsn”,
“us to combine multiple Pyro optimizers. Note that since <cite>MultiOptimizer</cite> uses <cite>torch.autograd.grad</cite> under the hood (instead of <cite>torch.Tensor.backward()</cite>), it has a slightly different interface; in particular the <cite>step()</cite> method also takes parameters as inputs.n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;def</span> <span class="pre">model():\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">pyro.param('a',</span> <span class="pre">...)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">pyro.param('b',</span> <span class="pre">...)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">...\n&quot;,</span>
<span class="pre">&quot;</span>&#160; <span class="pre">\n&quot;,</span>
<span class="pre">&quot;adam</span> <span class="pre">=</span> <span class="pre">pyro.optim.Adam({'lr':</span> <span class="pre">0.1})\n&quot;,</span>
<span class="pre">&quot;sgd</span> <span class="pre">=</span> <span class="pre">pyro.optim.SGD({'lr':</span> <span class="pre">0.01})\n&quot;,</span>
<span class="pre">&quot;optim</span> <span class="pre">=</span> <span class="pre">MixedMultiOptimizer([(['a'],</span> <span class="pre">adam),</span> <span class="pre">(['b'],</span> <span class="pre">sgd)])\n&quot;,</span>
<span class="pre">&quot;with</span> <span class="pre">pyro.poutine.trace(param_only=True)</span> <span class="pre">as</span> <span class="pre">param_capture:\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">loss</span> <span class="pre">=</span> <span class="pre">elbo.differentiable_loss(model,</span> <span class="pre">guide)\n&quot;,</span>
<span class="pre">&quot;params</span> <span class="pre">=</span> <span class="pre">{'a':</span> <span class="pre">pyro.param('a'),</span> <span class="pre">'b':</span> <span class="pre">pyro.param('b')}\n&quot;,</span>
<span class="pre">&quot;optim.step(loss,</span> <span class="pre">params)\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“n”,
“## Example: Custom ELBOn”,
“n”,
“In the previous three examples we bypassed creating a <cite>SVI</cite> object and directly manipulated n”,
“the differentiable loss function provided by an <cite>ELBO</cite> implementation. Another thing we n”,
“can do is create custom <cite>ELBO</cite> implementations and pass those into the <cite>SVI</cite> machinery. n”,
“For example, a simplified version of a <cite>Trace_ELBO</cite> loss function might look as follows:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;#</span> <span class="pre">note</span> <span class="pre">that</span> <span class="pre">simple_elbo</span> <span class="pre">takes</span> <span class="pre">a</span> <span class="pre">model,</span> <span class="pre">a</span> <span class="pre">guide,</span> <span class="pre">and</span> <span class="pre">their</span> <span class="pre">respective</span> <span class="pre">arguments</span> <span class="pre">as</span> <span class="pre">inputs\n&quot;,</span>
<span class="pre">&quot;def</span> <span class="pre">simple_elbo(model,</span> <span class="pre">guide,</span> <span class="pre">*args,</span> <span class="pre">**kwargs):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">run</span> <span class="pre">the</span> <span class="pre">guide</span> <span class="pre">and</span> <span class="pre">trace</span> <span class="pre">its</span> <span class="pre">execution\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">guide_trace</span> <span class="pre">=</span> <span class="pre">poutine.trace(guide).get_trace(*args,</span> <span class="pre">**kwargs)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">run</span> <span class="pre">the</span> <span class="pre">model</span> <span class="pre">and</span> <span class="pre">replay</span> <span class="pre">it</span> <span class="pre">against</span> <span class="pre">the</span> <span class="pre">samples</span> <span class="pre">from</span> <span class="pre">the</span> <span class="pre">guide\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">model_trace</span> <span class="pre">=</span> <span class="pre">poutine.trace(\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">poutine.replay(model,</span> <span class="pre">trace=guide_trace)).get_trace(*args,</span> <span class="pre">**kwargs)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">construct</span> <span class="pre">the</span> <span class="pre">elbo</span> <span class="pre">loss</span> <span class="pre">function\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">return</span> <span class="pre">-1*(model_trace.log_prob_sum()</span> <span class="pre">-</span> <span class="pre">guide_trace.log_prob_sum())\n&quot;,</span>
<span class="pre">&quot;\n&quot;,</span>
<span class="pre">&quot;svi</span> <span class="pre">=</span> <span class="pre">SVI(model,</span> <span class="pre">guide,</span> <span class="pre">optim,</span> <span class="pre">loss=simple_elbo)\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“Note that this is basically what the <cite>elbo</cite> implementation in [&quot;mini-pyro&quot;](<a class="reference external" href="https://github.com/pyro-ppl/pyro/blob/dev/pyro/contrib/minipyro.py">https://github.com/pyro-ppl/pyro/blob/dev/pyro/contrib/minipyro.py</a>) looks like.n”,
“n”,
“### Example: KL Annealingn”,
“n”,
“In the [Deep Markov Model Tutorial](<a class="reference external" href="http://pyro.ai/examples/dmm.html">http://pyro.ai/examples/dmm.html</a>) the ELBO variational objectiven”,
“is modified during training. In particular the various KL-divergence terms between latent randomn”,
“variables are scaled downward (i.e. annealed) relative to the log probabilities of the observed data.n”,
“In the tutorial this is accomplished using <cite>poutine.scale</cite>. We can accomplish the same thing by defining n”,
“a custom loss function. This latter option is not a very elegant pattern but we include it anyway to n”,
“show the flexibility we have at our disposal. n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;def</span> <span class="pre">simple_elbo_kl_annealing(model,</span> <span class="pre">guide,</span> <span class="pre">*args,</span> <span class="pre">**kwargs):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">get</span> <span class="pre">the</span> <span class="pre">annealing</span> <span class="pre">factor</span> <span class="pre">and</span> <span class="pre">latents</span> <span class="pre">to</span> <span class="pre">anneal</span> <span class="pre">from</span> <span class="pre">the</span> <span class="pre">keyword\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">arguments</span> <span class="pre">passed</span> <span class="pre">to</span> <span class="pre">the</span> <span class="pre">model</span> <span class="pre">and</span> <span class="pre">guide\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">annealing_factor</span> <span class="pre">=</span> <span class="pre">kwargs.pop('annealing_factor',</span> <span class="pre">1.0)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">latents_to_anneal</span> <span class="pre">=</span> <span class="pre">kwargs.pop('latents_to_anneal',</span> <span class="pre">[])\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">run</span> <span class="pre">the</span> <span class="pre">guide</span> <span class="pre">and</span> <span class="pre">replay</span> <span class="pre">the</span> <span class="pre">model</span> <span class="pre">against</span> <span class="pre">the</span> <span class="pre">guide\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">guide_trace</span> <span class="pre">=</span> <span class="pre">poutine.trace(guide).get_trace(*args,</span> <span class="pre">**kwargs)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">model_trace</span> <span class="pre">=</span> <span class="pre">poutine.trace(\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">poutine.replay(model,</span> <span class="pre">trace=guide_trace)).get_trace(*args,</span> <span class="pre">**kwargs)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">elbo</span> <span class="pre">=</span> <span class="pre">0.0\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">loop</span> <span class="pre">through</span> <span class="pre">all</span> <span class="pre">the</span> <span class="pre">sample</span> <span class="pre">sites</span> <span class="pre">in</span> <span class="pre">the</span> <span class="pre">model</span> <span class="pre">and</span> <span class="pre">guide</span> <span class="pre">trace</span> <span class="pre">and\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">construct</span> <span class="pre">the</span> <span class="pre">loss;</span> <span class="pre">note</span> <span class="pre">that</span> <span class="pre">we</span> <span class="pre">scale</span> <span class="pre">all</span> <span class="pre">the</span> <span class="pre">log</span> <span class="pre">probabilities</span> <span class="pre">of\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">samples</span> <span class="pre">sites</span> <span class="pre">in</span> <span class="pre">`latents_to_anneal`</span> <span class="pre">by</span> <span class="pre">the</span> <span class="pre">factor</span> <span class="pre">`annealing_factor`\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">for</span> <span class="pre">site</span> <span class="pre">in</span> <span class="pre">model_trace.values():\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">if</span> <span class="pre">site[\&quot;type\&quot;]</span> <span class="pre">==</span> <span class="pre">\&quot;sample\&quot;:\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">factor</span> <span class="pre">=</span> <span class="pre">annealing_factor</span> <span class="pre">if</span> <span class="pre">site[\&quot;name\&quot;]</span> <span class="pre">in</span> <span class="pre">latents_to_anneal</span> <span class="pre">else</span> <span class="pre">1.0\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">elbo</span> <span class="pre">=</span> <span class="pre">elbo</span> <span class="pre">+</span> <span class="pre">factor</span> <span class="pre">*</span> <span class="pre">site[\&quot;fn\&quot;].log_prob(site[\&quot;value\&quot;]).sum()\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">for</span> <span class="pre">site</span> <span class="pre">in</span> <span class="pre">guide_trace.values():\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">if</span> <span class="pre">site[\&quot;type\&quot;]</span> <span class="pre">==</span> <span class="pre">\&quot;sample\&quot;:\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">factor</span> <span class="pre">=</span> <span class="pre">annealing_factor</span> <span class="pre">if</span> <span class="pre">site[\&quot;name\&quot;]</span> <span class="pre">in</span> <span class="pre">latents_to_anneal</span> <span class="pre">else</span> <span class="pre">1.0</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">elbo</span> <span class="pre">=</span> <span class="pre">elbo</span> <span class="pre">-</span> <span class="pre">factor</span> <span class="pre">*</span> <span class="pre">site[\&quot;fn\&quot;].log_prob(site[\&quot;value\&quot;]).sum()\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">return</span> <span class="pre">-elbo\n&quot;,</span>
<span class="pre">&quot;\n&quot;,</span>
<span class="pre">&quot;svi</span> <span class="pre">=</span> <span class="pre">SVI(model,</span> <span class="pre">guide,</span> <span class="pre">optim,</span> <span class="pre">loss=simple_elbo_kl_annealing)\n&quot;,</span>
<span class="pre">&quot;svi.step(other_args,</span> <span class="pre">annealing_factor=0.2,</span> <span class="pre">latents_to_anneal=[\&quot;my_latent\&quot;])\n&quot;,</span>
<span class="pre">&quot;`</span></code>”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>],
“metadata”: {</p>
<blockquote>
<div><dl class="simple">
<dt>“kernelspec”: {</dt><dd><p>“display_name”: “Python 3”,
“language”: “python”,
“name”: “python3”</p>
</dd>
</dl>
<p>},
“language_info”: {</p>
<blockquote>
<div><dl class="simple">
<dt>“codemirror_mode”: {</dt><dd><p>“name”: “ipython”,
“version”: 3</p>
</dd>
</dl>
<p>},
“file_extension”: “.py”,
“mimetype”: “text/x-python”,
“name”: “python”,
“nbconvert_exporter”: “python”,
“pygments_lexer”: “ipython3”,
“version”: “3.8.2”</p>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p>},
“nbformat”: 4,
“nbformat_minor”: 2</p>
</dd>
</dl>
<p>}</p>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="easyguide.html" class="btn btn-neutral float-left" title="&lt;no title&gt;" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="boosting_bbvi.html" class="btn btn-neutral float-right" title="&lt;no title&gt;" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Pyro Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>