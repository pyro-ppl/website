<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Boosting Black Box Variational Inference &mdash; Pyro Tutorials 1.8.4 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/pyro.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Example: Neural MCMC with NeuTraReparam" href="neutra.html" />
    <link rel="prev" title="Customizing SVI objectives and training loops" href="custom_objectives.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html">
            <img src="_static/pyro_logo_wide.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                1.8.4
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Introductory Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro_long.html">Introduction to Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_rendering.html">Automatic rendering of Pyro models</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_i.html">SVI Part I: An Introduction to Stochastic Variational Inference in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_ii.html">SVI Part II: Conditional Independence, Subsampling, and Amortization</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_iii.html">SVI Part III: ELBO Gradient Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_iv.html">SVI Part IV: Tips and Tricks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Practical Pyro and PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="bayesian_regression.html">Bayesian Regression - Introduction (Part 1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayesian_regression_ii.html">Bayesian Regression - Inference Algorithms (Part 2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_shapes.html">Tensor shapes in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">Modules in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="workflow.html">High-dimensional Bayesian workflow, with applications to SARS-CoV-2 strains</a></li>
<li class="toctree-l1"><a class="reference internal" href="prior_predictive.html">Interactive posterior predictives checks</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">Using the PyTorch JIT Compiler with Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_horovod.html">Example: distributed training via Horovod</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deep Generative Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="vae.html">Variational Autoencoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="ss-vae.html">The Semi-Supervised VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="cvae.html">Conditional Variational Auto-encoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="normalizing_flows_i.html">Normalizing Flows - Introduction (Part 1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dmm.html">Deep Markov Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="air.html">Attend Infer Repeat</a></li>
<li class="toctree-l1"><a class="reference internal" href="cevae.html">Example: Causal Effect VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_gamma.html">Example: Sparse Gamma Deep Exponential Family</a></li>
<li class="toctree-l1"><a class="reference internal" href="prodlda.html">Probabilistic Topic Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="scanvi.html"><em>scANVI: Deep Generative Modeling for Single Cell Data with Pyro</em></a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Discrete Latent Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enumeration.html">Inference with Discrete Latent Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="gmm.html">Gaussian Mixture Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="dirichlet_process_mixture.html">Dirichlet Process Mixture Models in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="toy_mixture_model_discrete_enumeration.html">Example: Toy Mixture Model With Discrete Enumeration</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm.html">Example: Hidden Markov Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="capture_recapture.html">Example: Capture-Recapture Models (CJS Models)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mixed_hmm.html">Example: hierarchical mixed-effect hidden Markov models</a></li>
<li class="toctree-l1"><a class="reference internal" href="einsum.html">Example: Discrete Factor Graph Inference with Plated Einsum</a></li>
<li class="toctree-l1"><a class="reference internal" href="lda.html">Example: Amortized Latent Dirichlet Allocation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Customizing Inference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="mle_map.html">MLE and MAP Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="mle_map.html#Doing-the-same-thing-with-AutoGuides">Doing the same thing with AutoGuides</a></li>
<li class="toctree-l1"><a class="reference internal" href="easyguide.html">Writing guides using EasyGuide</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_objectives.html">Customizing SVI objectives and training loops</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Boosting Black Box Variational Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Contents">Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Theoretical-Background">Theoretical Background</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Variational-Inference">Variational Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id1">Boosting Black Box Variational Inference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#BBBVI-in-Pyro">BBBVI in Pyro</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#The-Model">The Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#The-Guide">The Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="#The-RELBO">The RELBO</a></li>
<li class="toctree-l3"><a class="reference internal" href="#The-Approximation">The Approximation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#The-Greedy-Algorithm">The Greedy Algorithm</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#The-Complete-Implementation">The Complete Implementation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#References">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="neutra.html">Example: Neural MCMC with NeuTraReparam</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_regression.html">Example: Sparse Bayesian Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="autoname_examples.html">Example: reducing boilerplate with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.autoname</span></code></a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Time Series</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="forecasting_i.html">Forecasting I: univariate, heavy tailed</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_ii.html">Forecasting II: state space models</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_iii.html">Forecasting III: hierarchical models</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_dlm.html">Forecasting with Dynamic Linear Model (DLM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="stable.html">Levy Stable models of Stochastic Volatility</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecast_simple.html">Multivariate Forecasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="timeseries.html">Example: Gaussian Process Time Series Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Gaussian Processes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="gp.html">Gaussian Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="gplvm.html">Gaussian Process Latent Variable Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="bo.html">Bayesian Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="dkl.html">Example: Deep Kernel Learning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Epidemiology</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="epi_intro.html">Epidemiological models: Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="epi_sir.html">Example: Univariate epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="epi_regional.html">Example: Regional epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="sir_hmc.html">Example: Epidemiological inference via HMC</a></li>
<li class="toctree-l1"><a class="reference internal" href="logistic-growth.html">Logistic growth models of SARS-CoV-2 lineage proportions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Biological sequences</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mue_profile.html">Example: Constant + MuE (Profile HMM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mue_factor.html">Example: Probabilistic PCA + MuE (FactorMuE)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Experimental Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="working_memory.html">Designing Adaptive Experiments to Study Working Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="elections.html">Predicting the outcome of a US presidential election using Bayesian optimal experimental design</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Object Tracking</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tracking_1d.html">Tracking an Unknown Number of Objects</a></li>
<li class="toctree-l1"><a class="reference internal" href="ekf.html">Kalman Filter</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Inference Algorithms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="baseball.html">Example: analyzing baseball stats with MCMC</a></li>
<li class="toctree-l1"><a class="reference internal" href="mcmc.html">Example: Inference with Markov Chain Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="lkj.html">Example: MCMC with an LKJ prior over covariances</a></li>
<li class="toctree-l1"><a class="reference internal" href="csis.html">Compiled Sequential Importance Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="smcfilter.html">Example: Sequential Monte Carlo Filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="inclined_plane.html">Example: importance sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="RSA-implicature.html">The Rational Speech Act framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="RSA-hyperbole.html">Understanding Hyperbole using RSA</a></li>
<li class="toctree-l1"><a class="reference internal" href="predictive_deterministic.html">Example: Utilizing Predictive and Deterministic with MCMC and SVI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Understanding Pyro's Internals</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="minipyro.html">Mini-Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="effect_handlers.html">Poutine: A Guide to Programming with Effect Handlers in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="contrib_funsor_intro_i.html"><code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code>, a new backend for Pyro - New primitives (Part 1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="contrib_funsor_intro_ii.html"><code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code>, a new backend for Pyro - Building inference algorithms (Part 2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm_funsor.html">Example: hidden Markov models with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">pyroapi</span></code></a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deprecated</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro_part_i.html">(DEPRECATED) An Introduction to Models in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro_part_ii.html">(DEPRECATED) An Introduction to Inference in Pyro</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pyro Tutorials</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">Boosting Black Box Variational Inference</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/boosting_bbvi.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="Boosting-Black-Box-Variational-Inference">
<h1>Boosting Black Box Variational Inference<a class="headerlink" href="#Boosting-Black-Box-Variational-Inference" title="Permalink to this heading">¶</a></h1>
<section id="Introduction">
<h2>Introduction<a class="headerlink" href="#Introduction" title="Permalink to this heading">¶</a></h2>
<p>This tutorial demonstrates how to implement boosting black box Variational Inference [1] in Pyro. In boosting Variational Inference [2], we approximate a target distribution with an iteratively selected mixture of densities. In cases where a single denisity provided by regular Variational Inference doesn’t adequately approximate a target density, boosting VI thus offers a simple way of getting more complex approximations. We show how this can be implemented as a relatively straightforward
extension of Pyro’s SVI.</p>
</section>
<section id="Contents">
<h2>Contents<a class="headerlink" href="#Contents" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="#theoretical-background">Theoretical Background</a></p>
<ul>
<li><p><a class="reference external" href="#variational-inference">Variational Inference</a></p></li>
<li><p><a class="reference external" href="#bbbvi">Boosting Black Box Variational Inference</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#bbbvi-pyro">BBBVI in Pyro</a></p>
<ul>
<li><p><a class="reference external" href="#the-model">The Model</a></p></li>
<li><p><a class="reference external" href="#the-guide">The Guide</a></p></li>
<li><p><a class="reference external" href="#the-relbo">The Relbo</a></p></li>
<li><p><a class="reference external" href="#the-approximation">The Approximation</a></p></li>
<li><p><a class="reference external" href="#the-greedy-algorithm">The Greedy Algorithm</a></p></li>
</ul>
</li>
</ul>
</section>
<section id="Theoretical-Background">
<h2>Theoretical Background<a class="headerlink" href="#Theoretical-Background" title="Permalink to this heading">¶</a></h2>
<section id="Variational-Inference">
<h3>Variational Inference<a class="headerlink" href="#Variational-Inference" title="Permalink to this heading">¶</a></h3>
<p>For an introduction to regular Variational Inference, we recommend having a look at <a class="reference external" href="https://pyro.ai/examples/svi_part_i.html">the tutorial on SVI in Pyro</a> and this excellent review [3].</p>
<p>Briefly, Variational Inference allows us to find approximations of probability densities which are intractable to compute analytically. For instance, one might have observed variables <span class="math notranslate nohighlight">\(\textbf{x}\)</span>, latent variables <span class="math notranslate nohighlight">\(\textbf{z}\)</span> and a joint distribution <span class="math notranslate nohighlight">\(p(\textbf{x}, \textbf{z})\)</span>. One can then use Variational Inference to approximate <span class="math notranslate nohighlight">\(p(\textbf{z}|\textbf{x})\)</span>. To do so, one first chooses a set of tractable densities, a variational family, and then tries to find the
element of this set which most closely approximates the target distribution <span class="math notranslate nohighlight">\(p(\textbf{z}|\textbf{x})\)</span>. This approximating density is found by maximizing the Evidence Lower BOund (ELBO):</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}_q[\log p(\mathbf{x}, \mathbf{z})] - \mathbb{E}_q[\log q(\mathbf{z})]\]</div>
<p>where <span class="math notranslate nohighlight">\(q(\mathbf{z})\)</span> is the approximating density.</p>
</section>
<section id="id1">
<h3>Boosting Black Box Variational Inference<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h3>
<p>In boosting black box Variational inference (BBBVI), we approximate the target density with a mixture of densities from the variational family:</p>
<div class="math notranslate nohighlight">
\[q^t(\mathbf{z}) = \sum_{i=1}^t \gamma_i s_i(\mathbf{z})\]</div>
<div class="math notranslate nohighlight">
\[\text{where} \sum_{i=1}^t \gamma_i =1\]</div>
<p>and <span class="math notranslate nohighlight">\(s_t(\mathbf{z})\)</span> are elements of the variational family.</p>
<p>The components of the approximation are selected greedily by maximising the so-called Residual ELBO (RELBO) with respect to the next component <span class="math notranslate nohighlight">\(s_{t+1}(\mathbf{z})\)</span>:</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}_s[\log p(\mathbf{x},\mathbf{z})] - \lambda \mathbb{E}_s[\log s(\mathbf{z})] - \mathbb{E}_s[\log q^t(\mathbf{z})]\]</div>
<p>Where the first two terms are the same as in the ELBO and the last term is the cross entropy between the next component <span class="math notranslate nohighlight">\(s_{t+1}(\mathbf{z})\)</span> and the current approximation <span class="math notranslate nohighlight">\(q^t(\mathbf{z})\)</span>.</p>
<p>It’s called <em>black box</em> Variational Inference because this optimization does not have to be tailored to the variational family which is being used. By setting <span class="math notranslate nohighlight">\(\lambda\)</span> (the regularization factor of the entropy term) to 1, standard SVI methods can be used to compute <span class="math notranslate nohighlight">\(\mathbb{E}_s[\log p(\mathbf{x}, \mathbf{z})] - \lambda \mathbb{E}_s[\log s(\mathbf{z})]\)</span>. See the explanation of <a class="reference external" href="#the-relbo">the section on the implementation of the RELBO</a> below for an explanation of how we compute
the term <span class="math notranslate nohighlight">\(- \mathbb{E}_s[\log q^t(\mathbf{z})]\)</span>. Imporantly, we do not need to make any additional assumptions about the variational family that’s being used to ensure that this algorithm converges.</p>
<p>In [1], a number of different ways of finding the mixture weights <span class="math notranslate nohighlight">\(\gamma_t\)</span> are suggested, ranging from fixed step sizes based on the iteration to solving the optimisation problem of finding <span class="math notranslate nohighlight">\(\gamma_t\)</span> that will minimise the RELBO. Here, we used the fixed step size method. For more details on the theory behind boosting black box variational inference, please refer to [1].</p>
</section>
</section>
<section id="BBBVI-in-Pyro">
<h2>BBBVI in Pyro<a class="headerlink" href="#BBBVI-in-Pyro" title="Permalink to this heading">¶</a></h2>
<p>To implement boosting black box variational inference in Pyro, we need to consider the following points: 1. The approximation components <span class="math notranslate nohighlight">\(s_{t}(\mathbf{z})\)</span> (guides). 2. The RELBO. 3. The approximation itself <span class="math notranslate nohighlight">\(q^t(\mathbf{z})\)</span>. 4. Using Pyro’s SVI to find new components of the approximation.</p>
<p>We will illustrate these points by looking at simple example: approximating a bimodal posterior.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import os
from collections import defaultdict
from functools import partial

import numpy as np
import pyro
import pyro.distributions as dist
import scipy.stats
import torch
import torch.distributions.constraints as constraints
from matplotlib import pyplot
from pyro.infer import SVI, Trace_ELBO
from pyro.optim import Adam
from pyro.poutine import block, replay, trace
<br/></pre></div>
</div>
</div>
<section id="The-Model">
<h3>The Model<a class="headerlink" href="#The-Model" title="Permalink to this heading">¶</a></h3>
<p>Boosting BBVI is particularly useful when we want to approximate multimodal distributions. In this tutorial, we’ll thus consider the following model:</p>
<div class="math notranslate nohighlight">
\[\mathbf{z} \sim \mathcal{N}(0,5)\]</div>
<div class="math notranslate nohighlight">
\[\mathbf{x} \sim \mathcal{N}(\mathbf{z}^2, 0.1)\]</div>
<p>Given the set of iid. observations <span class="math notranslate nohighlight">\(\text{data} ~ \mathcal{N}(4, 0.1)\)</span>, we thus expect <span class="math notranslate nohighlight">\(p(\mathbf{z}|\mathbf{x})\)</span> to be a bimodal distributions with modes around <span class="math notranslate nohighlight">\(-2\)</span> and <span class="math notranslate nohighlight">\(2\)</span>.</p>
<p>In Pyro, this model takes the following shape:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def model(data):
    prior_loc = torch.tensor([0.])
    prior_scale = torch.tensor([5.])
    z = pyro.sample(&#39;z&#39;, dist.Normal(prior_loc, prior_scale))
    scale = torch.tensor([0.1])

    with pyro.plate(&#39;data&#39;, len(data)):
        pyro.sample(&#39;x&#39;, dist.Normal(z*z, scale), obs=data)
</pre></div>
</div>
</div>
</section>
<section id="The-Guide">
<h3>The Guide<a class="headerlink" href="#The-Guide" title="Permalink to this heading">¶</a></h3>
<p>Next, we specify the guide which in our case will make up the components of our mixture. Recall that in Pyro the guide needs to take the same arguments as the model which is why our guide function also takes the data as an input.</p>
<p>We also need to make sure that every <code class="docutils literal notranslate"><span class="pre">pyro.sample()</span></code> statement from the model has a matching <code class="docutils literal notranslate"><span class="pre">pyro.sample()</span></code> statement in the guide. In our case, we include <code class="docutils literal notranslate"><span class="pre">z</span></code> in both the model and the guide.</p>
<p>In contrast to regular SVI, our guide takes an additional argument: <code class="docutils literal notranslate"><span class="pre">index</span></code>. Having this argument allows us to easily create new guides in each iteration of the greedy algorithm. Specifically, we make use of <code class="docutils literal notranslate"><span class="pre">partial()</span></code> from the <a class="reference external" href="https://docs.python.org/3.7/library/functools.html">functools library</a> to create guides which only take <code class="docutils literal notranslate"><span class="pre">data</span></code> as an argument. The statement <code class="docutils literal notranslate"><span class="pre">partial(guide,</span> <span class="pre">index=t)</span></code> creates a guide that will take only <code class="docutils literal notranslate"><span class="pre">data</span></code> as an input and which has trainable parameters
<code class="docutils literal notranslate"><span class="pre">scale_t</span></code> and <code class="docutils literal notranslate"><span class="pre">loc_t</span></code>.</p>
<p>Choosing our variational distribution to be a Normal distribution parameterized by <span class="math notranslate nohighlight">\(loc_t\)</span> and <span class="math notranslate nohighlight">\(scale_t\)</span> we get the following guide:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def guide(data, index):
    scale_q = pyro.param(&#39;scale_{}&#39;.format(index), torch.tensor([1.0]), constraints.positive)
    loc_q = pyro.param(&#39;loc_{}&#39;.format(index), torch.tensor([0.0]))
    pyro.sample(&quot;z&quot;, dist.Normal(loc_q, scale_q))
</pre></div>
</div>
</div>
</section>
<section id="The-RELBO">
<h3>The RELBO<a class="headerlink" href="#The-RELBO" title="Permalink to this heading">¶</a></h3>
<p>We implement the RELBO as a function which can be passed to Pyro’s SVI class in place of ELBO to find the approximation components <span class="math notranslate nohighlight">\(s_t(z)\)</span>. Recall that the RELBO has the following form:</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}_s[\log p(\mathbf{x},\mathbf{z})] - \lambda \mathbb{E}_s[\log s(\mathbf{z})] - \mathbb{E}_s[\log q^t(\mathbf{z})]\]</div>
<p>Conveniently, this is very similar to the regular ELBO which allows us to reuse Pyro’s existing ELBO. Specifically, we compute</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}_s[\log p(x,z)] - \lambda \mathbb{E}_s[\log s]\]</div>
<p>using Pyro’s <code class="docutils literal notranslate"><span class="pre">Trace_ELBO</span></code> and then compute</p>
<div class="math notranslate nohighlight">
\[- \mathbb{E}_s[\log q^t]\]</div>
<p>using Poutine. For more information on how this works, we recommend going through the Pyro tutorials <a class="reference external" href="https://pyro.ai/examples/effect_handlers.html">on Poutine</a> and <a class="reference external" href="https://pyro.ai/examples/custom_objectives.html">custom SVI objectives</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def relbo(model, guide, *args, **kwargs):
    approximation = kwargs.pop(&#39;approximation&#39;)

    # We first compute the elbo, but record a guide trace for use below.
    traced_guide = trace(guide)
    elbo = pyro.infer.Trace_ELBO(max_plate_nesting=1)
    loss_fn = elbo.differentiable_loss(model, traced_guide, *args, **kwargs)

    # We do not want to update parameters of previously fitted components
    # and thus block all parameters in the approximation apart from z.
    guide_trace = traced_guide.trace
    replayed_approximation = trace(replay(block(approximation, expose=[&#39;z&#39;]), guide_trace))
    approximation_trace = replayed_approximation.get_trace(*args, **kwargs)

    relbo = -loss_fn - approximation_trace.log_prob_sum()

    # By convention, the negative (R)ELBO is returned.
    return -relbo
</pre></div>
</div>
</div>
</section>
<section id="The-Approximation">
<h3>The Approximation<a class="headerlink" href="#The-Approximation" title="Permalink to this heading">¶</a></h3>
<p>Our implementation of the approximation <span class="math notranslate nohighlight">\(q^t(z) = \sum_{i=1}^t \gamma_i s_i(z)\)</span> consists of a list of components, i.e. the guides from the greedy selection steps, and a list containing the mixture weights of the components. To sample from the approximation, we thus first sample a component according to the mixture weights. In a second step, we draw a sample from the corresponding component.</p>
<p>Similarly as with the guide, we use <code class="docutils literal notranslate"><span class="pre">partial(approximation,</span> <span class="pre">components=components,</span> <span class="pre">weights=weights)</span></code> to get an approximation function which has the same signature as the model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def approximation(data, components, weights):
    assignment = pyro.sample(&#39;assignment&#39;, dist.Categorical(weights))
    result = components[assignment](data)
    return result
</pre></div>
</div>
</div>
</section>
<section id="The-Greedy-Algorithm">
<h3>The Greedy Algorithm<a class="headerlink" href="#The-Greedy-Algorithm" title="Permalink to this heading">¶</a></h3>
<p>We now have all the necessary parts to implement the greedy algorithm. First, we initialize the approximation:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>initial_approximation = partial(guide, index=0)
components = [initial_approximation]
weights = torch.tensor([1.])
wrapped_approximation = partial(approximation, components=components, weights=weights)
</pre></div>
</div>
</div>
<p>Then we iteratively find the <span class="math notranslate nohighlight">\(T\)</span> components of the approximation by maximizing the RELBO at every step:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># clear the param store in case we&#39;re in a REPL
pyro.clear_param_store()

# Sample observations from a Normal distribution with loc 4 and scale 0.1
n = torch.distributions.Normal(torch.tensor([4.0]), torch.tensor([0.1]))
data = n.sample((100,))

#T=2
smoke_test = (&#39;CI&#39; in os.environ)
n_steps = 2 if smoke_test else 12000
pyro.set_rng_seed(2)
n_iterations = 2
locs = [0]
scales = [0]
for t in range(1, n_iterations + 1):

    # Create guide that only takes data as argument
    wrapped_guide = partial(guide, index=t)
    losses = []

    adam_params = {&quot;lr&quot;: 0.01, &quot;betas&quot;: (0.90, 0.999)}
    optimizer = Adam(adam_params)

    # Pass our custom RELBO to SVI as the loss function.
    svi = SVI(model, wrapped_guide, optimizer, loss=relbo)
    for step in range(n_steps):
        # Pass the existing approximation to SVI.
        loss = svi.step(data, approximation=wrapped_approximation)
        losses.append(loss)

        if step % 100 == 0:
            print(&#39;.&#39;, end=&#39; &#39;)

    # Update the list of approximation components.
    components.append(wrapped_guide)

    # Set new mixture weight.
    new_weight = 2 / (t + 1)

    # In this specific case, we set the mixture weight of the second component to 0.5.
    if t == 2:
        new_weight = 0.5
    weights = weights * (1-new_weight)
    weights = torch.cat((weights, torch.tensor([new_weight])))

    # Update the approximation
    wrapped_approximation = partial(approximation, components=components, weights=weights)

    print(&#39;Parameters of component {}:&#39;.format(t))
    scale = pyro.param(&quot;scale_{}&quot;.format(t)).item()
    scales.append(scale)
    loc = pyro.param(&quot;loc_{}&quot;.format(t)).item()
    locs.append(loc)
    print(&#39;loc = {}&#39;.format(loc))
    print(&#39;scale = {}&#39;.format(scale))
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Parameters of component 1:
loc = -2.0068717002868652
scale = 0.01799079217016697
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Parameters of component 2:
loc = 2.0046799182891846
scale = 0.06008879840373993
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Plot the resulting approximation
X = np.arange(-10, 10, 0.1)
pyplot.figure(figsize=(10, 4), dpi=100).set_facecolor(&#39;white&#39;)
total_approximation = np.zeros(X.shape)
for i in range(1, n_iterations + 1):
    Y = weights[i].item() * scipy.stats.norm.pdf((X - locs[i]) / scales[i])
    pyplot.plot(X, Y)
    total_approximation += Y
pyplot.plot(X, total_approximation)
pyplot.plot(data.data.numpy(), np.zeros(len(data)), &#39;k*&#39;)
pyplot.title(&#39;Approximation of posterior over z&#39;)
pyplot.ylabel(&#39;probability density&#39;)
pyplot.show()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/boosting_bbvi_19_0.png" src="_images/boosting_bbvi_19_0.png" />
</div>
</div>
<p>We see that boosting BBVI successfully approximates the bimodal posterior distributions with modes around -2 and +2.</p>
</section>
</section>
<section id="The-Complete-Implementation">
<h2>The Complete Implementation<a class="headerlink" href="#The-Complete-Implementation" title="Permalink to this heading">¶</a></h2>
<p>Putting all the components together, we then get the complete implementation of boosting black box Variational Inference:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import os
from collections import defaultdict
from functools import partial

import numpy as np
import pyro
import pyro.distributions as dist
import scipy.stats
import torch
import torch.distributions.constraints as constraints
from matplotlib import pyplot
from pyro.infer import SVI, Trace_ELBO
from pyro.optim import Adam
from pyro.poutine import block, replay, trace

# this is for running the notebook in our testing framework
n_steps = 2 if smoke_test else 12000
pyro.set_rng_seed(2)

# clear the param store in case we&#39;re in a REPL
pyro.clear_param_store()

# Sample observations from a Normal distribution with loc 4 and scale 0.1
n = torch.distributions.Normal(torch.tensor([4.0]), torch.tensor([0.1]))
data = n.sample((100,))


def guide(data, index):
    scale_q = pyro.param(&#39;scale_{}&#39;.format(index), torch.tensor([1.0]), constraints.positive)
    loc_q = pyro.param(&#39;loc_{}&#39;.format(index), torch.tensor([0.0]))
    pyro.sample(&quot;z&quot;, dist.Normal(loc_q, scale_q))


def model(data):
    prior_loc = torch.tensor([0.])
    prior_scale = torch.tensor([5.])
    z = pyro.sample(&#39;z&#39;, dist.Normal(prior_loc, prior_scale))
    scale = torch.tensor([0.1])

    with pyro.plate(&#39;data&#39;, len(data)):
        pyro.sample(&#39;x&#39;, dist.Normal(z*z, scale), obs=data)


def relbo(model, guide, *args, **kwargs):
    approximation = kwargs.pop(&#39;approximation&#39;)

    # We first compute the elbo, but record a guide trace for use below.
    traced_guide = trace(guide)
    elbo = pyro.infer.Trace_ELBO(max_plate_nesting=1)
    loss_fn = elbo.differentiable_loss(model, traced_guide, *args, **kwargs)

    # We do not want to update parameters of previously fitted components
    # and thus block all parameters in the approximation apart from z.
    guide_trace = traced_guide.trace
    replayed_approximation = trace(replay(block(approximation, expose=[&#39;z&#39;]), guide_trace))
    approximation_trace = replayed_approximation.get_trace(*args, **kwargs)

    relbo = -loss_fn - approximation_trace.log_prob_sum()

    # By convention, the negative (R)ELBO is returned.
    return -relbo


def approximation(data, components, weights):
    assignment = pyro.sample(&#39;assignment&#39;, dist.Categorical(weights))
    result = components[assignment](data)
    return result


def boosting_bbvi():
    # T=2
    n_iterations = 2
    initial_approximation = partial(guide, index=0)
    components = [initial_approximation]
    weights = torch.tensor([1.])
    wrapped_approximation = partial(approximation, components=components, weights=weights)

    locs = [0]
    scales = [0]

    for t in range(1, n_iterations + 1):

        # Create guide that only takes data as argument
        wrapped_guide = partial(guide, index=t)
        losses = []

        adam_params = {&quot;lr&quot;: 0.01, &quot;betas&quot;: (0.90, 0.999)}
        optimizer = Adam(adam_params)

        # Pass our custom RELBO to SVI as the loss function.
        svi = SVI(model, wrapped_guide, optimizer, loss=relbo)
        for step in range(n_steps):
            # Pass the existing approximation to SVI.
            loss = svi.step(data, approximation=wrapped_approximation)
            losses.append(loss)

            if step % 100 == 0:
                print(&#39;.&#39;, end=&#39; &#39;)

        # Update the list of approximation components.
        components.append(wrapped_guide)

        # Set new mixture weight.
        new_weight = 2 / (t + 1)

        # In this specific case, we set the mixture weight of the second component to 0.5.
        if t == 2:
            new_weight = 0.5
        weights = weights * (1-new_weight)
        weights = torch.cat((weights, torch.tensor([new_weight])))

        # Update the approximation
        wrapped_approximation = partial(approximation, components=components, weights=weights)

        print(&#39;Parameters of component {}:&#39;.format(t))
        scale = pyro.param(&quot;scale_{}&quot;.format(t)).item()
        scales.append(scale)
        loc = pyro.param(&quot;loc_{}&quot;.format(t)).item()
        locs.append(loc)
        print(&#39;loc = {}&#39;.format(loc))
        print(&#39;scale = {}&#39;.format(scale))


    # Plot the resulting approximation
    X = np.arange(-10, 10, 0.1)
    pyplot.figure(figsize=(10, 4), dpi=100).set_facecolor(&#39;white&#39;)
    total_approximation = np.zeros(X.shape)
    for i in range(1, n_iterations + 1):
        Y = weights[i].item() * scipy.stats.norm.pdf((X - locs[i]) / scales[i])
        pyplot.plot(X, Y)
        total_approximation += Y
    pyplot.plot(X, total_approximation)
    pyplot.plot(data.data.numpy(), np.zeros(len(data)), &#39;k*&#39;)
    pyplot.title(&#39;Approximation of posterior over z&#39;)
    pyplot.ylabel(&#39;probability density&#39;)
    pyplot.show()

if __name__ == &#39;__main__&#39;:
    boosting_bbvi()
<br/></pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Parameters of component 1:
loc = -1.9996534585952759
scale = 0.016739774495363235
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Parameters of component 2:
loc = 1.998241901397705
scale = 0.01308442372828722
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/boosting_bbvi_23_1.png" src="_images/boosting_bbvi_23_1.png" />
</div>
</div>
<section id="References">
<h3>References<a class="headerlink" href="#References" title="Permalink to this heading">¶</a></h3>
<p>[1] Locatello, Francesco, et al. “Boosting black box variational inference.” Advances in Neural Information Processing Systems. 2018.</p>
<p>[2] Ranganath, Rajesh, Sean Gerrish, and David Blei. “Black box variational inference.” Artificial Intelligence and Statistics. 2014.</p>
<p>[3] Blei, David M., Alp Kucukelbir, and Jon D. McAuliffe. “Variational inference: A review for statisticians.” Journal of the American statistical Association 112.518 (2017): 859-877.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="custom_objectives.html" class="btn btn-neutral float-left" title="Customizing SVI objectives and training loops" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="neutra.html" class="btn btn-neutral float-right" title="Example: Neural MCMC with NeuTraReparam" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Pyro Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>