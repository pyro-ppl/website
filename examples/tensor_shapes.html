<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Tensor shapes in Pyro &mdash; Pyro Tutorials 1.8.4 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/pyro.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Modules in Pyro" href="modules.html" />
    <link rel="prev" title="Bayesian Regression - Inference Algorithms (Part 2)" href="bayesian_regression_ii.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html">
            <img src="_static/pyro_logo_wide.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                1.8.4
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Introductory Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro_long.html">Introduction to Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_rendering.html">Automatic rendering of Pyro models</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_i.html">SVI Part I: An Introduction to Stochastic Variational Inference in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_ii.html">SVI Part II: Conditional Independence, Subsampling, and Amortization</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_iii.html">SVI Part III: ELBO Gradient Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_iv.html">SVI Part IV: Tips and Tricks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Practical Pyro and PyTorch</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="bayesian_regression.html">Bayesian Regression - Introduction (Part 1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayesian_regression_ii.html">Bayesian Regression - Inference Algorithms (Part 2)</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Tensor shapes in Pyro</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Summary:">Summary:</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Table-of-Contents">Table of Contents</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Distributions-shapes:-batch_shape-and-event_shape">Distributions shapes: <code class="docutils literal notranslate"><span class="pre">batch_shape</span></code> and <code class="docutils literal notranslate"><span class="pre">event_shape</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Reshaping-distributions">Reshaping distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#It-is-always-safe-to-assume-dependence">It is always safe to assume dependence</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Declaring-independent-dims-with-plate">Declaring independent dims with <code class="docutils literal notranslate"><span class="pre">plate</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#Subsampling-tensors-inside-a-plate">Subsampling tensors inside a <code class="docutils literal notranslate"><span class="pre">plate</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#Broadcasting-to-allow-parallel-enumeration">Broadcasting to allow parallel enumeration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Writing-parallelizable-code">Writing parallelizable code</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Automatic-broadcasting-inside-pyro.plate">Automatic broadcasting inside pyro.plate</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">Modules in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="workflow.html">High-dimensional Bayesian workflow, with applications to SARS-CoV-2 strains</a></li>
<li class="toctree-l1"><a class="reference internal" href="prior_predictive.html">Interactive posterior predictives checks</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">Using the PyTorch JIT Compiler with Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_horovod.html">Example: distributed training via Horovod</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deep Generative Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="vae.html">Variational Autoencoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="ss-vae.html">The Semi-Supervised VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="cvae.html">Conditional Variational Auto-encoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="normalizing_flows_i.html">Normalizing Flows - Introduction (Part 1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dmm.html">Deep Markov Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="air.html">Attend Infer Repeat</a></li>
<li class="toctree-l1"><a class="reference internal" href="cevae.html">Example: Causal Effect VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_gamma.html">Example: Sparse Gamma Deep Exponential Family</a></li>
<li class="toctree-l1"><a class="reference internal" href="prodlda.html">Probabilistic Topic Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="scanvi.html"><em>scANVI: Deep Generative Modeling for Single Cell Data with Pyro</em></a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Discrete Latent Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enumeration.html">Inference with Discrete Latent Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="gmm.html">Gaussian Mixture Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="dirichlet_process_mixture.html">Dirichlet Process Mixture Models in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="toy_mixture_model_discrete_enumeration.html">Example: Toy Mixture Model With Discrete Enumeration</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm.html">Example: Hidden Markov Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="capture_recapture.html">Example: Capture-Recapture Models (CJS Models)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mixed_hmm.html">Example: hierarchical mixed-effect hidden Markov models</a></li>
<li class="toctree-l1"><a class="reference internal" href="einsum.html">Example: Discrete Factor Graph Inference with Plated Einsum</a></li>
<li class="toctree-l1"><a class="reference internal" href="lda.html">Example: Amortized Latent Dirichlet Allocation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Customizing Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mle_map.html">MLE and MAP Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="mle_map.html#Doing-the-same-thing-with-AutoGuides">Doing the same thing with AutoGuides</a></li>
<li class="toctree-l1"><a class="reference internal" href="easyguide.html">Writing guides using EasyGuide</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_objectives.html">Customizing SVI objectives and training loops</a></li>
<li class="toctree-l1"><a class="reference internal" href="boosting_bbvi.html">Boosting Black Box Variational Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="neutra.html">Example: Neural MCMC with NeuTraReparam</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_regression.html">Example: Sparse Bayesian Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="autoname_examples.html">Example: reducing boilerplate with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.autoname</span></code></a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Time Series</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="forecasting_i.html">Forecasting I: univariate, heavy tailed</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_ii.html">Forecasting II: state space models</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_iii.html">Forecasting III: hierarchical models</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_dlm.html">Forecasting with Dynamic Linear Model (DLM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="stable.html">Levy Stable models of Stochastic Volatility</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecast_simple.html">Multivariate Forecasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="timeseries.html">Example: Gaussian Process Time Series Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Gaussian Processes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="gp.html">Gaussian Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="gplvm.html">Gaussian Process Latent Variable Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="bo.html">Bayesian Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="dkl.html">Example: Deep Kernel Learning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Epidemiology</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="epi_intro.html">Epidemiological models: Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="epi_sir.html">Example: Univariate epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="epi_regional.html">Example: Regional epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="sir_hmc.html">Example: Epidemiological inference via HMC</a></li>
<li class="toctree-l1"><a class="reference internal" href="logistic-growth.html">Logistic growth models of SARS-CoV-2 lineage proportions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Biological sequences</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mue_profile.html">Example: Constant + MuE (Profile HMM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mue_factor.html">Example: Probabilistic PCA + MuE (FactorMuE)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Experimental Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="working_memory.html">Designing Adaptive Experiments to Study Working Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="elections.html">Predicting the outcome of a US presidential election using Bayesian optimal experimental design</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Object Tracking</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tracking_1d.html">Tracking an Unknown Number of Objects</a></li>
<li class="toctree-l1"><a class="reference internal" href="ekf.html">Kalman Filter</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Inference Algorithms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="baseball.html">Example: analyzing baseball stats with MCMC</a></li>
<li class="toctree-l1"><a class="reference internal" href="mcmc.html">Example: Inference with Markov Chain Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="lkj.html">Example: MCMC with an LKJ prior over covariances</a></li>
<li class="toctree-l1"><a class="reference internal" href="csis.html">Compiled Sequential Importance Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="smcfilter.html">Example: Sequential Monte Carlo Filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="inclined_plane.html">Example: importance sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="RSA-implicature.html">The Rational Speech Act framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="RSA-hyperbole.html">Understanding Hyperbole using RSA</a></li>
<li class="toctree-l1"><a class="reference internal" href="predictive_deterministic.html">Example: Utilizing Predictive and Deterministic with MCMC and SVI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Understanding Pyro's Internals</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="minipyro.html">Mini-Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="effect_handlers.html">Poutine: A Guide to Programming with Effect Handlers in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="contrib_funsor_intro_i.html"><code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code>, a new backend for Pyro - New primitives (Part 1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="contrib_funsor_intro_ii.html"><code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code>, a new backend for Pyro - Building inference algorithms (Part 2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm_funsor.html">Example: hidden Markov models with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">pyroapi</span></code></a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deprecated</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro_part_i.html">(DEPRECATED) An Introduction to Models in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro_part_ii.html">(DEPRECATED) An Introduction to Inference in Pyro</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pyro Tutorials</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">Tensor shapes in Pyro</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/tensor_shapes.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="Tensor-shapes-in-Pyro">
<h1>Tensor shapes in Pyro<a class="headerlink" href="#Tensor-shapes-in-Pyro" title="Permalink to this heading">¶</a></h1>
<div class="line-block">
<div class="line">This tutorial introduces Pyro’s organization of tensor dimensions. Before starting, you should familiarize yourself with <a class="reference external" href="http://pytorch.org/docs/master/notes/broadcasting.html">PyTorch broadcasting semantics</a>.</div>
<div class="line">After this tutorial, you may want to also read about <a class="reference external" href="http://pyro.ai/examples/enumeration.html">enumeration</a>.</div>
</div>
<p>You may also find it useful to read Eric J. Ma’s post <a class="reference external" href="https://ericmjl.github.io/blog/2019/5/29/reasoning-about-shapes-and-probability-distributions/">Reasoning about Shapes and Probability Distributions</a>. While this post is specifically about TensorFlow Probability, many of the same concepts apply.</p>
<section id="Summary:">
<h2>Summary:<a class="headerlink" href="#Summary:" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p>Tensors broadcast by aligning on the right: <code class="docutils literal notranslate"><span class="pre">torch.ones(3,4,5)</span> <span class="pre">+</span> <span class="pre">torch.ones(5)</span></code>.</p></li>
<li><p>Distribution <code class="docutils literal notranslate"><span class="pre">.sample().shape</span> <span class="pre">==</span> <span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">event_shape</span></code>.</p></li>
<li><p>Distribution <code class="docutils literal notranslate"><span class="pre">.log_prob(x).shape</span> <span class="pre">==</span> <span class="pre">batch_shape</span></code> (but not <code class="docutils literal notranslate"><span class="pre">event_shape</span></code>!).</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">.expand()</span></code> to draw a batch of samples, or rely on <code class="docutils literal notranslate"><span class="pre">plate</span></code> to expand automatically.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">my_dist.to_event(1)</span></code> to declare a dimension as dependent.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">with</span> <span class="pre">pyro.plate('name',</span> <span class="pre">size):</span></code> to declare a dimension as conditionally independent.</p></li>
<li><p>All dimensions must be declared either dependent or conditionally independent.</p></li>
<li><p>Try to support batching on the left. This lets Pyro auto-parallelize.</p>
<ul>
<li><p>use negative indices like <code class="docutils literal notranslate"><span class="pre">x.sum(-1)</span></code> rather than <code class="docutils literal notranslate"><span class="pre">x.sum(2)</span></code></p></li>
<li><p>use ellipsis notation like <code class="docutils literal notranslate"><span class="pre">pixel</span> <span class="pre">=</span> <span class="pre">image[...,</span> <span class="pre">i,</span> <span class="pre">j]</span></code></p></li>
<li><p>use <a class="reference external" href="http://docs.pyro.ai/en/dev/ops.html#pyro.ops.indexing.Vindex">Vindex</a> if <code class="docutils literal notranslate"><span class="pre">i,j</span></code> are enumerated, <code class="docutils literal notranslate"><span class="pre">pixel</span> <span class="pre">=</span> <span class="pre">Vindex(image)[...,</span> <span class="pre">i,</span> <span class="pre">j]</span></code></p></li>
</ul>
</li>
<li><p>When using <code class="docutils literal notranslate"><span class="pre">pyro.plate</span></code>’s automatic subsampling, be sure to subsample your data:</p>
<ul>
<li><p>Either manually subample by capturing the index <code class="docutils literal notranslate"><span class="pre">with</span> <span class="pre">pyro.plate(...)</span> <span class="pre">as</span> <span class="pre">i:</span> <span class="pre">...</span></code></p></li>
<li><p>or automatically subsample via <code class="docutils literal notranslate"><span class="pre">batch</span> <span class="pre">=</span> <span class="pre">pyro.subsample(data,</span> <span class="pre">event_dim=...)</span></code>.</p></li>
</ul>
</li>
<li><p>When debugging, examine all shapes in a trace using <a class="reference external" href="http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.Trace.format_shapes">Trace.format_shapes()</a>.</p></li>
</ul>
</section>
<section id="Table-of-Contents">
<h2>Table of Contents<a class="headerlink" href="#Table-of-Contents" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="#Distributions-shapes:-batch_shape-and-event_shape">Distribution shapes</a></p>
<ul>
<li><p><a class="reference external" href="#Examples">Examples</a></p></li>
<li><p><a class="reference external" href="#Reshaping-distributions">Reshaping distributions</a></p></li>
<li><p><a class="reference external" href="#It-is-always-safe-to-assume-dependence">It is always safe to assume dependence</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#Declaring-independent-dims-with-plate">Declaring independence with plate</a></p></li>
<li><p><a class="reference external" href="#Subsampling-tensors-inside-a-plate">Subsampling inside plate</a></p></li>
<li><p><a class="reference external" href="#Broadcasting-to-allow-parallel-enumeration">Broadcasting to allow Parallel Enumeration</a></p>
<ul>
<li><p><a class="reference external" href="#Writing-parallelizable-code">Writing parallelizable code</a></p></li>
<li><p><a class="reference external" href="#Automatic-broadcasting-inside-pyro-plate">Automatic broadcasting inside pyro.plate</a></p></li>
</ul>
</li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import os
import torch
import pyro
from torch.distributions import constraints
from pyro.distributions import Bernoulli, Categorical, MultivariateNormal, Normal
from pyro.distributions.util import broadcast_shape
from pyro.infer import Trace_ELBO, TraceEnum_ELBO, config_enumerate
import pyro.poutine as poutine
from pyro.optim import Adam

smoke_test = (&#39;CI&#39; in os.environ)
assert pyro.__version__.startswith(&#39;1.8.4&#39;)

# We&#39;ll ue this helper to check our models are correct.
def test_model(model, guide, loss):
    pyro.clear_param_store()
    loss.loss(model, guide)
</pre></div>
</div>
</div>
<section id="Distributions-shapes:-batch_shape-and-event_shape">
<h3>Distributions shapes: <code class="docutils literal notranslate"><span class="pre">batch_shape</span></code> and <code class="docutils literal notranslate"><span class="pre">event_shape</span></code><a class="headerlink" href="#Distributions-shapes:-batch_shape-and-event_shape" title="Permalink to this heading">¶</a></h3>
<p>PyTorch <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>s have a single <code class="docutils literal notranslate"><span class="pre">.shape</span></code> attribute, but <code class="docutils literal notranslate"><span class="pre">Distribution</span></code>s have two shape attributions with special meaning: <code class="docutils literal notranslate"><span class="pre">.batch_shape</span></code> and <code class="docutils literal notranslate"><span class="pre">.event_shape</span></code>. These two combine to define the total shape of a sample</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">d</span><span class="o">.</span><span class="n">batch_shape</span> <span class="o">+</span> <span class="n">d</span><span class="o">.</span><span class="n">event_shape</span>
</pre></div>
</div>
<p>Indices over <code class="docutils literal notranslate"><span class="pre">.batch_shape</span></code> denote conditionally independent random variables, whereas indices over <code class="docutils literal notranslate"><span class="pre">.event_shape</span></code> denote dependent random variables (ie one draw from a distribution). Because the dependent random variables define probability together, the <code class="docutils literal notranslate"><span class="pre">.log_prob()</span></code> method only produces a single number for each event of shape <code class="docutils literal notranslate"><span class="pre">.event_shape</span></code>. Thus the total shape of <code class="docutils literal notranslate"><span class="pre">.log_prob()</span></code> is <code class="docutils literal notranslate"><span class="pre">.batch_shape</span></code>:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">d</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">d</span><span class="o">.</span><span class="n">batch_shape</span>
</pre></div>
</div>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">Distribution.sample()</span></code> method also takes a <code class="docutils literal notranslate"><span class="pre">sample_shape</span></code> parameter that indexes over independent identically distributed (iid) random varables, so that</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="n">x2</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample_shape</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">x2</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">sample_shape</span> <span class="o">+</span> <span class="n">batch_shape</span> <span class="o">+</span> <span class="n">event_shape</span>
</pre></div>
</div>
<p>In summary</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>      |      iid     | independent | dependent
------+--------------+-------------+------------
shape = sample_shape + batch_shape + event_shape
</pre></div>
</div>
<p>For example univariate distributions have empty event shape (because each number is an independent event). Distributions over vectors like <code class="docutils literal notranslate"><span class="pre">MultivariateNormal</span></code> have <code class="docutils literal notranslate"><span class="pre">len(event_shape)</span> <span class="pre">==</span> <span class="pre">1</span></code>. Distributions over matrices like <code class="docutils literal notranslate"><span class="pre">InverseWishart</span></code> have <code class="docutils literal notranslate"><span class="pre">len(event_shape)</span> <span class="pre">==</span> <span class="pre">2</span></code>.</p>
<section id="Examples">
<h4>Examples<a class="headerlink" href="#Examples" title="Permalink to this heading">¶</a></h4>
<p>The simplest distribution shape is a single univariate distribution.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>d = Bernoulli(0.5)
assert d.batch_shape == ()
assert d.event_shape == ()
x = d.sample()
assert x.shape == ()
assert d.log_prob(x).shape == ()
</pre></div>
</div>
</div>
<p>Distributions can be batched by passing in batched parameters.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>d = Bernoulli(0.5 * torch.ones(3,4))
assert d.batch_shape == (3, 4)
assert d.event_shape == ()
x = d.sample()
assert x.shape == (3, 4)
assert d.log_prob(x).shape == (3, 4)
</pre></div>
</div>
</div>
<p>Another way to batch distributions is via the <code class="docutils literal notranslate"><span class="pre">.expand()</span></code> method. This only works if parameters are identical along the leftmost dimensions.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>d = Bernoulli(torch.tensor([0.1, 0.2, 0.3, 0.4])).expand([3, 4])
assert d.batch_shape == (3, 4)
assert d.event_shape == ()
x = d.sample()
assert x.shape == (3, 4)
assert d.log_prob(x).shape == (3, 4)
</pre></div>
</div>
</div>
<p>Multivariate distributions have nonempty <code class="docutils literal notranslate"><span class="pre">.event_shape</span></code>. For these distributions, the shapes of <code class="docutils literal notranslate"><span class="pre">.sample()</span></code> and <code class="docutils literal notranslate"><span class="pre">.log_prob(x)</span></code> differ:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>d = MultivariateNormal(torch.zeros(3), torch.eye(3, 3))
assert d.batch_shape == ()
assert d.event_shape == (3,)
x = d.sample()
assert x.shape == (3,)            # == batch_shape + event_shape
assert d.log_prob(x).shape == ()  # == batch_shape
</pre></div>
</div>
</div>
</section>
<section id="Reshaping-distributions">
<h4>Reshaping distributions<a class="headerlink" href="#Reshaping-distributions" title="Permalink to this heading">¶</a></h4>
<p>In Pyro you can treat a univariate distribution as multivariate by calling the <a class="reference external" href="http://docs.pyro.ai/en/dev/distributions.html#pyro.distributions.torch_distribution.TorchDistributionMixin.to_event">.to_event(n)</a> property where <code class="docutils literal notranslate"><span class="pre">n</span></code> is the number of batch dimensions (from the right) to declare as <em>dependent</em>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>d = Bernoulli(0.5 * torch.ones(3,4)).to_event(1)
assert d.batch_shape == (3,)
assert d.event_shape == (4,)
x = d.sample()
assert x.shape == (3, 4)
assert d.log_prob(x).shape == (3,)
</pre></div>
</div>
</div>
<p>While you work with Pyro programs, keep in mind that samples have shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">event_shape</span></code>, whereas <code class="docutils literal notranslate"><span class="pre">.log_prob(x)</span></code> values have shape <code class="docutils literal notranslate"><span class="pre">batch_shape</span></code>. You’ll need to ensure that <code class="docutils literal notranslate"><span class="pre">batch_shape</span></code> is carefully controlled by either trimming it down with <code class="docutils literal notranslate"><span class="pre">.to_event(n)</span></code> or by declaring dimensions as independent via <code class="docutils literal notranslate"><span class="pre">pyro.plate</span></code>.</p>
</section>
<section id="It-is-always-safe-to-assume-dependence">
<h4>It is always safe to assume dependence<a class="headerlink" href="#It-is-always-safe-to-assume-dependence" title="Permalink to this heading">¶</a></h4>
<p>Often in Pyro we’ll declare some dimensions as dependent even though they are in fact independent, e.g.</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">([</span><span class="mi">10</span><span class="p">])</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">10</span><span class="p">,)</span>
</pre></div>
</div>
<p>This is useful for two reasons: First it allows us to easily swap in a <code class="docutils literal notranslate"><span class="pre">MultivariateNormal</span></code> distribution later. Second it simplifies the code a bit since we don’t need a <code class="docutils literal notranslate"><span class="pre">plate</span></code> (see below) as in</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;x_plate&quot;</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># .expand([10]) is automatic</span>
    <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">10</span><span class="p">,)</span>
</pre></div>
</div>
<p>The difference between these two versions is that the second version with <code class="docutils literal notranslate"><span class="pre">plate</span></code> informs Pyro that it can make use of conditional independence information when estimating gradients, whereas in the first version Pyro must assume they are dependent (even though the normals are in fact conditionally independent). This is analogous to d-separation in graphical models: it is always safe to add edges and assume variables <em>may</em> be dependent (i.e. to widen the model class), but it is unsafe to assume
independence when variables are actually dependent (i.e. narrowing the model class so the true model lies outside of the class, as in mean field). In practice Pyro’s SVI inference algorithm uses reparameterized gradient estimators for <code class="docutils literal notranslate"><span class="pre">Normal</span></code> distributions so both gradient estimators have the same performance.</p>
</section>
</section>
<section id="Declaring-independent-dims-with-plate">
<h3>Declaring independent dims with <code class="docutils literal notranslate"><span class="pre">plate</span></code><a class="headerlink" href="#Declaring-independent-dims-with-plate" title="Permalink to this heading">¶</a></h3>
<p>Pyro models can use the context manager <a class="reference external" href="http://docs.pyro.ai/en/dev/primitives.html#pyro.plate">pyro.plate</a> to declare that certain batch dimensions are independent. Inference algorithms can then take advantage of this independence to e.g. construct lower variance gradient estimators or to enumerate in linear space rather than exponential space. An example of an independent dimension is the index over data in a minibatch: each datum should be independent of all others.</p>
<p>The simplest way to declare a dimension as independent is to declare the rightmost batch dimension as independent via a simple</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;my_plate&quot;</span><span class="p">):</span>
    <span class="c1"># within this context, batch dimension -1 is independent</span>
</pre></div>
</div>
<p>We recommend always providing an optional size argument to aid in debugging shapes</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;my_plate&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">my_data</span><span class="p">)):</span>
    <span class="c1"># within this context, batch dimension -1 is independent</span>
</pre></div>
</div>
<p>Starting with Pyro 0.2 you can additionally nest <code class="docutils literal notranslate"><span class="pre">plates</span></code>, e.g. if you have per-pixel independence:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;x_axis&quot;</span><span class="p">,</span> <span class="mi">320</span><span class="p">):</span>
    <span class="c1"># within this context, batch dimension -1 is independent</span>
    <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;y_axis&quot;</span><span class="p">,</span> <span class="mi">200</span><span class="p">):</span>
        <span class="c1"># within this context, batch dimensions -2 and -1 are independent</span>
</pre></div>
</div>
<p>Note that we always count from the right by using negative indices like -2, -1.</p>
<p>Finally if you want to mix and match <code class="docutils literal notranslate"><span class="pre">plate</span></code>s for e.g. noise that depends only on <code class="docutils literal notranslate"><span class="pre">x</span></code>, some noise that depends only on <code class="docutils literal notranslate"><span class="pre">y</span></code>, and some noise that depends on both, you can declare multiple <code class="docutils literal notranslate"><span class="pre">plates</span></code> and use them as reusable context managers. In this case Pyro cannot automatically allocate a dimension, so you need to provide a <code class="docutils literal notranslate"><span class="pre">dim</span></code> argument (again counting from the right):</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="n">x_axis</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;x_axis&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
<span class="n">y_axis</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;y_axis&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">3</span><span class="p">)</span>
<span class="k">with</span> <span class="n">x_axis</span><span class="p">:</span>
    <span class="c1"># within this context, batch dimension -2 is independent</span>
<span class="k">with</span> <span class="n">y_axis</span><span class="p">:</span>
    <span class="c1"># within this context, batch dimension -3 is independent</span>
<span class="k">with</span> <span class="n">x_axis</span><span class="p">,</span> <span class="n">y_axis</span><span class="p">:</span>
    <span class="c1"># within this context, batch dimensions -3 and -2 are independent</span>
</pre></div>
</div>
<p>Let’s take a closer look at batch sizes within <code class="docutils literal notranslate"><span class="pre">plate</span></code>s.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def model1():
    a = pyro.sample(&quot;a&quot;, Normal(0, 1))
    b = pyro.sample(&quot;b&quot;, Normal(torch.zeros(2), 1).to_event(1))
    with pyro.plate(&quot;c_plate&quot;, 2):
        c = pyro.sample(&quot;c&quot;, Normal(torch.zeros(2), 1))
    with pyro.plate(&quot;d_plate&quot;, 3):
        d = pyro.sample(&quot;d&quot;, Normal(torch.zeros(3,4,5), 1).to_event(2))
    assert a.shape == ()       # batch_shape == ()     event_shape == ()
    assert b.shape == (2,)     # batch_shape == ()     event_shape == (2,)
    assert c.shape == (2,)     # batch_shape == (2,)   event_shape == ()
    assert d.shape == (3,4,5)  # batch_shape == (3,)   event_shape == (4,5)

    x_axis = pyro.plate(&quot;x_axis&quot;, 3, dim=-2)
    y_axis = pyro.plate(&quot;y_axis&quot;, 2, dim=-3)
    with x_axis:
        x = pyro.sample(&quot;x&quot;, Normal(0, 1))
    with y_axis:
        y = pyro.sample(&quot;y&quot;, Normal(0, 1))
    with x_axis, y_axis:
        xy = pyro.sample(&quot;xy&quot;, Normal(0, 1))
        z = pyro.sample(&quot;z&quot;, Normal(0, 1).expand([5]).to_event(1))
    assert x.shape == (3, 1)        # batch_shape == (3,1)     event_shape == ()
    assert y.shape == (2, 1, 1)     # batch_shape == (2,1,1)   event_shape == ()
    assert xy.shape == (2, 3, 1)    # batch_shape == (2,3,1)   event_shape == ()
    assert z.shape == (2, 3, 1, 5)  # batch_shape == (2,3,1)   event_shape == (5,)

test_model(model1, model1, Trace_ELBO())
</pre></div>
</div>
</div>
<p>It is helpful to visualize the <code class="docutils literal notranslate"><span class="pre">.shape</span></code>s of each sample site by aligning them at the boundary between <code class="docutils literal notranslate"><span class="pre">batch_shape</span></code> and <code class="docutils literal notranslate"><span class="pre">event_shape</span></code>: dimensions to the right will be summed out in <code class="docutils literal notranslate"><span class="pre">.log_prob()</span></code> and dimensions to the left will remain.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>batch dims | event dims
-----------+-----------
           |        a = sample(&quot;a&quot;, Normal(0, 1))
           |2       b = sample(&quot;b&quot;, Normal(zeros(2), 1)
           |                        .to_event(1))
           |        with plate(&quot;c&quot;, 2):
          2|            c = sample(&quot;c&quot;, Normal(zeros(2), 1))
           |        with plate(&quot;d&quot;, 3):
          3|4 5         d = sample(&quot;d&quot;, Normal(zeros(3,4,5), 1)
           |                       .to_event(2))
           |
           |        x_axis = plate(&quot;x&quot;, 3, dim=-2)
           |        y_axis = plate(&quot;y&quot;, 2, dim=-3)
           |        with x_axis:
        3 1|            x = sample(&quot;x&quot;, Normal(0, 1))
           |        with y_axis:
      2 1 1|            y = sample(&quot;y&quot;, Normal(0, 1))
           |        with x_axis, y_axis:
      2 3 1|            xy = sample(&quot;xy&quot;, Normal(0, 1))
      2 3 1|5           z = sample(&quot;z&quot;, Normal(0, 1).expand([5])
           |                       .to_event(1))
</pre></div>
</div>
<p>To examine the shapes of sample sites in a program automatically, you can trace the program and use the <a class="reference external" href="http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.Trace.format_shapes">Trace.format_shapes()</a> method, which prints three shapes for each sample site: the distribution shape (both <code class="docutils literal notranslate"><span class="pre">site[&quot;fn&quot;].batch_shape</span></code> and <code class="docutils literal notranslate"><span class="pre">site[&quot;fn&quot;].event_shape</span></code>), the value shape (<code class="docutils literal notranslate"><span class="pre">site[&quot;value&quot;].shape</span></code>), and if log probability has been computed also the <code class="docutils literal notranslate"><span class="pre">log_prob</span></code> shape (<code class="docutils literal notranslate"><span class="pre">site[&quot;log_prob&quot;].shape</span></code>):</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>trace = poutine.trace(model1).get_trace()
trace.compute_log_prob()  # optional, but allows printing of log_prob shapes
print(trace.format_shapes())
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Trace Shapes:
 Param Sites:
Sample Sites:
       a dist       |
        value       |
     log_prob       |
       b dist       | 2
        value       | 2
     log_prob       |
 c_plate dist       |
        value     2 |
     log_prob       |
       c dist     2 |
        value     2 |
     log_prob     2 |
 d_plate dist       |
        value     3 |
     log_prob       |
       d dist     3 | 4 5
        value     3 | 4 5
     log_prob     3 |
  x_axis dist       |
        value     3 |
     log_prob       |
  y_axis dist       |
        value     2 |
     log_prob       |
       x dist   3 1 |
        value   3 1 |
     log_prob   3 1 |
       y dist 2 1 1 |
        value 2 1 1 |
     log_prob 2 1 1 |
      xy dist 2 3 1 |
        value 2 3 1 |
     log_prob 2 3 1 |
       z dist 2 3 1 | 5
        value 2 3 1 | 5
     log_prob 2 3 1 |
</pre></div></div>
</div>
</section>
<section id="Subsampling-tensors-inside-a-plate">
<h3>Subsampling tensors inside a <code class="docutils literal notranslate"><span class="pre">plate</span></code><a class="headerlink" href="#Subsampling-tensors-inside-a-plate" title="Permalink to this heading">¶</a></h3>
<p>One of the main uses of <a class="reference external" href="http://docs.pyro.ai/en/dev/primitives.html#pyro.plate">plate</a> is to subsample data. This is possible within a <code class="docutils literal notranslate"><span class="pre">plate</span></code> because data are conditionally independent, so the expected value of the loss on, say, half the data should be half the expected loss on the full data.</p>
<p>To subsample data, you need to inform Pyro of both the original data size and the subsample size; Pyro will then choose a random subset of data and yield the set of indices.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>data = torch.arange(100.)

def model2():
    mean = pyro.param(&quot;mean&quot;, torch.zeros(len(data)))
    with pyro.plate(&quot;data&quot;, len(data), subsample_size=10) as ind:
        assert len(ind) == 10    # ind is a LongTensor that indexes the subsample.
        batch = data[ind]        # Select a minibatch of data.
        mean_batch = mean[ind]   # Take care to select the relevant per-datum parameters.
        # Do stuff with batch:
        x = pyro.sample(&quot;x&quot;, Normal(mean_batch, 1), obs=batch)
        assert len(x) == 10

test_model(model2, guide=lambda: None, loss=Trace_ELBO())
</pre></div>
</div>
</div>
</section>
<section id="Broadcasting-to-allow-parallel-enumeration">
<h3>Broadcasting to allow parallel enumeration<a class="headerlink" href="#Broadcasting-to-allow-parallel-enumeration" title="Permalink to this heading">¶</a></h3>
<p>Pyro 0.2 introduces the ability to enumerate discrete latent variables in parallel. This can significantly reduce the variance of gradient estimators when learning a posterior via <a class="reference external" href="http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.svi.SVI">SVI</a>.</p>
<p>To use parallel enumeration, Pyro needs to allocate tensor dimension that it can use for enumeration. To avoid conflicting with other dimensions that we want to use for <code class="docutils literal notranslate"><span class="pre">plate</span></code>s, we need to declare a budget of the maximum number of tensor dimensions we’ll use. This budget is called <code class="docutils literal notranslate"><span class="pre">max_plate_nesting</span></code> and is an argument to <a class="reference external" href="http://docs.pyro.ai/en/dev/inference_algos.html">SVI</a> (the argument is simply passed through to
<a class="reference external" href="http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.traceenum_elbo.TraceEnum_ELBO">TraceEnum_ELBO</a>). Usually Pyro can determine this budget on its own (it runs the <code class="docutils literal notranslate"><span class="pre">(model,guide)</span></code> pair once and record what happens), but in case of dynamic model structure you may need to declare <code class="docutils literal notranslate"><span class="pre">max_plate_nesting</span></code> manually.</p>
<p>To understand <code class="docutils literal notranslate"><span class="pre">max_plate_nesting</span></code> and how Pyro allocates dimensions for enumeration, let’s revisit <code class="docutils literal notranslate"><span class="pre">model1()</span></code> from above. This time we’ll map out three types of dimensions: enumeration dimensions on the left (Pyro takes control of these), batch dimensions in the middle, and event dimensions on the right.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>      max_plate_nesting = 3
           |&lt;---&gt;|
enumeration|batch|event
-----------+-----+-----
           |. . .|      a = sample(&quot;a&quot;, Normal(0, 1))
           |. . .|2     b = sample(&quot;b&quot;, Normal(zeros(2), 1)
           |     |                      .to_event(1))
           |     |      with plate(&quot;c&quot;, 2):
           |. . 2|          c = sample(&quot;c&quot;, Normal(zeros(2), 1))
           |     |      with plate(&quot;d&quot;, 3):
           |. . 3|4 5       d = sample(&quot;d&quot;, Normal(zeros(3,4,5), 1)
           |     |                     .to_event(2))
           |     |
           |     |      x_axis = plate(&quot;x&quot;, 3, dim=-2)
           |     |      y_axis = plate(&quot;y&quot;, 2, dim=-3)
           |     |      with x_axis:
           |. 3 1|          x = sample(&quot;x&quot;, Normal(0, 1))
           |     |      with y_axis:
           |2 1 1|          y = sample(&quot;y&quot;, Normal(0, 1))
           |     |      with x_axis, y_axis:
           |2 3 1|          xy = sample(&quot;xy&quot;, Normal(0, 1))
           |2 3 1|5         z = sample(&quot;z&quot;, Normal(0, 1).expand([5]))
           |     |                     .to_event(1))
</pre></div>
</div>
<p>Note that it is safe to overprovision <code class="docutils literal notranslate"><span class="pre">max_plate_nesting=4</span></code> but we cannot underprovision <code class="docutils literal notranslate"><span class="pre">max_plate_nesting=2</span></code> (or Pyro will error). Let’s see how this works in practice.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>@config_enumerate
def model3():
    p = pyro.param(&quot;p&quot;, torch.arange(6.) / 6)
    locs = pyro.param(&quot;locs&quot;, torch.tensor([-1., 1.]))

    a = pyro.sample(&quot;a&quot;, Categorical(torch.ones(6) / 6))
    b = pyro.sample(&quot;b&quot;, Bernoulli(p[a]))  # Note this depends on a.
    with pyro.plate(&quot;c_plate&quot;, 4):
        c = pyro.sample(&quot;c&quot;, Bernoulli(0.3))
        with pyro.plate(&quot;d_plate&quot;, 5):
            d = pyro.sample(&quot;d&quot;, Bernoulli(0.4))
            e_loc = locs[d.long()].unsqueeze(-1)
            e_scale = torch.arange(1., 8.)
            e = pyro.sample(&quot;e&quot;, Normal(e_loc, e_scale)
                            .to_event(1))  # Note this depends on d.

    #                   enumerated|batch|event dims
    assert a.shape == (         6, 1, 1   )  # Six enumerated values of the Categorical.
    assert b.shape == (      2, 1, 1, 1   )  # Two enumerated Bernoullis, unexpanded.
    assert c.shape == (   2, 1, 1, 1, 1   )  # Only two Bernoullis, unexpanded.
    assert d.shape == (2, 1, 1, 1, 1, 1   )  # Only two Bernoullis, unexpanded.
    assert e.shape == (2, 1, 1, 1, 5, 4, 7)  # This is sampled and depends on d.

    assert e_loc.shape   == (2, 1, 1, 1, 1, 1, 1,)
    assert e_scale.shape == (                  7,)

test_model(model3, model3, TraceEnum_ELBO(max_plate_nesting=2))
</pre></div>
</div>
</div>
<p>Let’s take a closer look at those dimensions. First note that Pyro allocates enumeration dims starting from the right at <code class="docutils literal notranslate"><span class="pre">max_plate_nesting</span></code>: Pyro allocates dim -3 to enumerate <code class="docutils literal notranslate"><span class="pre">a</span></code>, then dim -4 to enumerate <code class="docutils literal notranslate"><span class="pre">b</span></code>, then dim -5 to enumerate <code class="docutils literal notranslate"><span class="pre">c</span></code>, and finally dim -6 to enumerate <code class="docutils literal notranslate"><span class="pre">d</span></code>. Next note that samples only have extent (size &gt; 1) in the new enumeration dimension. This helps keep tensors small and computation cheap. (Note that the <code class="docutils literal notranslate"><span class="pre">log_prob</span></code> shape will be broadcast up to contain both
enumeratin shape and batch shape, so e.g. <code class="docutils literal notranslate"><span class="pre">trace.nodes['d']['log_prob'].shape</span> <span class="pre">==</span> <span class="pre">(2,</span> <span class="pre">1,</span> <span class="pre">1,</span> <span class="pre">1,</span> <span class="pre">5,</span> <span class="pre">4)</span></code>.)</p>
<p>We can draw a similar map of the tensor dimensions:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>     max_plate_nesting = 2
            |&lt;-&gt;|
enumeration batch event
------------|---|-----
           6|1 1|     a = pyro.sample(&quot;a&quot;, Categorical(torch.ones(6) / 6))
         2 1|1 1|     b = pyro.sample(&quot;b&quot;, Bernoulli(p[a]))
            |   |     with pyro.plate(&quot;c_plate&quot;, 4):
       2 1 1|1 1|         c = pyro.sample(&quot;c&quot;, Bernoulli(0.3))
            |   |         with pyro.plate(&quot;d_plate&quot;, 5):
     2 1 1 1|1 1|             d = pyro.sample(&quot;d&quot;, Bernoulli(0.4))
     2 1 1 1|1 1|1            e_loc = locs[d.long()].unsqueeze(-1)
            |   |7            e_scale = torch.arange(1., 8.)
     2 1 1 1|5 4|7            e = pyro.sample(&quot;e&quot;, Normal(e_loc, e_scale)
            |   |                             .to_event(1))
</pre></div>
</div>
<p>To automatically examine this model with enumeration semantics, we can create an enumerated trace and then use <a class="reference external" href="http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.Trace.format_shapes">Trace.format_shapes()</a>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>trace = poutine.trace(poutine.enum(model3, first_available_dim=-3)).get_trace()
trace.compute_log_prob()  # optional, but allows printing of log_prob shapes
print(trace.format_shapes())
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Trace Shapes:
 Param Sites:
            p             6
         locs             2
Sample Sites:
       a dist             |
        value       6 1 1 |
     log_prob       6 1 1 |
       b dist       6 1 1 |
        value     2 1 1 1 |
     log_prob     2 6 1 1 |
 c_plate dist             |
        value           4 |
     log_prob             |
       c dist           4 |
        value   2 1 1 1 1 |
     log_prob   2 1 1 1 4 |
 d_plate dist             |
        value           5 |
     log_prob             |
       d dist         5 4 |
        value 2 1 1 1 1 1 |
     log_prob 2 1 1 1 5 4 |
       e dist 2 1 1 1 5 4 | 7
        value 2 1 1 1 5 4 | 7
     log_prob 2 1 1 1 5 4 |
</pre></div></div>
</div>
<section id="Writing-parallelizable-code">
<h4>Writing parallelizable code<a class="headerlink" href="#Writing-parallelizable-code" title="Permalink to this heading">¶</a></h4>
<p>It can be tricky to write Pyro models that correctly handle parallelized sample sites. Two tricks help: <a class="reference external" href="http://pytorch.org/docs/master/notes/broadcasting.html">broadcasting</a> and <a class="reference external" href="http://python-reference.readthedocs.io/en/dev/docs/brackets/ellipsis.html">ellipsis slicing</a>. Let’s look at a contrived model to see how these work in practice. Our aim is to write a model that works both with and without enumeration.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>width = 8
height = 10
sparse_pixels = torch.LongTensor([[3, 2], [3, 5], [3, 9], [7, 1]])
enumerated = None  # set to either True or False below

def fun(observe):
    p_x = pyro.param(&quot;p_x&quot;, torch.tensor(0.1), constraint=constraints.unit_interval)
    p_y = pyro.param(&quot;p_y&quot;, torch.tensor(0.1), constraint=constraints.unit_interval)
    x_axis = pyro.plate(&#39;x_axis&#39;, width, dim=-2)
    y_axis = pyro.plate(&#39;y_axis&#39;, height, dim=-1)

    # Note that the shapes of these sites depend on whether Pyro is enumerating.
    with x_axis:
        x_active = pyro.sample(&quot;x_active&quot;, Bernoulli(p_x))
    with y_axis:
        y_active = pyro.sample(&quot;y_active&quot;, Bernoulli(p_y))
    if enumerated:
        assert x_active.shape  == (2, 1, 1)
        assert y_active.shape  == (2, 1, 1, 1)
    else:
        assert x_active.shape  == (width, 1)
        assert y_active.shape  == (height,)

    # The first trick is to broadcast. This works with or without enumeration.
    p = 0.1 + 0.5 * x_active * y_active
    if enumerated:
        assert p.shape == (2, 2, 1, 1)
    else:
        assert p.shape == (width, height)
    dense_pixels = p.new_zeros(broadcast_shape(p.shape, (width, height)))

    # The second trick is to index using ellipsis slicing.
    # This allows Pyro to add arbitrary dimensions on the left.
    for x, y in sparse_pixels:
        dense_pixels[..., x, y] = 1
    if enumerated:
        assert dense_pixels.shape == (2, 2, width, height)
    else:
        assert dense_pixels.shape == (width, height)

    with x_axis, y_axis:
        if observe:
            pyro.sample(&quot;pixels&quot;, Bernoulli(p), obs=dense_pixels)

def model4():
    fun(observe=True)

def guide4():
    fun(observe=False)

# Test without enumeration.
enumerated = False
test_model(model4, guide4, Trace_ELBO())

# Test with enumeration.
enumerated = True
test_model(model4, config_enumerate(guide4, &quot;parallel&quot;),
           TraceEnum_ELBO(max_plate_nesting=2))
</pre></div>
</div>
</div>
</section>
<section id="Automatic-broadcasting-inside-pyro.plate">
<h4>Automatic broadcasting inside pyro.plate<a class="headerlink" href="#Automatic-broadcasting-inside-pyro.plate" title="Permalink to this heading">¶</a></h4>
<p>Note that in all our model/guide specifications, we have relied on <a class="reference external" href="http://docs.pyro.ai/en/dev/primitives.html#pyro.plate">pyro.plate</a> to automatically expand sample shapes to satisfy the constraints on batch shape enforced by <code class="docutils literal notranslate"><span class="pre">pyro.sample</span></code> statements. However this broadcasting is equivalent to hand-annotated <code class="docutils literal notranslate"><span class="pre">.expand()</span></code> statements.</p>
<p>We will demonstrate this using <code class="docutils literal notranslate"><span class="pre">model4</span></code> from the <a class="reference external" href="#Writing-parallelizable-code">previous section</a>. Note the following changes to the code from earlier:</p>
<ul class="simple">
<li><p>For the purpose of this example, we will only consider “parallel” enumeration, but broadcasting should work as expected without enumeration or with “sequential” enumeration.</p></li>
<li><p>We have separated out the sampling function which returns the tensors corresponding to the active pixels. Modularizing the model code into components is a common practice, and helps with maintainability of large models.</p></li>
<li><p>We would also like to use the <code class="docutils literal notranslate"><span class="pre">pyro.plate</span></code> construct to parallelize the ELBO estimator over <a class="reference external" href="http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.elbo.ELBO">num_particles</a>. This is done by wrapping the contents of model/guide inside an outermost <code class="docutils literal notranslate"><span class="pre">pyro.plate</span></code> context.</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>num_particles = 100  # Number of samples for the ELBO estimator
width = 8
height = 10
sparse_pixels = torch.LongTensor([[3, 2], [3, 5], [3, 9], [7, 1]])

def sample_pixel_locations_no_broadcasting(p_x, p_y, x_axis, y_axis):
    with x_axis:
        x_active = pyro.sample(&quot;x_active&quot;, Bernoulli(p_x).expand([num_particles, width, 1]))
    with y_axis:
        y_active = pyro.sample(&quot;y_active&quot;, Bernoulli(p_y).expand([num_particles, 1, height]))
    return x_active, y_active

def sample_pixel_locations_full_broadcasting(p_x, p_y, x_axis, y_axis):
    with x_axis:
        x_active = pyro.sample(&quot;x_active&quot;, Bernoulli(p_x))
    with y_axis:
        y_active = pyro.sample(&quot;y_active&quot;, Bernoulli(p_y))
    return x_active, y_active

def sample_pixel_locations_partial_broadcasting(p_x, p_y, x_axis, y_axis):
    with x_axis:
        x_active = pyro.sample(&quot;x_active&quot;, Bernoulli(p_x).expand([width, 1]))
    with y_axis:
        y_active = pyro.sample(&quot;y_active&quot;, Bernoulli(p_y).expand([height]))
    return x_active, y_active

def fun(observe, sample_fn):
    p_x = pyro.param(&quot;p_x&quot;, torch.tensor(0.1), constraint=constraints.unit_interval)
    p_y = pyro.param(&quot;p_y&quot;, torch.tensor(0.1), constraint=constraints.unit_interval)
    x_axis = pyro.plate(&#39;x_axis&#39;, width, dim=-2)
    y_axis = pyro.plate(&#39;y_axis&#39;, height, dim=-1)

    with pyro.plate(&quot;num_particles&quot;, 100, dim=-3):
        x_active, y_active = sample_fn(p_x, p_y, x_axis, y_axis)
        # Indices corresponding to &quot;parallel&quot; enumeration are appended
        # to the left of the &quot;num_particles&quot; plate dim.
        assert x_active.shape  == (2, 1, 1, 1)
        assert y_active.shape  == (2, 1, 1, 1, 1)
        p = 0.1 + 0.5 * x_active * y_active
        assert p.shape == (2, 2, 1, 1, 1)

        dense_pixels = p.new_zeros(broadcast_shape(p.shape, (width, height)))
        for x, y in sparse_pixels:
            dense_pixels[..., x, y] = 1
        assert dense_pixels.shape == (2, 2, 1, width, height)

        with x_axis, y_axis:
            if observe:
                pyro.sample(&quot;pixels&quot;, Bernoulli(p), obs=dense_pixels)

def test_model_with_sample_fn(sample_fn):
    def model():
        fun(observe=True, sample_fn=sample_fn)

    @config_enumerate
    def guide():
        fun(observe=False, sample_fn=sample_fn)

    test_model(model, guide, TraceEnum_ELBO(max_plate_nesting=3))

test_model_with_sample_fn(sample_pixel_locations_no_broadcasting)
test_model_with_sample_fn(sample_pixel_locations_full_broadcasting)
test_model_with_sample_fn(sample_pixel_locations_partial_broadcasting)
</pre></div>
</div>
</div>
<p>In the first sampling function, we had to do some manual book-keeping and expand the <code class="docutils literal notranslate"><span class="pre">Bernoulli</span></code> distribution’s batch shape to account for the conditionally independent dimensions added by the <code class="docutils literal notranslate"><span class="pre">pyro.plate</span></code> contexts. In particular, note how <code class="docutils literal notranslate"><span class="pre">sample_pixel_locations</span></code> needs knowledge of <code class="docutils literal notranslate"><span class="pre">num_particles</span></code>, <code class="docutils literal notranslate"><span class="pre">width</span></code> and <code class="docutils literal notranslate"><span class="pre">height</span></code> and is accessing these variables from the global scope, which is not ideal.</p>
<ul class="simple">
<li><p>The second argument to <code class="docutils literal notranslate"><span class="pre">pyro.plate</span></code>, i.e. the optional <code class="docutils literal notranslate"><span class="pre">size</span></code> argument needs to be provided for implicit broadasting, so that it can infer the batch shape requirement for each of the sample sites.</p></li>
<li><p>The existing <code class="docutils literal notranslate"><span class="pre">batch_shape</span></code> of the sample site must be broadcastable with the size of the <code class="docutils literal notranslate"><span class="pre">pyro.plate</span></code> contexts. In our particular example, <code class="docutils literal notranslate"><span class="pre">Bernoulli(p_x)</span></code> has an empty batch shape which is universally broadcastable.</p></li>
</ul>
<p>Note how simple it is to achieve parallelization via tensorized operations using <code class="docutils literal notranslate"><span class="pre">pyro.plate</span></code>! <code class="docutils literal notranslate"><span class="pre">pyro.plate</span></code> also helps in code modularization because model components can be written agnostic of the <code class="docutils literal notranslate"><span class="pre">plate</span></code> contexts in which they may subsequently get embedded in.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="bayesian_regression_ii.html" class="btn btn-neutral float-left" title="Bayesian Regression - Inference Algorithms (Part 2)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="modules.html" class="btn btn-neutral float-right" title="Modules in Pyro" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Pyro Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>