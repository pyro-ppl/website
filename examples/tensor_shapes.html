<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>&lt;no title&gt; &mdash; Pyro Tutorials 1.8.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/pyro.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="&lt;no title&gt;" href="modules.html" />
    <link rel="prev" title="&lt;no title&gt;" href="bayesian_regression_ii.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html">
            <img src="_static/pyro_logo_wide.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                1.8.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Practical Pyro and PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="svi_horovod.html">Example: distributed training via Horovod</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deep Generative Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cevae.html">Example: Causal Effect VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_gamma.html">Example: Sparse Gamma Deep Exponential Family</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Discrete Latent Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="toy_mixture_model_discrete_enumeration.html">Example: Toy Mixture Model With Discrete Enumeration</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm.html">Example: Hidden Markov Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="capture_recapture.html">Example: Capture-Recapture Models (CJS Models)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mixed_hmm.html">Example: hierarchical mixed-effect hidden Markov models</a></li>
<li class="toctree-l1"><a class="reference internal" href="einsum.html">Example: Discrete Factor Graph Inference with Plated Einsum</a></li>
<li class="toctree-l1"><a class="reference internal" href="lda.html">Example: Amortized Latent Dirichlet Allocation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Customizing Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="neutra.html">Example: Neural MCMC with NeuTraReparam</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_regression.html">Example: Sparse Bayesian Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="autoname_examples.html">Example: reducing boilerplate with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.autoname</span></code></a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Time Series</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="forecast_simple.html">Multivariate Forecasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="timeseries.html">Example: Gaussian Process Time Series Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Gaussian Processes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dkl.html">Example: Deep Kernel Learning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Epidemiology</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="epi_sir.html">Example: Univariate epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="epi_regional.html">Example: Regional epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="sir_hmc.html">Example: Epidemiological inference via HMC</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Biological sequences</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mue_profile.html">Example: Constant + MuE (Profile HMM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mue_factor.html">Example: Probabilistic PCA + MuE (FactorMuE)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Inference Algorithms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="baseball.html">Example: analyzing baseball stats with MCMC</a></li>
<li class="toctree-l1"><a class="reference internal" href="mcmc.html">Example: Inference with Markov Chain Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="lkj.html">Example: MCMC with an LKJ prior over covariances</a></li>
<li class="toctree-l1"><a class="reference internal" href="smcfilter.html">Example: Sequential Monte Carlo Filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="inclined_plane.html">Example: importance sampling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Understanding Pyro's Internals</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="minipyro.html">Mini-Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm_funsor.html">Example: hidden Markov models with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">pyroapi</span></code></a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pyro Tutorials</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>&lt;no title&gt;</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/tensor_shapes.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<dl>
<dt>{</dt><dd><dl>
<dt>“cells”: [</dt><dd><dl>
<dt>{</dt><dd><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“# Tensor shapes in Pyron”,
“n”,
“This tutorial introduces Pyro’s organization of tensor dimensions. n”,
“Before starting, you should familiarize yourself with [PyTorch broadcasting semantics](<a class="reference external" href="http://pytorch.org/docs/master/notes/broadcasting.html">http://pytorch.org/docs/master/notes/broadcasting.html</a>).  n”,
“After this tutorial, you may want to also read about [enumeration](<a class="reference external" href="http://pyro.ai/examples/enumeration.html).n">http://pyro.ai/examples/enumeration.html).n</a>”,
“n”,
“You may also find it useful to read Eric J. Ma’s post [Reasoning about Shapes and Probability Distributions](<a class="reference external" href="https://ericmjl.github.io/blog/2019/5/29/reasoning-about-shapes-and-probability-distributions/">https://ericmjl.github.io/blog/2019/5/29/reasoning-about-shapes-and-probability-distributions/</a>). n”,
“While this post is specifically about TensorFlow Probability, many of the same concepts apply.n”,
“n”,
“#### Summary:n”,
“- Tensors broadcast by aligning on the right: <cite>torch.ones(3,4,5) + torch.ones(5)</cite>.n”,
“- Distribution <cite>.sample().shape == batch_shape + event_shape</cite>.n”,
“- Distribution <cite>.log_prob(x).shape == batch_shape</cite> (but not <cite>event_shape</cite>!).n”,
“- Use <cite>.expand()</cite> to draw a batch of samples, or rely on <cite>plate</cite> to expand automatically.n”,
“- Use <cite>my_dist.to_event(1)</cite> to declare a dimension as dependent.n”,
“- Use <cite>with pyro.plate(‘name’, size):</cite> to declare a dimension as conditionally independent.n”,
“- All dimensions must be declared either dependent or conditionally independent.n”,
“- Try to support batching on the left. This lets Pyro auto-parallelize.n”,
”  - use negative indices like <cite>x.sum(-1)</cite> rather than <cite>x.sum(2)</cite>n”,
”  - use ellipsis notation like <cite>pixel = image[…, i, j]</cite>n”,
”  - use [Vindex](<a class="reference external" href="http://docs.pyro.ai/en/dev/ops.html#pyro.ops.indexing.Vindex">http://docs.pyro.ai/en/dev/ops.html#pyro.ops.indexing.Vindex</a>) if <cite>i,j</cite> are enumerated, <cite>pixel = Vindex(image)[…, i, j]</cite>n”,
“- When using <cite>pyro.plate</cite>’s automatic subsampling, be sure to subsample your <a class="reference external" href="data:n">data:n</a>”,
”  - Either manually subample by capturing the index <cite>with pyro.plate(…) as i: …</cite>n”,
”  - or automatically subsample via <cite>batch = pyro.subsample(data, event_dim=…)</cite>.n”,
“- When debugging, examine all shapes in a trace using [Trace.format_shapes()](<a class="reference external" href="http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.Trace.format_shapes).n">http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.Trace.format_shapes).n</a>”,
”  n”,
“#### Table of Contentsn”,
“- [Distribution shapes](#Distributions-shapes:-batch_shape-and-event_shape)n”,
”  - [Examples](#Examples)n”,
”  - [Reshaping distributions](#Reshaping-distributions)n”,
”  - [It is always safe to assume dependence](#It-is-always-safe-to-assume-dependence)n”,
“- [Declaring independence with plate](#Declaring-independent-dims-with-plate)n”,
“- [Subsampling inside plate](#Subsampling-tensors-inside-a-plate)n”,
“- [Broadcasting to allow Parallel Enumeration](#Broadcasting-to-allow-parallel-enumeration)n”,
”  - [Writing parallelizable code](#Writing-parallelizable-code)n”,
”  - [Automatic broadcasting inside pyro.plate](#Automatic-broadcasting-inside-pyro-plate)n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 1,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“import osn”,
“import torchn”,
“import pyron”,
“from torch.distributions import constraintsn”,
“from pyro.distributions import Bernoulli, Categorical, MultivariateNormal, Normaln”,
“from pyro.distributions.util import broadcast_shapen”,
“from pyro.infer import Trace_ELBO, TraceEnum_ELBO, config_enumeraten”,
“import pyro.poutine as poutinen”,
“from pyro.optim import Adamn”,
“n”,
“smoke_test = (‘CI’ in os.environ)n”,
“assert pyro.__version__.startswith(‘1.8.1’)n”,
“n”,
“# We’ll ue this helper to check our models are correct.n”,
“def test_model(model, guide, loss):n”,
”    pyro.clear_param_store()n”,
”    loss.loss(model, guide)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Distributions shapes: <cite>batch_shape</cite> and <cite>event_shape</cite> &lt;a class=&quot;anchor&quot; id=&quot;Distributions-shapes:-batch_shape-and-event_shape&quot;&gt;&lt;/a&gt;n”,
“n”,
“PyTorch <cite>Tensor`s have a single `.shape</cite> attribute, but <cite>Distribution`s have two shape attributions with special meaning: `.batch_shape</cite> and <cite>.event_shape</cite>. These two combine to define the total shape of a samplen”,
“<code class="docutils literal notranslate"><span class="pre">`py\n&quot;,</span>
<span class="pre">&quot;x</span> <span class="pre">=</span> <span class="pre">d.sample()\n&quot;,</span>
<span class="pre">&quot;assert</span> <span class="pre">x.shape</span> <span class="pre">==</span> <span class="pre">d.batch_shape</span> <span class="pre">+</span> <span class="pre">d.event_shape\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“Indices over <cite>.batch_shape</cite> denote conditionally independent random variables, whereas indices over <cite>.event_shape</cite> denote dependent random variables (ie one draw from a distribution). Because the dependent random variables define probability together, the <cite>.log_prob()</cite> method only produces a single number for each event of shape <cite>.event_shape</cite>. Thus the total shape of <cite>.log_prob()</cite> is <cite>.batch_shape</cite>:n”,
“<code class="docutils literal notranslate"><span class="pre">`py\n&quot;,</span>
<span class="pre">&quot;assert</span> <span class="pre">d.log_prob(x).shape</span> <span class="pre">==</span> <span class="pre">d.batch_shape\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“Note that the <cite>Distribution.sample()</cite> method also takes a <cite>sample_shape</cite> parameter that indexes over independent identically distributed (iid) random varables, so thatn”,
“<code class="docutils literal notranslate"><span class="pre">`py\n&quot;,</span>
<span class="pre">&quot;x2</span> <span class="pre">=</span> <span class="pre">d.sample(sample_shape)\n&quot;,</span>
<span class="pre">&quot;assert</span> <span class="pre">x2.shape</span> <span class="pre">==</span> <span class="pre">sample_shape</span> <span class="pre">+</span> <span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">event_shape\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“In summaryn”,
“<code class="docutils literal notranslate"><span class="pre">`\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">iid</span>&#160;&#160;&#160;&#160; <span class="pre">|</span> <span class="pre">independent</span> <span class="pre">|</span> <span class="pre">dependent\n&quot;,</span>
<span class="pre">&quot;------+--------------+-------------+------------\n&quot;,</span>
<span class="pre">&quot;shape</span> <span class="pre">=</span> <span class="pre">sample_shape</span> <span class="pre">+</span> <span class="pre">batch_shape</span> <span class="pre">+</span> <span class="pre">event_shape\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“For example univariate distributions have empty event shape (because each number is an independent event). Distributions over vectors like <cite>MultivariateNormal</cite> have <cite>len(event_shape) == 1</cite>. Distributions over matrices like <cite>InverseWishart</cite> have <cite>len(event_shape) == 2</cite>.n”,
“n”,
“### Examples &lt;a class=&quot;anchor&quot; id=&quot;Examples&quot;&gt;&lt;/a&gt;n”,
“n”,
“The simplest distribution shape is a single univariate distribution.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 2,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“d = Bernoulli(0.5)n”,
“assert d.batch_shape == ()n”,
“assert d.event_shape == ()n”,
“x = d.sample()n”,
“assert x.shape == ()n”,
“assert d.log_prob(x).shape == ()”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Distributions can be batched by passing in batched parameters.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 3,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“d = Bernoulli(0.5 * torch.ones(3,4))n”,
“assert d.batch_shape == (3, 4)n”,
“assert d.event_shape == ()n”,
“x = d.sample()n”,
“assert x.shape == (3, 4)n”,
“assert d.log_prob(x).shape == (3, 4)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Another way to batch distributions is via the <cite>.expand()</cite> method. This only works if n”,
“parameters are identical along the leftmost dimensions.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 4,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“d = Bernoulli(torch.tensor([0.1, 0.2, 0.3, 0.4])).expand([3, 4])n”,
“assert d.batch_shape == (3, 4)n”,
“assert d.event_shape == ()n”,
“x = d.sample()n”,
“assert x.shape == (3, 4)n”,
“assert d.log_prob(x).shape == (3, 4)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Multivariate distributions have nonempty <cite>.event_shape</cite>. For these distributions, the shapes of <cite>.sample()</cite> and <cite>.log_prob(x)</cite> differ:”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 5,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“d = MultivariateNormal(torch.zeros(3), torch.eye(3, 3))n”,
“assert d.batch_shape == ()n”,
“assert d.event_shape == (3,)n”,
“x = d.sample()n”,
“assert x.shape == (3,)            # == batch_shape + event_shapen”,
“assert d.log_prob(x).shape == ()  # == batch_shape”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“### Reshaping distributions &lt;a class=&quot;anchor&quot; id=&quot;Reshaping-distributions&quot;&gt;&lt;/a&gt;n”,
“n”,
“In Pyro you can treat a univariate distribution as multivariate by calling the [.to_event(n)](<a class="reference external" href="http://docs.pyro.ai/en/dev/distributions.html#pyro.distributions.torch_distribution.TorchDistributionMixin.to_event">http://docs.pyro.ai/en/dev/distributions.html#pyro.distributions.torch_distribution.TorchDistributionMixin.to_event</a>) property where <cite>n</cite> is the number of batch dimensions (from the right) to declare as <em>dependent</em>.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 6,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“d = Bernoulli(0.5 * torch.ones(3,4)).to_event(1)n”,
“assert d.batch_shape == (3,)n”,
“assert d.event_shape == (4,)n”,
“x = d.sample()n”,
“assert x.shape == (3, 4)n”,
“assert d.log_prob(x).shape == (3,)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“While you work with Pyro programs, keep in mind that samples have shape <cite>batch_shape + event_shape</cite>, whereas <cite>.log_prob(x)</cite> values have shape <cite>batch_shape</cite>. You’ll need to ensure that <cite>batch_shape</cite> is carefully controlled by either trimming it down with <cite>.to_event(n)</cite> or by declaring dimensions as independent via <cite>pyro.plate</cite>.n”,
“n”,
“### It is always safe to assume dependence &lt;a class=&quot;anchor&quot; id=&quot;It-is-always-safe-to-assume-dependence&quot;&gt;&lt;/a&gt;n”,
“n”,
“Often in Pyro we’ll declare some dimensions as dependent even though they are in fact independent, e.g.n”,
“<code class="docutils literal notranslate"><span class="pre">`py\n&quot;,</span>
<span class="pre">&quot;x</span> <span class="pre">=</span> <span class="pre">pyro.sample(\&quot;x\&quot;,</span> <span class="pre">Normal(0,</span> <span class="pre">1).expand([10]).to_event(1))\n&quot;,</span>
<span class="pre">&quot;assert</span> <span class="pre">x.shape</span> <span class="pre">==</span> <span class="pre">(10,)\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“This is useful for two reasons: First it allows us to easily swap in a <cite>MultivariateNormal</cite> distribution later. Second it simplifies the code a bit since we don’t need a <cite>plate</cite> (see below) as inn”,
“<code class="docutils literal notranslate"><span class="pre">`py\n&quot;,</span>
<span class="pre">&quot;with</span> <span class="pre">pyro.plate(\&quot;x_plate\&quot;,</span> <span class="pre">10):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">x</span> <span class="pre">=</span> <span class="pre">pyro.sample(\&quot;x\&quot;,</span> <span class="pre">Normal(0,</span> <span class="pre">1))</span>&#160; <span class="pre">#</span> <span class="pre">.expand([10])</span> <span class="pre">is</span> <span class="pre">automatic\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">assert</span> <span class="pre">x.shape</span> <span class="pre">==</span> <span class="pre">(10,)\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“The difference between these two versions is that the second version with <cite>plate</cite> informs Pyro that it can make use of conditional independence information when estimating gradients, whereas in the first version Pyro must assume they are dependent (even though the normals are in fact conditionally independent). This is analogous to d-separation in graphical models: it is always safe to add edges and assume variables <em>may</em> be dependent (i.e. to widen the model class), but it is unsafe to assume independence when variables are actually dependent (i.e. narrowing the model class so the true model lies outside of the class, as in mean field). In practice Pyro’s SVI inference algorithm uses reparameterized gradient estimators for <cite>Normal</cite> distributions so both gradient estimators have the same performance.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Declaring independent dims with <cite>plate</cite> &lt;a class=&quot;anchor&quot; id=&quot;Declaring-independent-dims-with-plate&quot;&gt;&lt;/a&gt;n”,
“n”,
“Pyro models can use the context manager [pyro.plate](<a class="reference external" href="http://docs.pyro.ai/en/dev/primitives.html#pyro.plate">http://docs.pyro.ai/en/dev/primitives.html#pyro.plate</a>) to declare that certain batch dimensions are independent. Inference algorithms can then take advantage of this independence to e.g. construct lower variance gradient estimators or to enumerate in linear space rather than exponential space. An example of an independent dimension is the index over data in a minibatch: each datum should be independent of all others.n”,
“n”,
“The simplest way to declare a dimension as independent is to declare the rightmost batch dimension as independent via a simplen”,
“<code class="docutils literal notranslate"><span class="pre">`py\n&quot;,</span>
<span class="pre">&quot;with</span> <span class="pre">pyro.plate(\&quot;my_plate\&quot;):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">within</span> <span class="pre">this</span> <span class="pre">context,</span> <span class="pre">batch</span> <span class="pre">dimension</span> <span class="pre">-1</span> <span class="pre">is</span> <span class="pre">independent\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“We recommend always providing an optional size argument to aid in debugging shapesn”,
“<code class="docutils literal notranslate"><span class="pre">`py\n&quot;,</span>
<span class="pre">&quot;with</span> <span class="pre">pyro.plate(\&quot;my_plate\&quot;,</span> <span class="pre">len(my_data)):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">within</span> <span class="pre">this</span> <span class="pre">context,</span> <span class="pre">batch</span> <span class="pre">dimension</span> <span class="pre">-1</span> <span class="pre">is</span> <span class="pre">independent\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“Starting with Pyro 0.2 you can additionally nest <cite>plates</cite>, e.g. if you have per-pixel independence:n”,
“<code class="docutils literal notranslate"><span class="pre">`py\n&quot;,</span>
<span class="pre">&quot;with</span> <span class="pre">pyro.plate(\&quot;x_axis\&quot;,</span> <span class="pre">320):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">within</span> <span class="pre">this</span> <span class="pre">context,</span> <span class="pre">batch</span> <span class="pre">dimension</span> <span class="pre">-1</span> <span class="pre">is</span> <span class="pre">independent\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">with</span> <span class="pre">pyro.plate(\&quot;y_axis\&quot;,</span> <span class="pre">200):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">within</span> <span class="pre">this</span> <span class="pre">context,</span> <span class="pre">batch</span> <span class="pre">dimensions</span> <span class="pre">-2</span> <span class="pre">and</span> <span class="pre">-1</span> <span class="pre">are</span> <span class="pre">independent\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“Note that we always count from the right by using negative indices like -2, -1.n”,
“n”,
“Finally if you want to mix and match <cite>plate`s for e.g. noise that depends only on `x</cite>, some noise that depends only on <cite>y</cite>, and some noise that depends on both, you can declare multiple <cite>plates</cite> and use them as reusable context managers. In this case Pyro cannot automatically allocate a dimension, so you need to provide a <cite>dim</cite> argument (again counting from the right):n”,
“<code class="docutils literal notranslate"><span class="pre">`py\n&quot;,</span>
<span class="pre">&quot;x_axis</span> <span class="pre">=</span> <span class="pre">pyro.plate(\&quot;x_axis\&quot;,</span> <span class="pre">3,</span> <span class="pre">dim=-2)\n&quot;,</span>
<span class="pre">&quot;y_axis</span> <span class="pre">=</span> <span class="pre">pyro.plate(\&quot;y_axis\&quot;,</span> <span class="pre">2,</span> <span class="pre">dim=-3)\n&quot;,</span>
<span class="pre">&quot;with</span> <span class="pre">x_axis:\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">within</span> <span class="pre">this</span> <span class="pre">context,</span> <span class="pre">batch</span> <span class="pre">dimension</span> <span class="pre">-2</span> <span class="pre">is</span> <span class="pre">independent\n&quot;,</span>
<span class="pre">&quot;with</span> <span class="pre">y_axis:\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">within</span> <span class="pre">this</span> <span class="pre">context,</span> <span class="pre">batch</span> <span class="pre">dimension</span> <span class="pre">-3</span> <span class="pre">is</span> <span class="pre">independent\n&quot;,</span>
<span class="pre">&quot;with</span> <span class="pre">x_axis,</span> <span class="pre">y_axis:\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">within</span> <span class="pre">this</span> <span class="pre">context,</span> <span class="pre">batch</span> <span class="pre">dimensions</span> <span class="pre">-3</span> <span class="pre">and</span> <span class="pre">-2</span> <span class="pre">are</span> <span class="pre">independent\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“Let’s take a closer look at batch sizes within <a href="#id1"><span class="problematic" id="id2">`</span></a>plate`s.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 7,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“def model1():n”,
”    a = pyro.sample(&quot;a&quot;, Normal(0, 1))n”,
”    b = pyro.sample(&quot;b&quot;, Normal(torch.zeros(2), 1).to_event(1))n”,
”    with pyro.plate(&quot;c_plate&quot;, 2):n”,
”        c = pyro.sample(&quot;c&quot;, Normal(torch.zeros(2), 1))n”,
”    with pyro.plate(&quot;d_plate&quot;, 3):n”,
”        d = pyro.sample(&quot;d&quot;, Normal(torch.zeros(3,4,5), 1).to_event(2))n”,
”    assert a.shape == ()       # batch_shape == ()     event_shape == ()n”,
”    assert b.shape == (2,)     # batch_shape == ()     event_shape == (2,)n”,
”    assert c.shape == (2,)     # batch_shape == (2,)   event_shape == ()n”,
”    assert d.shape == (3,4,5)  # batch_shape == (3,)   event_shape == (4,5) n”,
“n”,
”    x_axis = pyro.plate(&quot;x_axis&quot;, 3, dim=-2)n”,
”    y_axis = pyro.plate(&quot;y_axis&quot;, 2, dim=-3)n”,
”    with x_axis:n”,
”        x = pyro.sample(&quot;x&quot;, Normal(0, 1))n”,
”    with y_axis:n”,
”        y = pyro.sample(&quot;y&quot;, Normal(0, 1))n”,
”    with x_axis, y_axis:n”,
”        xy = pyro.sample(&quot;xy&quot;, Normal(0, 1))n”,
”        z = pyro.sample(&quot;z&quot;, Normal(0, 1).expand([5]).to_event(1))n”,
”    assert x.shape == (3, 1)        # batch_shape == (3,1)     event_shape == ()n”,
”    assert y.shape == (2, 1, 1)     # batch_shape == (2,1,1)   event_shape == ()n”,
”    assert xy.shape == (2, 3, 1)    # batch_shape == (2,3,1)   event_shape == ()n”,
”    assert z.shape == (2, 3, 1, 5)  # batch_shape == (2,3,1)   event_shape == (5,)n”,
”    n”,
“test_model(model1, model1, Trace_ELBO())”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“It is helpful to visualize the <cite>.shape`s of each sample site by aligning them at the boundary between `batch_shape</cite> and <cite>event_shape</cite>: dimensions to the right will be summed out in <cite>.log_prob()</cite> and dimensions to the left will remain. n”,
“<code class="docutils literal notranslate"><span class="pre">`\n&quot;,</span>
<span class="pre">&quot;batch</span> <span class="pre">dims</span> <span class="pre">|</span> <span class="pre">event</span> <span class="pre">dims\n&quot;,</span>
<span class="pre">&quot;-----------+-----------\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">a</span> <span class="pre">=</span> <span class="pre">sample(\&quot;a\&quot;,</span> <span class="pre">Normal(0,</span> <span class="pre">1))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|2</span>&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">b</span> <span class="pre">=</span> <span class="pre">sample(\&quot;b\&quot;,</span> <span class="pre">Normal(zeros(2),</span> <span class="pre">1)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">.to_event(1))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">with</span> <span class="pre">plate(\&quot;c\&quot;,</span> <span class="pre">2):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">2|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">c</span> <span class="pre">=</span> <span class="pre">sample(\&quot;c\&quot;,</span> <span class="pre">Normal(zeros(2),</span> <span class="pre">1))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">with</span> <span class="pre">plate(\&quot;d\&quot;,</span> <span class="pre">3):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">3|4</span> <span class="pre">5</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">d</span> <span class="pre">=</span> <span class="pre">sample(\&quot;d\&quot;,</span> <span class="pre">Normal(zeros(3,4,5),</span> <span class="pre">1)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">.to_event(2))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">x_axis</span> <span class="pre">=</span> <span class="pre">plate(\&quot;x\&quot;,</span> <span class="pre">3,</span> <span class="pre">dim=-2)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">y_axis</span> <span class="pre">=</span> <span class="pre">plate(\&quot;y\&quot;,</span> <span class="pre">2,</span> <span class="pre">dim=-3)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">with</span> <span class="pre">x_axis:\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">3</span> <span class="pre">1|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">x</span> <span class="pre">=</span> <span class="pre">sample(\&quot;x\&quot;,</span> <span class="pre">Normal(0,</span> <span class="pre">1))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">with</span> <span class="pre">y_axis:\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">2</span> <span class="pre">1</span> <span class="pre">1|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">y</span> <span class="pre">=</span> <span class="pre">sample(\&quot;y\&quot;,</span> <span class="pre">Normal(0,</span> <span class="pre">1))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">with</span> <span class="pre">x_axis,</span> <span class="pre">y_axis:\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">2</span> <span class="pre">3</span> <span class="pre">1|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">xy</span> <span class="pre">=</span> <span class="pre">sample(\&quot;xy\&quot;,</span> <span class="pre">Normal(0,</span> <span class="pre">1))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">2</span> <span class="pre">3</span> <span class="pre">1|5</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">z</span> <span class="pre">=</span> <span class="pre">sample(\&quot;z\&quot;,</span> <span class="pre">Normal(0,</span> <span class="pre">1).expand([5])\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">.to_event(1))\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“To examine the shapes of sample sites in a program automatically, you can trace the program and use the [Trace.format_shapes()](<a class="reference external" href="http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.Trace.format_shapes">http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.Trace.format_shapes</a>) method, which prints three shapes for each sample site: the distribution shape (both <cite>site[&quot;fn&quot;].batch_shape</cite> and <cite>site[&quot;fn&quot;].event_shape</cite>), the value shape (<cite>site[&quot;value&quot;].shape</cite>), and if log probability has been computed also the <cite>log_prob</cite> shape (<cite>site[&quot;log_prob&quot;].shape</cite>):”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 8,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“Trace Shapes:            n”,
” Param Sites:            n”,
“Sample Sites:            n”,
”       a dist       |    n”,
”        value       |    n”,
”     log_prob       |    n”,
”       b dist       | 2  n”,
”        value       | 2  n”,
”     log_prob       |    n”,
” c_plate dist       |    n”,
”        value     2 |    n”,
”     log_prob       |    n”,
”       c dist     2 |    n”,
”        value     2 |    n”,
”     log_prob     2 |    n”,
” d_plate dist       |    n”,
”        value     3 |    n”,
”     log_prob       |    n”,
”       d dist     3 | 4 5n”,
”        value     3 | 4 5n”,
”     log_prob     3 |    n”,
”  x_axis dist       |    n”,
”        value     3 |    n”,
”     log_prob       |    n”,
”  y_axis dist       |    n”,
”        value     2 |    n”,
”     log_prob       |    n”,
”       x dist   3 1 |    n”,
”        value   3 1 |    n”,
”     log_prob   3 1 |    n”,
”       y dist 2 1 1 |    n”,
”        value 2 1 1 |    n”,
”     log_prob 2 1 1 |    n”,
”      xy dist 2 3 1 |    n”,
”        value 2 3 1 |    n”,
”     log_prob 2 3 1 |    n”,
”       z dist 2 3 1 | 5  n”,
”        value 2 3 1 | 5  n”,
”     log_prob 2 3 1 |    n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“trace = poutine.trace(model1).get_trace()n”,
“trace.compute_log_prob()  # optional, but allows printing of log_prob shapesn”,
“print(trace.format_shapes())”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Subsampling tensors inside a <cite>plate</cite> &lt;a class=&quot;anchor&quot; id=&quot;Subsampling-tensors-inside-a-plate&quot;&gt;&lt;/a&gt;n”,
“n”,
“One of the main uses of [plate](<a class="reference external" href="http://docs.pyro.ai/en/dev/primitives.html#pyro.plate">http://docs.pyro.ai/en/dev/primitives.html#pyro.plate</a>) is to subsample data. This is possible within a <cite>plate</cite> because data are conditionally independent, so the expected value of the loss on, say, half the data should be half the expected loss on the full data.n”,
“n”,
“To subsample data, you need to inform Pyro of both the original data size and the subsample size; Pyro will then choose a random subset of data and yield the set of indices.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 9,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“data = torch.arange(100.)n”,
“n”,
“def model2():n”,
”    mean = pyro.param(&quot;mean&quot;, torch.zeros(len(data)))n”,
”    with pyro.plate(&quot;data&quot;, len(data), subsample_size=10) as ind:n”,
”        assert len(ind) == 10    # ind is a LongTensor that indexes the subsample.n”,
”        batch = data[ind]        # Select a minibatch of data.n”,
”        mean_batch = mean[ind]   # Take care to select the relevant per-datum parameters.n”,
”        # Do stuff with batch:n”,
”        x = pyro.sample(&quot;x&quot;, Normal(mean_batch, 1), obs=batch)n”,
”        assert len(x) == 10n”,
”        n”,
“test_model(model2, guide=lambda: None, loss=Trace_ELBO())”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Broadcasting to allow parallel enumeration &lt;a class=&quot;anchor&quot; id=&quot;Broadcasting-to-allow-parallel-enumeration&quot;&gt;&lt;/a&gt;n”,
“n”,
“Pyro 0.2 introduces the ability to enumerate discrete latent variables in parallel. This can significantly reduce the variance of gradient estimators when learning a posterior via [SVI](<a class="reference external" href="http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.svi.SVI).n">http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.svi.SVI).n</a>”,
“n”,
“To use parallel enumeration, Pyro needs to allocate tensor dimension that it can use for enumeration. To avoid conflicting with other dimensions that we want to use for <cite>plate`s, we need to declare a budget of the maximum number of tensor dimensions we’ll use. This budget is called `max_plate_nesting</cite> and is an argument to [SVI](<a class="reference external" href="http://docs.pyro.ai/en/dev/inference_algos.html">http://docs.pyro.ai/en/dev/inference_algos.html</a>) (the argument is simply passed through to [TraceEnum_ELBO](<a class="reference external" href="http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.traceenum_elbo.TraceEnum_ELBO">http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.traceenum_elbo.TraceEnum_ELBO</a>)). Usually Pyro can determine this budget on its own (it runs the <cite>(model,guide)</cite> pair once and record what happens), but in case of dynamic model structure you may need to declare <cite>max_plate_nesting</cite> manually.n”,
“n”,
“To understand <cite>max_plate_nesting</cite> and how Pyro allocates dimensions for enumeration, let’s revisit <cite>model1()</cite> from above. This time we’ll map out three types of dimensions:n”,
“enumeration dimensions on the left (Pyro takes control of these), batch dimensions in the middle, and event dimensions on the right.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“<code class="docutils literal notranslate"><span class="pre">`\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">max_plate_nesting</span> <span class="pre">=</span> <span class="pre">3\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|&lt;---&gt;|\n&quot;,</span>
<span class="pre">&quot;enumeration|batch|event\n&quot;,</span>
<span class="pre">&quot;-----------+-----+-----\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|.</span> <span class="pre">.</span> <span class="pre">.|</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">a</span> <span class="pre">=</span> <span class="pre">sample(\&quot;a\&quot;,</span> <span class="pre">Normal(0,</span> <span class="pre">1))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|.</span> <span class="pre">.</span> <span class="pre">.|2</span>&#160;&#160;&#160;&#160; <span class="pre">b</span> <span class="pre">=</span> <span class="pre">sample(\&quot;b\&quot;,</span> <span class="pre">Normal(zeros(2),</span> <span class="pre">1)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">.to_event(1))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">with</span> <span class="pre">plate(\&quot;c\&quot;,</span> <span class="pre">2):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|.</span> <span class="pre">.</span> <span class="pre">2|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">c</span> <span class="pre">=</span> <span class="pre">sample(\&quot;c\&quot;,</span> <span class="pre">Normal(zeros(2),</span> <span class="pre">1))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">with</span> <span class="pre">plate(\&quot;d\&quot;,</span> <span class="pre">3):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|.</span> <span class="pre">.</span> <span class="pre">3|4</span> <span class="pre">5</span>&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">d</span> <span class="pre">=</span> <span class="pre">sample(\&quot;d\&quot;,</span> <span class="pre">Normal(zeros(3,4,5),</span> <span class="pre">1)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">.to_event(2))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160; <span class="pre">|\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">x_axis</span> <span class="pre">=</span> <span class="pre">plate(\&quot;x\&quot;,</span> <span class="pre">3,</span> <span class="pre">dim=-2)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">y_axis</span> <span class="pre">=</span> <span class="pre">plate(\&quot;y\&quot;,</span> <span class="pre">2,</span> <span class="pre">dim=-3)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">with</span> <span class="pre">x_axis:\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|.</span> <span class="pre">3</span> <span class="pre">1|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">x</span> <span class="pre">=</span> <span class="pre">sample(\&quot;x\&quot;,</span> <span class="pre">Normal(0,</span> <span class="pre">1))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">with</span> <span class="pre">y_axis:\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|2</span> <span class="pre">1</span> <span class="pre">1|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">y</span> <span class="pre">=</span> <span class="pre">sample(\&quot;y\&quot;,</span> <span class="pre">Normal(0,</span> <span class="pre">1))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">with</span> <span class="pre">x_axis,</span> <span class="pre">y_axis:\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|2</span> <span class="pre">3</span> <span class="pre">1|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">xy</span> <span class="pre">=</span> <span class="pre">sample(\&quot;xy\&quot;,</span> <span class="pre">Normal(0,</span> <span class="pre">1))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|2</span> <span class="pre">3</span> <span class="pre">1|5</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">z</span> <span class="pre">=</span> <span class="pre">sample(\&quot;z\&quot;,</span> <span class="pre">Normal(0,</span> <span class="pre">1).expand([5]))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">.to_event(1))\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“Note that it is safe to overprovision <cite>max_plate_nesting=4</cite> but we cannot underprovision <cite>max_plate_nesting=2</cite> (or Pyro will error). Let’s see how this works in practice.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 10,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“&#64;config_enumeraten”,
“def model3():n”,
”    p = pyro.param(&quot;p&quot;, torch.arange(6.) / 6)n”,
”    locs = pyro.param(&quot;locs&quot;, torch.tensor([-1., 1.]))n”,
“n”,
”    a = pyro.sample(&quot;a&quot;, Categorical(torch.ones(6) / 6))n”,
”    b = pyro.sample(&quot;b&quot;, Bernoulli(p[a]))  # Note this depends on a.n”,
”    with pyro.plate(&quot;c_plate&quot;, 4):n”,
”        c = pyro.sample(&quot;c&quot;, Bernoulli(0.3))n”,
”        with pyro.plate(&quot;d_plate&quot;, 5):n”,
”            d = pyro.sample(&quot;d&quot;, Bernoulli(0.4))n”,
”            e_loc = locs[d.long()].unsqueeze(-1)n”,
”            e_scale = torch.arange(1., 8.)n”,
”            e = pyro.sample(&quot;e&quot;, Normal(e_loc, e_scale)n”,
”                            .to_event(1))  # Note this depends on d.n”,
“n”,
”    #                   enumerated|batch|event dimsn”,
”    assert a.shape == (         6, 1, 1   )  # Six enumerated values of the Categorical.n”,
”    assert b.shape == (      2, 1, 1, 1   )  # Two enumerated Bernoullis, unexpanded.n”,
”    assert c.shape == (   2, 1, 1, 1, 1   )  # Only two Bernoullis, unexpanded.n”,
”    assert d.shape == (2, 1, 1, 1, 1, 1   )  # Only two Bernoullis, unexpanded.n”,
”    assert e.shape == (2, 1, 1, 1, 5, 4, 7)  # This is sampled and depends on d.n”,
“n”,
”    assert e_loc.shape   == (2, 1, 1, 1, 1, 1, 1,)n”,
”    assert e_scale.shape == (                  7,)n”,
”            n”,
“test_model(model3, model3, TraceEnum_ELBO(max_plate_nesting=2))”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Let’s take a closer look at those dimensions. First note that Pyro allocates enumeration dims starting from the right at <cite>max_plate_nesting</cite>: Pyro allocates dim -3 to enumerate <cite>a</cite>, then dim -4 to enumerate <cite>b</cite>, then dim -5 to enumerate <cite>c</cite>, and finally dim -6 to enumerate <cite>d</cite>. Next note that samples only have extent (size &gt; 1) in the new enumeration dimension. This helps keep tensors small and computation cheap. (Note that the <cite>log_prob</cite> shape will be broadcast up to contain both enumeratin shape and batch shape, so e.g. <cite>trace.nodes[‘d’][‘log_prob’].shape == (2, 1, 1, 1, 5, 4)</cite>.)n”,
“n”,
“We can draw a similar map of the tensor dimensions:n”,
“<code class="docutils literal notranslate"><span class="pre">`\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160; <span class="pre">max_plate_nesting</span> <span class="pre">=</span> <span class="pre">2\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|&lt;-&gt;|\n&quot;,</span>
<span class="pre">&quot;enumeration</span> <span class="pre">batch</span> <span class="pre">event\n&quot;,</span>
<span class="pre">&quot;------------|---|-----\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">6|1</span> <span class="pre">1|</span>&#160;&#160;&#160;&#160; <span class="pre">a</span> <span class="pre">=</span> <span class="pre">pyro.sample(\&quot;a\&quot;,</span> <span class="pre">Categorical(torch.ones(6)</span> <span class="pre">/</span> <span class="pre">6))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">2</span> <span class="pre">1|1</span> <span class="pre">1|</span>&#160;&#160;&#160;&#160; <span class="pre">b</span> <span class="pre">=</span> <span class="pre">pyro.sample(\&quot;b\&quot;,</span> <span class="pre">Bernoulli(p[a]))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160; <span class="pre">with</span> <span class="pre">pyro.plate(\&quot;c_plate\&quot;,</span> <span class="pre">4):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">2</span> <span class="pre">1</span> <span class="pre">1|1</span> <span class="pre">1|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">c</span> <span class="pre">=</span> <span class="pre">pyro.sample(\&quot;c\&quot;,</span> <span class="pre">Bernoulli(0.3))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">with</span> <span class="pre">pyro.plate(\&quot;d_plate\&quot;,</span> <span class="pre">5):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160; <span class="pre">2</span> <span class="pre">1</span> <span class="pre">1</span> <span class="pre">1|1</span> <span class="pre">1|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">d</span> <span class="pre">=</span> <span class="pre">pyro.sample(\&quot;d\&quot;,</span> <span class="pre">Bernoulli(0.4))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160; <span class="pre">2</span> <span class="pre">1</span> <span class="pre">1</span> <span class="pre">1|1</span> <span class="pre">1|1</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">e_loc</span> <span class="pre">=</span> <span class="pre">locs[d.long()].unsqueeze(-1)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160; <span class="pre">|7</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">e_scale</span> <span class="pre">=</span> <span class="pre">torch.arange(1.,</span> <span class="pre">8.)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160; <span class="pre">2</span> <span class="pre">1</span> <span class="pre">1</span> <span class="pre">1|5</span> <span class="pre">4|7</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">e</span> <span class="pre">=</span> <span class="pre">pyro.sample(\&quot;e\&quot;,</span> <span class="pre">Normal(e_loc,</span> <span class="pre">e_scale)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">|</span>&#160;&#160; <span class="pre">|</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">.to_event(1))\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“To automatically examine this model with enumeration semantics, we can create an enumerated trace and then use [Trace.format_shapes()](<a class="reference external" href="http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.Trace.format_shapes">http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.Trace.format_shapes</a>):”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 11,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“Trace Shapes:                n”,
” Param Sites:                n”,
”            p             6  n”,
”         locs             2  n”,
“Sample Sites:                n”,
”       a dist             |  n”,
”        value       6 1 1 |  n”,
”     log_prob       6 1 1 |  n”,
”       b dist       6 1 1 |  n”,
”        value     2 1 1 1 |  n”,
”     log_prob     2 6 1 1 |  n”,
” c_plate dist             |  n”,
”        value           4 |  n”,
”     log_prob             |  n”,
”       c dist           4 |  n”,
”        value   2 1 1 1 1 |  n”,
”     log_prob   2 1 1 1 4 |  n”,
” d_plate dist             |  n”,
”        value           5 |  n”,
”     log_prob             |  n”,
”       d dist         5 4 |  n”,
”        value 2 1 1 1 1 1 |  n”,
”     log_prob 2 1 1 1 5 4 |  n”,
”       e dist 2 1 1 1 5 4 | 7n”,
”        value 2 1 1 1 5 4 | 7n”,
”     log_prob 2 1 1 1 5 4 |  n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“trace = poutine.trace(poutine.enum(model3, first_available_dim=-3)).get_trace()n”,
“trace.compute_log_prob()  # optional, but allows printing of log_prob shapesn”,
“print(trace.format_shapes())”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“### Writing parallelizable code &lt;a class=&quot;anchor&quot; id=&quot;Writing-parallelizable-code&quot;&gt;&lt;/a&gt;n”,
“n”,
“It can be tricky to write Pyro models that correctly handle parallelized sample sites. Two tricks help: [broadcasting](<a class="reference external" href="http://pytorch.org/docs/master/notes/broadcasting.html">http://pytorch.org/docs/master/notes/broadcasting.html</a>) and [ellipsis slicing](<a class="reference external" href="http://python-reference.readthedocs.io/en/dev/docs/brackets/ellipsis.html">http://python-reference.readthedocs.io/en/dev/docs/brackets/ellipsis.html</a>). Let’s look at a contrived model to see how these work in practice. Our aim is to write a model that works both with and without enumeration.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 12,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“width = 8n”,
“height = 10n”,
“sparse_pixels = torch.LongTensor([[3, 2], [3, 5], [3, 9], [7, 1]])n”,
“enumerated = None  # set to either True or False belown”,
“n”,
“def fun(observe):n”,
”    p_x = pyro.param(&quot;p_x&quot;, torch.tensor(0.1), constraint=constraints.unit_interval)n”,
”    p_y = pyro.param(&quot;p_y&quot;, torch.tensor(0.1), constraint=constraints.unit_interval)n”,
”    x_axis = pyro.plate(‘x_axis’, width, dim=-2)n”,
”    y_axis = pyro.plate(‘y_axis’, height, dim=-1)n”,
“n”,
”    # Note that the shapes of these sites depend on whether Pyro is enumerating.n”,
”    with x_axis:n”,
”        x_active = pyro.sample(&quot;x_active&quot;, Bernoulli(p_x))n”,
”    with y_axis:n”,
”        y_active = pyro.sample(&quot;y_active&quot;, Bernoulli(p_y))n”,
”    if enumerated:n”,
”        assert x_active.shape  == (2, 1, 1)n”,
”        assert y_active.shape  == (2, 1, 1, 1)n”,
”    else:n”,
”        assert x_active.shape  == (width, 1)n”,
”        assert y_active.shape  == (height,)n”,
“n”,
”    # The first trick is to broadcast. This works with or without enumeration.n”,
”    p = 0.1 + 0.5 * x_active * y_activen”,
”    if enumerated:n”,
”        assert p.shape == (2, 2, 1, 1)n”,
”    else:n”,
”        assert p.shape == (width, height)n”,
”    dense_pixels = p.new_zeros(broadcast_shape(p.shape, (width, height)))n”,
“n”,
”    # The second trick is to index using ellipsis slicing.n”,
”    # This allows Pyro to add arbitrary dimensions on the left.n”,
”    for x, y in sparse_pixels:n”,
”        dense_pixels[…, x, y] = 1n”,
”    if enumerated:n”,
”        assert dense_pixels.shape == (2, 2, width, height)n”,
”    else:n”,
”        assert dense_pixels.shape == (width, height)n”,
“n”,
”    with x_axis, y_axis:    n”,
”        if observe:n”,
”            pyro.sample(&quot;pixels&quot;, Bernoulli(p), obs=dense_pixels)n”,
“n”,
“def model4():n”,
”    fun(observe=True)n”,
“n”,
“def guide4():n”,
”    fun(observe=False)n”,
“n”,
“# Test without enumeration.n”,
“enumerated = Falsen”,
“test_model(model4, guide4, Trace_ELBO())n”,
“n”,
“# Test with enumeration.n”,
“enumerated = Truen”,
“test_model(model4, config_enumerate(guide4, &quot;parallel&quot;),n”,
”           TraceEnum_ELBO(max_plate_nesting=2))”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“### Automatic broadcasting inside pyro.plate&lt;a class=&quot;anchor&quot; id=&quot;Automatic-broadcasting-inside-pyro-plate&quot;&gt;&lt;/a&gt;n”,
“n”,
“Note that in all our model/guide specifications, we have relied on [pyro.plate](<a class="reference external" href="http://docs.pyro.ai/en/dev/primitives.html#pyro.plate">http://docs.pyro.ai/en/dev/primitives.html#pyro.plate</a>) to automatically expand sample shapes to satisfy the constraints on batch shape enforced by <cite>pyro.sample</cite> statements. However this broadcasting is equivalent to hand-annotated <cite>.expand()</cite> statements.n”,
“n”,
“We will demonstrate this using <cite>model4</cite> from the [previous section](#Writing-parallelizable-code). Note the following changes to the code from earlier:n”,
“n”,
” - For the purpose of this example, we will only consider &quot;parallel&quot; enumeration, but broadcasting should work as expected without enumeration or with &quot;sequential&quot; enumeration.n”,
” - We have separated out the sampling function which returns the tensors corresponding to the active pixels. Modularizing the model code into components is a common practice, and helps with maintainability of large models.n”,
” - We would also like to use the <cite>pyro.plate</cite> construct to parallelize the ELBO estimator over [num_particles](<a class="reference external" href="http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.elbo.ELBO">http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.elbo.ELBO</a>). This is done by wrapping the contents of model/guide inside an outermost <cite>pyro.plate</cite> context.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 13,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“num_particles = 100  # Number of samples for the ELBO estimatorn”,
“width = 8n”,
“height = 10n”,
“sparse_pixels = torch.LongTensor([[3, 2], [3, 5], [3, 9], [7, 1]])n”,
“n”,
“def sample_pixel_locations_no_broadcasting(p_x, p_y, x_axis, y_axis):n”,
”    with x_axis:n”,
”        x_active = pyro.sample(&quot;x_active&quot;, Bernoulli(p_x).expand([num_particles, width, 1]))n”,
”    with y_axis:n”,
”        y_active = pyro.sample(&quot;y_active&quot;, Bernoulli(p_y).expand([num_particles, 1, height]))n”,
”    return x_active, y_activen”,
“n”,
“def sample_pixel_locations_full_broadcasting(p_x, p_y, x_axis, y_axis):n”,
”    with x_axis:n”,
”        x_active = pyro.sample(&quot;x_active&quot;, Bernoulli(p_x))n”,
”    with y_axis:n”,
”        y_active = pyro.sample(&quot;y_active&quot;, Bernoulli(p_y))n”,
”    return x_active, y_active n”,
“n”,
“def sample_pixel_locations_partial_broadcasting(p_x, p_y, x_axis, y_axis):n”,
”    with x_axis:n”,
”        x_active = pyro.sample(&quot;x_active&quot;, Bernoulli(p_x).expand([width, 1]))n”,
”    with y_axis:n”,
”        y_active = pyro.sample(&quot;y_active&quot;, Bernoulli(p_y).expand([height]))n”,
”    return x_active, y_active n”,
“n”,
“def fun(observe, sample_fn):n”,
”    p_x = pyro.param(&quot;p_x&quot;, torch.tensor(0.1), constraint=constraints.unit_interval)n”,
”    p_y = pyro.param(&quot;p_y&quot;, torch.tensor(0.1), constraint=constraints.unit_interval)n”,
”    x_axis = pyro.plate(‘x_axis’, width, dim=-2)n”,
”    y_axis = pyro.plate(‘y_axis’, height, dim=-1)n”,
“n”,
”    with pyro.plate(&quot;num_particles&quot;, 100, dim=-3):n”,
”        x_active, y_active = sample_fn(p_x, p_y, x_axis, y_axis)n”,
”        # Indices corresponding to &quot;parallel&quot; enumeration are appended n”,
”        # to the left of the &quot;num_particles&quot; plate dim.n”,
”        assert x_active.shape  == (2, 1, 1, 1)n”,
”        assert y_active.shape  == (2, 1, 1, 1, 1)n”,
”        p = 0.1 + 0.5 * x_active * y_activen”,
”        assert p.shape == (2, 2, 1, 1, 1)n”,
“n”,
”        dense_pixels = p.new_zeros(broadcast_shape(p.shape, (width, height)))n”,
”        for x, y in sparse_pixels:n”,
”            dense_pixels[…, x, y] = 1n”,
”        assert dense_pixels.shape == (2, 2, 1, width, height)n”,
“n”,
”        with x_axis, y_axis:    n”,
”            if observe:n”,
”                pyro.sample(&quot;pixels&quot;, Bernoulli(p), obs=dense_pixels)n”,
“n”,
“def test_model_with_sample_fn(sample_fn):n”,
”    def model():n”,
”        fun(observe=True, sample_fn=sample_fn)n”,
“n”,
”    &#64;config_enumeraten”,
”    def guide():n”,
”        fun(observe=False, sample_fn=sample_fn)n”,
“n”,
”    test_model(model, guide, TraceEnum_ELBO(max_plate_nesting=3))n”,
“n”,
“test_model_with_sample_fn(sample_pixel_locations_no_broadcasting)n”,
“test_model_with_sample_fn(sample_pixel_locations_full_broadcasting)n”,
“test_model_with_sample_fn(sample_pixel_locations_partial_broadcasting)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“In the first sampling function, we had to do some manual book-keeping and expand the <cite>Bernoulli</cite> distribution’s batch shape to account for the conditionally independent dimensions added by the <cite>pyro.plate</cite> contexts. In particular, note how <cite>sample_pixel_locations</cite> needs knowledge of <cite>num_particles</cite>, <cite>width</cite> and <cite>height</cite> and is accessing these variables from the global scope, which is not ideal. n”,
“n”,
” - The second argument to <cite>pyro.plate</cite>, i.e. the optional <cite>size</cite> argument needs to be provided for implicit broadasting, so that it can infer the batch shape requirement for each of the sample sites. n”,
” - The existing <cite>batch_shape</cite> of the sample site must be broadcastable with the size of the <cite>pyro.plate</cite> contexts. In our particular example, <cite>Bernoulli(p_x)</cite> has an empty batch shape which is universally broadcastable.n”,
“n”,
“Note how simple it is to achieve parallelization via tensorized operations using <cite>pyro.plate</cite>! <cite>pyro.plate</cite> also helps in code modularization because model components can be written agnostic of the <cite>plate</cite> contexts in which they may subsequently get embedded in.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: null,
“metadata”: {},
“outputs”: [],
“source”: []</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>],
“metadata”: {</p>
<blockquote>
<div><dl class="simple">
<dt>“kernelspec”: {</dt><dd><p>“display_name”: “Python 3”,
“language”: “python”,
“name”: “python3”</p>
</dd>
</dl>
<p>},
“language_info”: {</p>
<blockquote>
<div><dl class="simple">
<dt>“codemirror_mode”: {</dt><dd><p>“name”: “ipython”,
“version”: 3</p>
</dd>
</dl>
<p>},
“file_extension”: “.py”,
“mimetype”: “text/x-python”,
“name”: “python”,
“nbconvert_exporter”: “python”,
“pygments_lexer”: “ipython3”,
“version”: “3.8.2”</p>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p>},
“nbformat”: 4,
“nbformat_minor”: 2</p>
</dd>
</dl>
<p>}</p>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="bayesian_regression_ii.html" class="btn btn-neutral float-left" title="&lt;no title&gt;" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="modules.html" class="btn btn-neutral float-right" title="&lt;no title&gt;" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Pyro Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>