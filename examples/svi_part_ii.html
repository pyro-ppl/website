<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>&lt;no title&gt; &mdash; Pyro Tutorials 1.8.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/pyro.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="&lt;no title&gt;" href="svi_part_iii.html" />
    <link rel="prev" title="&lt;no title&gt;" href="svi_part_i.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html">
            <img src="_static/pyro_logo_wide.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                1.8.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Practical Pyro and PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="svi_horovod.html">Example: distributed training via Horovod</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deep Generative Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cevae.html">Example: Causal Effect VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_gamma.html">Example: Sparse Gamma Deep Exponential Family</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Discrete Latent Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="toy_mixture_model_discrete_enumeration.html">Example: Toy Mixture Model With Discrete Enumeration</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm.html">Example: Hidden Markov Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="capture_recapture.html">Example: Capture-Recapture Models (CJS Models)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mixed_hmm.html">Example: hierarchical mixed-effect hidden Markov models</a></li>
<li class="toctree-l1"><a class="reference internal" href="einsum.html">Example: Discrete Factor Graph Inference with Plated Einsum</a></li>
<li class="toctree-l1"><a class="reference internal" href="lda.html">Example: Amortized Latent Dirichlet Allocation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Customizing Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="neutra.html">Example: Neural MCMC with NeuTraReparam</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_regression.html">Example: Sparse Bayesian Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="autoname_examples.html">Example: reducing boilerplate with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.autoname</span></code></a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Time Series</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="forecast_simple.html">Multivariate Forecasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="timeseries.html">Example: Gaussian Process Time Series Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Gaussian Processes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dkl.html">Example: Deep Kernel Learning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Epidemiology</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="epi_sir.html">Example: Univariate epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="epi_regional.html">Example: Regional epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="sir_hmc.html">Example: Epidemiological inference via HMC</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Biological sequences</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mue_profile.html">Example: Constant + MuE (Profile HMM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mue_factor.html">Example: Probabilistic PCA + MuE (FactorMuE)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Inference Algorithms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="baseball.html">Example: analyzing baseball stats with MCMC</a></li>
<li class="toctree-l1"><a class="reference internal" href="mcmc.html">Example: Inference with Markov Chain Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="lkj.html">Example: MCMC with an LKJ prior over covariances</a></li>
<li class="toctree-l1"><a class="reference internal" href="smcfilter.html">Example: Sequential Monte Carlo Filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="inclined_plane.html">Example: importance sampling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Understanding Pyro's Internals</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="minipyro.html">Mini-Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm_funsor.html">Example: hidden Markov models with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">pyroapi</span></code></a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pyro Tutorials</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>&lt;no title&gt;</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/svi_part_ii.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<dl>
<dt>{</dt><dd><dl>
<dt>“cells”: [</dt><dd><dl>
<dt>{</dt><dd><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“# SVI Part II: Conditional Independence, Subsampling, and Amortizationn”,
“n”,
“## The Goal: Scaling SVI to Large Datasetsn”,
“n”,
“For a model with $N$ observations, running the <cite>model</cite> and <cite>guide</cite> and constructing the ELBO involves evaluating log pdf’s whose complexity scales badly with $N$. This is a problem if we want to scale to large datasets. Luckily, the ELBO objective naturally supports subsampling provided that our model/guide have some conditional independence structure that we can take advantage of. For example, in the case that the observations are conditionally independent given the latents, the log likelihood term in the ELBO can be approximated withn”,
“n”,
“$$ \sum_{i=1}^N \log p({\bf x}_i | {\bf z}) \approx  \frac{N}{M}n”,
“\sum_{i\in{\mathcal{I}_M}} \log p({\bf x}_i | {\bf z})  $$n”,
“n”,
“where $\mathcal{I}_M$ is a mini-batch of indices of size $M$ with $M&lt;N$ (for a discussion please see references [1,2]). Great, problem solved! But how do we do this in Pyro?n”,
“n”,
“## Marking Conditional Independence in Pyron”,
“n”,
“If a user wants to do this sort of thing in Pyro, he or she first needs to make sure that the model and guide are written in such a way that Pyro can leverage the relevant conditional independencies. Let’s see how this is done. Pyro provides two language primitives for marking conditional independencies: <cite>plate</cite> and <cite>markov</cite>. Let’s start with the simpler of the two.n”,
“n”,
“### Sequential <cite>plate</cite>n”,
“n”,
“Let’s return to the example we used in the [previous tutorial](svi_part_i.ipynb). For convenience let’s replicate the main logic of <cite>model</cite> here:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;def</span> <span class="pre">model(data):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">sample</span> <span class="pre">f</span> <span class="pre">from</span> <span class="pre">the</span> <span class="pre">beta</span> <span class="pre">prior\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">f</span> <span class="pre">=</span> <span class="pre">pyro.sample(\&quot;latent_fairness\&quot;,</span> <span class="pre">dist.Beta(alpha0,</span> <span class="pre">beta0))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">loop</span> <span class="pre">over</span> <span class="pre">the</span> <span class="pre">observed</span> <span class="pre">data</span> <span class="pre">using</span> <span class="pre">pyro.sample</span> <span class="pre">with</span> <span class="pre">the</span> <span class="pre">obs</span> <span class="pre">keyword</span> <span class="pre">argument\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">for</span> <span class="pre">i</span> <span class="pre">in</span> <span class="pre">range(len(data)):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">observe</span> <span class="pre">datapoint</span> <span class="pre">i</span> <span class="pre">using</span> <span class="pre">the</span> <span class="pre">bernoulli</span> <span class="pre">likelihood\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">pyro.sample(\&quot;obs_{}\&quot;.format(i),</span> <span class="pre">dist.Bernoulli(f),</span> <span class="pre">obs=data[i])\n&quot;,</span>
<span class="pre">&quot;`</span></code>        n”,
“n”,
“For this model the observations are conditionally independent given the latent random variable <cite>latent_fairness</cite>. To explicitly mark this in Pyro we basically just need to replace the Python builtin <cite>range</cite> with the Pyro construct <cite>plate</cite>:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;def</span> <span class="pre">model(data):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">sample</span> <span class="pre">f</span> <span class="pre">from</span> <span class="pre">the</span> <span class="pre">beta</span> <span class="pre">prior\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">f</span> <span class="pre">=</span> <span class="pre">pyro.sample(\&quot;latent_fairness\&quot;,</span> <span class="pre">dist.Beta(alpha0,</span> <span class="pre">beta0))\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">loop</span> <span class="pre">over</span> <span class="pre">the</span> <span class="pre">observed</span> <span class="pre">data</span> <span class="pre">[WE</span> <span class="pre">ONLY</span> <span class="pre">CHANGE</span> <span class="pre">THE</span> <span class="pre">NEXT</span> <span class="pre">LINE]\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">for</span> <span class="pre">i</span> <span class="pre">in</span> <span class="pre">pyro.plate(\&quot;data_loop\&quot;,</span> <span class="pre">len(data)):</span>&#160; <span class="pre">\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">observe</span> <span class="pre">datapoint</span> <span class="pre">i</span> <span class="pre">using</span> <span class="pre">the</span> <span class="pre">bernoulli</span> <span class="pre">likelihood\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">pyro.sample(\&quot;obs_{}\&quot;.format(i),</span> <span class="pre">dist.Bernoulli(f),</span> <span class="pre">obs=data[i])\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“n”,
“We see that <cite>pyro.plate</cite> is very similar to <cite>range</cite> with one main difference: each invocation of <cite>plate</cite> requires the user to provide a unique name. The second argument is an integer just like for <cite>range</cite>. n”,
“n”,
“So far so good. Pyro can now leverage the conditional independency of the observations given the latent random variable. But how does this actually work? Basically <cite>pyro.plate</cite> is implemented using a context manager. At every execution of the body of the <cite>for</cite> loop we enter a new (conditional) independence context which is then exited at the end of the <cite>for</cite> loop body. Let’s be very explicit about this: n”,
“n”,
“- because each observed <cite>pyro.sample</cite> statement occurs within a different execution of the body of the <cite>for</cite> loop, Pyro marks each observation as independentn”,
“- this independence is properly a _conditional_ independence _given_ <cite>latent_fairness</cite> because <cite>latent_fairness</cite> is sampled _outside_ of the context of <cite>data_loop</cite>.n”,
“n”,
“Before moving on, let’s mention some gotchas to be avoided when using sequential <cite>plate</cite>. Consider the following variant of the above code snippet:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;#</span> <span class="pre">WARNING</span> <span class="pre">do</span> <span class="pre">not</span> <span class="pre">do</span> <span class="pre">this!\n&quot;,</span>
<span class="pre">&quot;my_reified_list</span> <span class="pre">=</span> <span class="pre">list(pyro.plate(\&quot;data_loop\&quot;,</span> <span class="pre">len(data)))\n&quot;,</span>
<span class="pre">&quot;for</span> <span class="pre">i</span> <span class="pre">in</span> <span class="pre">my_reified_list:</span>&#160; <span class="pre">\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">pyro.sample(\&quot;obs_{}\&quot;.format(i),</span> <span class="pre">dist.Bernoulli(f),</span> <span class="pre">obs=data[i])\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“n”,
“This will _not_ achieve the desired behavior, since <cite>list()</cite> will enter and exit the <cite>data_loop</cite> context completely before a single <cite>pyro.sample</cite> statement is called. Similarly, the user needs to take care not to leak mutable computations across the boundary of the context manager, as this may lead to subtle bugs. For example, <cite>pyro.plate</cite> is not appropriate for temporal models where each iteration of a loop depends on the previous iteration; in this case a <cite>range</cite> or <cite>pyro.markov</cite> should be used instead.n”,
“n”,
“### Vectorized <cite>plate</cite>n”,
“n”,
“Conceptually vectorized <cite>plate</cite> is the same as sequential <cite>plate</cite> except that it is a vectorized operation (as <cite>torch.arange</cite> is to <cite>range</cite>). As such it potentially enables large speed-ups compared to the explicit <cite>for</cite> loop that appears with sequential <cite>plate</cite>. Let’s see how this looks for our running example. First we need <cite>data</cite> to be in the form of a tensor:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;data</span> <span class="pre">=</span> <span class="pre">torch.zeros(10)\n&quot;,</span>
<span class="pre">&quot;data[0:6]</span> <span class="pre">=</span> <span class="pre">torch.ones(6)</span>&#160; <span class="pre">#</span> <span class="pre">6</span> <span class="pre">heads</span> <span class="pre">and</span> <span class="pre">4</span> <span class="pre">tails\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“n”,
“Then we have:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;with</span> <span class="pre">pyro.plate('observe_data'):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">pyro.sample('obs',</span> <span class="pre">dist.Bernoulli(f),</span> <span class="pre">obs=data)\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“n”,
“Let’s compare this to the analogous sequential <cite>plate</cite> usage point-by-point:n”,
“n”,
“- both patterns requires the user to specify a unique name.n”,
“- note that this code snippet only introduces a single (observed) random variable (namely <cite>obs</cite>), since the entire tensor is considered at once. n”,
“- since there is no need for an iterator in this case, there is no need to specify the length of the tensor(s) involved in the <cite>plate</cite> contextn”,
“n”,
“Note that the gotchas mentioned in the case of sequential <cite>plate</cite> also apply to vectorized <cite>plate</cite>.”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Subsamplingn”,
“n”,
“We now know how to mark conditional independence in Pyro. This is useful in and of itself (see the [dependency tracking section](svi_part_iii.ipynb) in SVI Part III), but we’d also like to do subsampling so that we can do SVI on large datasets. Depending on the structure of the model and guide, Pyro supports several ways of doing subsampling. Let’s go through these one by one.n”,
“n”,
“### Automatic subsampling with <cite>plate</cite>n”,
“n”,
“Let’s look at the simplest case first, in which we get subsampling for free with one or two additional arguments to <cite>plate</cite>:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;for</span> <span class="pre">i</span> <span class="pre">in</span> <span class="pre">pyro.plate(\&quot;data_loop\&quot;,</span> <span class="pre">len(data),</span> <span class="pre">subsample_size=5):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">pyro.sample(\&quot;obs_{}\&quot;.format(i),</span> <span class="pre">dist.Bernoulli(f),</span> <span class="pre">obs=data[i])\n&quot;,</span>
<span class="pre">&quot;`</span></code>    n”,
“n”,
“That’s all there is to it: we just use the argument <cite>subsample_size</cite>. Whenever we run <cite>model()</cite> we now only evaluate the log likelihood for 5 randomly chosen datapoints in <cite>data</cite>; in addition, the log likelihood will be automatically scaled by the appropriate factor of $\tfrac{10}{5} = 2$. What about vectorized <cite>plate</cite>? The incantation is entirely analogous:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;with</span> <span class="pre">pyro.plate('observe_data',</span> <span class="pre">size=10,</span> <span class="pre">subsample_size=5)</span> <span class="pre">as</span> <span class="pre">ind:\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">pyro.sample('obs',</span> <span class="pre">dist.Bernoulli(f),</span> <span class="pre">\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">obs=data.index_select(0,</span> <span class="pre">ind))\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“n”,
“Importantly, <cite>plate</cite> now returns a tensor of indices <cite>ind</cite>, which, in this case will be of length 5. Note that in addition to the argument <cite>subsample_size</cite> we also pass the argument <cite>size</cite> so that <cite>plate</cite> is aware of the full size of the tensor <cite>data</cite> so that it can compute the correct scaling factor.  Just like for sequential <cite>plate</cite>, the user is responsible for selecting the correct datapoints using the indices provided by <cite>plate</cite>.   n”,
“n”,
“Finally, note that the user must pass a <cite>device</cite> argument to <cite>plate</cite> if <cite>data</cite> is on the GPU.n”,
“n”,
“### Custom subsampling strategies with <cite>plate</cite>n”,
“n”,
“Every time the above <cite>model()</cite> is run <cite>plate</cite> will sample new subsample indices. Since this subsampling is stateless, this can lead to some problems: basically for a sufficiently large dataset even after a large number of iterations there’s a nonnegligible  probability that some of the datapoints will have never been selected. To avoid this the user can take control of subsampling by making use of the <cite>subsample</cite> argument to  <cite>plate</cite>. See [the docs](<a class="reference external" href="http://docs.pyro.ai/en/dev/primitives.html#pyro.plate">http://docs.pyro.ai/en/dev/primitives.html#pyro.plate</a>) for details.n”,
“n”,
“### Subsampling when there are only local random variables n”,
“n”,
“We have in mind a model with a joint probability density given byn”,
“n”,
“$$ p({\bf x}, {\bf z}) = \prod_{i=1}^N p({\bf x}_i | {\bf z}_i) p({\bf z}_i)  $$n”,
“n”,
“For a model with this dependency structure the scale factor introduced by subsampling scales all the terms in the ELBO by the same amount. This is the case, for example, for a vanilla VAE. This explains why for the VAE it’s permissible for the user to take complete control over subsampling and pass mini-batches directly to the model and guide; <cite>plate</cite> is still used, but <cite>subsample_size</cite> and <cite>subsample</cite> are not. To see how this looks in detail, see the [VAE tutorial](vae.ipynb).n”,
“n”,
“n”,
“### Subsampling when there are both global and local random variablesn”,
“n”,
“In the coin flip examples above <cite>plate</cite> appeared in the model but not in the guide, since the only thing being subsampled was the observations. Let’s look at a more complicated example where subsampling appears in both the model and guide. To make things simple let’s keep the discussion somewhat abstract and avoid writing a complete model and guide. n”,
“n”,
“Consider the model specified by the following joint distribution:n”,
“n”,
“$$ p({\bf x}, {\bf z}, \beta) = p(\beta) n”,
“\prod_{i=1}^N p({\bf x}_i | {\bf z}_i) p({\bf z}_i | \beta)  $$n”,
“n”,
“There are $N$ observations $\{ {\bf x}_i \}$ and $N$ local latent random variables n”,
“$\{ {\bf z}_i \}$. There is also a global latent random variable $\beta$. Our guide will be factorized asn”,
“n”,
“$$ q({\bf z}, \beta) = q(\beta) \prod_{i=1}^N q({\bf z}_i | \beta, \lambda_i)  $$n”,
“n”,
“Here we’ve been explicit about introducing $N$ local variational parameters n”,
“$\{\lambda_i \}$, while the other variational parameters are left implicit. Both the model and guide have conditional independencies. In particular, on the model side, given the $\{ {\bf z}_i \}$ the observations $\{ {\bf x}_i \}$ are independent. In addition, given $\beta$ the latent random variables  $\{\bf {z}_i \}$ are independent. On the guide side, given the variational parameters $\{\lambda_i \}$ and $\beta$ the latent random variables  $\{\bf {z}_i \}$ are independent. To mark these conditional independencies in Pyro and do subsampling we need to make use of <cite>plate</cite> in _both_ the model _and_ the guide. Let’s sketch out the basic logic using sequential <cite>plate</cite> (a more complete piece of code would include <cite>pyro.param</cite> statements, etc.). First, the model:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;def</span> <span class="pre">model(data):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">beta</span> <span class="pre">=</span> <span class="pre">pyro.sample(\&quot;beta\&quot;,</span> <span class="pre">...)</span> <span class="pre">#</span> <span class="pre">sample</span> <span class="pre">the</span> <span class="pre">global</span> <span class="pre">RV\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">for</span> <span class="pre">i</span> <span class="pre">in</span> <span class="pre">pyro.plate(\&quot;locals\&quot;,</span> <span class="pre">len(data)):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">z_i</span> <span class="pre">=</span> <span class="pre">pyro.sample(\&quot;z_{}\&quot;.format(i),</span> <span class="pre">...)\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">compute</span> <span class="pre">the</span> <span class="pre">parameter</span> <span class="pre">used</span> <span class="pre">to</span> <span class="pre">define</span> <span class="pre">the</span> <span class="pre">observation</span> <span class="pre">\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">likelihood</span> <span class="pre">using</span> <span class="pre">the</span> <span class="pre">local</span> <span class="pre">random</span> <span class="pre">variable\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">theta_i</span> <span class="pre">=</span> <span class="pre">compute_something(z_i)</span> <span class="pre">\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">pyro.sample(\&quot;obs_{}\&quot;.format(i),</span> <span class="pre">dist.MyDist(theta_i),</span> <span class="pre">obs=data[i])\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“n”,
“Note that in contrast to our running coin flip example, here we have <cite>pyro.sample</cite> statements both inside and outside of the <cite>plate</cite> loop. Next the guide:n”,
“n”,
“<code class="docutils literal notranslate"><span class="pre">`python\n&quot;,</span>
<span class="pre">&quot;def</span> <span class="pre">guide(data):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">beta</span> <span class="pre">=</span> <span class="pre">pyro.sample(\&quot;beta\&quot;,</span> <span class="pre">...)</span> <span class="pre">#</span> <span class="pre">sample</span> <span class="pre">the</span> <span class="pre">global</span> <span class="pre">RV\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160; <span class="pre">for</span> <span class="pre">i</span> <span class="pre">in</span> <span class="pre">pyro.plate(\&quot;locals\&quot;,</span> <span class="pre">len(data),</span> <span class="pre">subsample_size=5):\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">#</span> <span class="pre">sample</span> <span class="pre">the</span> <span class="pre">local</span> <span class="pre">RVs\n&quot;,</span>
<span class="pre">&quot;</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">pyro.sample(\&quot;z_{}\&quot;.format(i),</span> <span class="pre">...,</span> <span class="pre">lambda_i)\n&quot;,</span>
<span class="pre">&quot;`</span></code>n”,
“n”,
“Note that crucially the indices will only be subsampled once in the guide; the Pyro backend makes sure that the same set of indices are used during execution of the model. For this reason <cite>subsample_size</cite> only needs to be specified in the guide.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Amortizationn”,
“n”,
“Let’s again consider a model with global and local latent random variables and local variational parameters:n”,
“n”,
“$$ p({\bf x}, {\bf z}, \beta) = p(\beta) n”,
“\prod_{i=1}^N p({\bf x}_i | {\bf z}_i) p({\bf z}_i | \beta)  \qquad \qquadn”,
“q({\bf z}, \beta) = q(\beta) \prod_{i=1}^N q({\bf z}_i | \beta, \lambda_i)  $$n”,
“n”,
“For small to medium-sized $N$ using local variational parameters like this can be a good approach. If $N$ is large, however, the fact that the space we’re doing optimization over grows with $N$ can be a real problem. One way to avoid this nasty growth with the size of the dataset is <em>amortization</em>.n”,
“n”,
“This works as follows. Instead of introducing local variational parameters, we’re going to learn a single parametric function $f(\cdot)$ and work with a variational distribution that has the form n”,
“n”,
“$$q(\beta) \prod_{n=1}^N q({\bf z}_i | f({\bf x}_i))$$n”,
“n”,
“The function $f(\cdot)$&amp;mdash;which basically maps a given observation to a set of variational parameters tailored to that datapoint&amp;mdash;will need to be sufficiently rich to capture the posterior accurately, but now we can handle large datasets without having to introduce an obscene number of variational parameters. n”,
“This approach has other benefits too: for example, during learning $f(\cdot)$ effectively allows us to share statistical power among different datapoints. Note that this is precisely the approach used in the [VAE](vae.ipynb).n”,
“n”,
“## Tensor shapes and vectorized <cite>plate</cite>n”,
“n”,
“The usage of <cite>pyro.plate</cite> in this tutorial was limited to relatively simple cases. For example, none of the <cite>plate`s were nested inside of other `plate`s. In order to make full use of `plate</cite>, the user must be careful to use Pyro’s tensor shape semantics. For a discussion see the [tensor shapes tutorial](tensor_shapes.ipynb).”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Referencesn”,
“n”,
“[1] <cite>Stochastic Variational Inference</cite>,n”,
“&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;n”,
“Matthew D. Hoffman, David M. Blei, Chong Wang, John Paisleyn”,
“n”,
“[2] <cite>Auto-Encoding Variational Bayes</cite>,&lt;br/&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;n”,
“Diederik P Kingma, Max Welling”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>],
“metadata”: {</p>
<blockquote>
<div><dl class="simple">
<dt>“kernelspec”: {</dt><dd><p>“display_name”: “Python 3”,
“language”: “python”,
“name”: “python3”</p>
</dd>
</dl>
<p>},
“language_info”: {</p>
<blockquote>
<div><dl class="simple">
<dt>“codemirror_mode”: {</dt><dd><p>“name”: “ipython”,
“version”: 3</p>
</dd>
</dl>
<p>},
“file_extension”: “.py”,
“mimetype”: “text/x-python”,
“name”: “python”,
“nbconvert_exporter”: “python”,
“pygments_lexer”: “ipython3”,
“version”: “3.6.10”</p>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p>},
“nbformat”: 4,
“nbformat_minor”: 2</p>
</dd>
</dl>
<p>}</p>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="svi_part_i.html" class="btn btn-neutral float-left" title="&lt;no title&gt;" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="svi_part_iii.html" class="btn btn-neutral float-right" title="&lt;no title&gt;" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Pyro Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>