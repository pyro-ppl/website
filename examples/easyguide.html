<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>&lt;no title&gt; &mdash; Pyro Tutorials 1.8.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/pyro.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="&lt;no title&gt;" href="custom_objectives.html" />
    <link rel="prev" title="&lt;no title&gt;" href="mle_map.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html">
            <img src="_static/pyro_logo_wide.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                1.8.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Practical Pyro and PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="svi_horovod.html">Example: distributed training via Horovod</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deep Generative Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cevae.html">Example: Causal Effect VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_gamma.html">Example: Sparse Gamma Deep Exponential Family</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Discrete Latent Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="toy_mixture_model_discrete_enumeration.html">Example: Toy Mixture Model With Discrete Enumeration</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm.html">Example: Hidden Markov Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="capture_recapture.html">Example: Capture-Recapture Models (CJS Models)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mixed_hmm.html">Example: hierarchical mixed-effect hidden Markov models</a></li>
<li class="toctree-l1"><a class="reference internal" href="einsum.html">Example: Discrete Factor Graph Inference with Plated Einsum</a></li>
<li class="toctree-l1"><a class="reference internal" href="lda.html">Example: Amortized Latent Dirichlet Allocation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Customizing Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="neutra.html">Example: Neural MCMC with NeuTraReparam</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_regression.html">Example: Sparse Bayesian Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="autoname_examples.html">Example: reducing boilerplate with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.autoname</span></code></a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Time Series</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="forecast_simple.html">Multivariate Forecasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="timeseries.html">Example: Gaussian Process Time Series Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Gaussian Processes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dkl.html">Example: Deep Kernel Learning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Epidemiology</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="epi_sir.html">Example: Univariate epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="epi_regional.html">Example: Regional epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="sir_hmc.html">Example: Epidemiological inference via HMC</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Biological sequences</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mue_profile.html">Example: Constant + MuE (Profile HMM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mue_factor.html">Example: Probabilistic PCA + MuE (FactorMuE)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Inference Algorithms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="baseball.html">Example: analyzing baseball stats with MCMC</a></li>
<li class="toctree-l1"><a class="reference internal" href="mcmc.html">Example: Inference with Markov Chain Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="lkj.html">Example: MCMC with an LKJ prior over covariances</a></li>
<li class="toctree-l1"><a class="reference internal" href="smcfilter.html">Example: Sequential Monte Carlo Filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="inclined_plane.html">Example: importance sampling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Understanding Pyro's Internals</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="minipyro.html">Mini-Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm_funsor.html">Example: hidden Markov models with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">pyroapi</span></code></a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pyro Tutorials</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>&lt;no title&gt;</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/easyguide.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<dl>
<dt>{</dt><dd><dl>
<dt>“cells”: [</dt><dd><dl>
<dt>{</dt><dd><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“# Writing guides using EasyGuiden”,
“n”,
“This tutorial describes the [pyro.contrib.easyguide](<a class="reference external" href="http://docs.pyro.ai/en/stable/contrib.easyguide.html">http://docs.pyro.ai/en/stable/contrib.easyguide.html</a>) module. This tutorial assumes the reader is already familiar with [SVI](<a class="reference external" href="http://pyro.ai/examples/svi_part_ii.html">http://pyro.ai/examples/svi_part_ii.html</a>) and [tensor shapes](<a class="reference external" href="http://pyro.ai/examples/tensor_shapes.html).n">http://pyro.ai/examples/tensor_shapes.html).n</a>”,
“n”,
“#### Summaryn”,
“n”,
“- For simple black-box guides, try using components in [pyro.infer.autoguide](<a class="reference external" href="http://docs.pyro.ai/en/stable/infer.autoguide.html).n">http://docs.pyro.ai/en/stable/infer.autoguide.html).n</a>”,
“- For more complex guides, try using components in [pyro.contrib.easyguide](<a class="reference external" href="http://docs.pyro.ai/en/stable/contrib.easyguide.html).n">http://docs.pyro.ai/en/stable/contrib.easyguide.html).n</a>”,
“- Decorate with <cite>&#64;easy_guide(model)</cite>.n”,
“- Select multiple model sites using <cite>group = self.group(match=&quot;my_regex&quot;)</cite>.n”,
“- Guide a group of sites by a single distribution using <cite>group.sample(…)</cite>.n”,
“- Inspect concatenated group shape using <cite>group.batch_shape</cite>, <cite>group.event_shape</cite>, etc.n”,
“- Use <cite>self.plate(…)</cite> instead of <cite>pyro.plate(…)</cite>.n”,
“- To be compatible with subsampling, pass the <cite>event_dim</cite> arg to <cite>pyro.param(…)</cite>.n”,
“- To MAP estimate model site &quot;foo&quot;, use <cite>foo = self.map_estimate(&quot;foo&quot;)</cite>.n”,
“n”,
“#### Table of contentsn”,
“n”,
“- [Modeling time series data](#Modeling-time-series-data)n”,
“- [Writing a guide without EasyGuide](#Writing-a-guide-without-EasyGuide)n”,
“- [Using EasyGuide](#Using-EasyGuide)n”,
“- [Amortized guides](#Amortized-guides)”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: null,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“import osn”,
“import torchn”,
“import pyron”,
“import pyro.distributions as distn”,
“from pyro.infer import SVI, Trace_ELBOn”,
“from pyro.contrib.easyguide import easy_guiden”,
“from pyro.optim import Adamn”,
“from torch.distributions import constraintsn”,
“n”,
“smoke_test = (‘CI’ in os.environ)n”,
“assert pyro.__version__.startswith(‘1.8.1’)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Modeling time series data”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Consider a time-series model with a slowly-varying continuous latent state and Bernoulli observations with a logistic link function.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: null,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“def model(batch, subsample, full_size):n”,
”    batch = list(batch)n”,
”    num_time_steps = len(batch)n”,
”    drift = pyro.sample(&quot;drift&quot;, dist.LogNormal(-1, 0.5))n”,
”    with pyro.plate(&quot;data&quot;, full_size, subsample=subsample):n”,
”        z = 0.n”,
”        for t in range(num_time_steps):n”,
”            z = pyro.sample(&quot;state_{}&quot;.format(t),n”,
”                            dist.Normal(z, drift))n”,
”            batch[t] = pyro.sample(&quot;obs_{}&quot;.format(t),n”,
”                                   dist.Bernoulli(logits=z),n”,
”                                   obs=batch[t])n”,
”    return torch.stack(batch)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Let’s generate some data directly from the model.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: null,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“full_size = 100n”,
“num_time_steps = 7n”,
“pyro.set_rng_seed(123456789)n”,
“data = model([None] * num_time_steps, torch.arange(full_size), full_size)n”,
“assert data.shape == (num_time_steps, full_size)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Writing a guide without EasyGuiden”,
“n”,
“Consider a possible guide for this model where we point-estimate the <cite>drift</cite> parameter using a <cite>Delta</cite> distribution, and then model local time series using shared uncertainty but local means, using a <cite>LowRankMultivariateNormal</cite> distribution. There is a single global sample site which we can model with a <cite>param</cite> and <cite>sample</cite> statement. Then we sample a global pair of uncertainty parameters <cite>cov_diag</cite> and <cite>cov_factor</cite>. Next we sample a local <cite>loc</cite> parameter using <cite>pyro.param(…, event_dim=…)</cite> and an auxiliary sample site. Finally we unpack that auxiliary site into one element per time series. The auxiliary-unpacked-to-<a href="#id1"><span class="problematic" id="id2">`</span></a>Delta`s pattern is quite common.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: null,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“rank = 3n”,
”    n”,
“def guide(batch, subsample, full_size):n”,
”    num_time_steps, batch_size = batch.shapen”,
“n”,
”    # MAP estimate the drift.n”,
”    drift_loc = pyro.param(&quot;drift_loc&quot;, lambda: torch.tensor(0.1),n”,
”                           constraint=constraints.positive)n”,
”    pyro.sample(&quot;drift&quot;, dist.Delta(drift_loc))n”,
“n”,
”    # Model local states using shared uncertainty + local mean.n”,
”    cov_diag = pyro.param(&quot;state_cov_diag&quot;,n”,
”                          lambda: torch.full((num_time_steps,), 0.01),n”,
”                         constraint=constraints.positive)n”,
”    cov_factor = pyro.param(&quot;state_cov_factor&quot;,n”,
”                            lambda: torch.randn(num_time_steps, rank) * 0.01)n”,
”    with pyro.plate(&quot;data&quot;, full_size, subsample=subsample):n”,
”        # Sample local mean.n”,
”        loc = pyro.param(&quot;state_loc&quot;,n”,
”                         lambda: torch.full((full_size, num_time_steps), 0.5),n”,
”                         event_dim=1)n”,
”        states = pyro.sample(&quot;states&quot;,n”,
”                             dist.LowRankMultivariateNormal(loc, cov_factor, cov_diag),n”,
”                             infer={&quot;is_auxiliary&quot;: True})n”,
”        # Unpack the joint states into one sample site per time step.n”,
”        for t in range(num_time_steps):n”,
”            pyro.sample(&quot;state_{}&quot;.format(t), dist.Delta(states[:, t]))”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Let’s train using [SVI](<a class="reference external" href="http://docs.pyro.ai/en/stable/inference_algos.html#module-pyro.infer.svi">http://docs.pyro.ai/en/stable/inference_algos.html#module-pyro.infer.svi</a>) and [Trace_ELBO](<a class="reference external" href="http://docs.pyro.ai/en/stable/inference_algos.html#pyro.infer.trace_elbo.Trace_ELBO">http://docs.pyro.ai/en/stable/inference_algos.html#pyro.infer.trace_elbo.Trace_ELBO</a>), manually batching data into small minibatches.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: null,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“def train(guide, num_epochs=1 if smoke_test else 101, batch_size=20):n”,
”    full_size = data.size(-1)n”,
”    pyro.get_param_store().clear()n”,
”    pyro.set_rng_seed(123456789)n”,
”    svi = SVI(model, guide, Adam({&quot;lr&quot;: 0.02}), Trace_ELBO())n”,
”    for epoch in range(num_epochs):n”,
”        pos = 0n”,
”        losses = []n”,
”        while pos &lt; full_size:n”,
”            subsample = torch.arange(pos, pos + batch_size)n”,
”            batch = data[:, pos:pos + batch_size]n”,
”            pos += batch_sizen”,
”            losses.append(svi.step(batch, subsample, full_size=full_size))n”,
”        epoch_loss = sum(losses) / len(losses)n”,
”        if epoch % 10 == 0:n”,
”            print(&quot;epoch {} loss = {}&quot;.format(epoch, epoch_loss / data.numel()))”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: null,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“train(guide)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Using EasyGuiden”,
“n”,
“Now let’s simplify using the <cite>&#64;easy_guide</cite> decorator. Our modifications are:n”,
“1. Decorate with <cite>&#64;easy_guide</cite> and add <cite>self</cite> to args.n”,
“2. Replace the <cite>Delta</cite> guide for drift with a simple <cite>map_estimate()</cite>.n”,
“3. Select a <cite>group</cite> of model sites and read their concatenated <cite>event_shape</cite>.n”,
“4. Replace the auxiliary site and <cite>Delta</cite> slices with a single <cite>group.sample()</cite>.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: null,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“&#64;easy_guide(model)n”,
“def guide(self, batch, subsample, full_size):n”,
”    # MAP estimate the drift.n”,
”    self.map_estimate(&quot;drift&quot;)n”,
“n”,
”    # Model local states using shared uncertainty + local mean.n”,
”    group = self.group(match=&quot;state_[0-9]*&quot;)  # Selects all local variables.n”,
”    cov_diag = pyro.param(&quot;state_cov_diag&quot;,n”,
”                          lambda: torch.full(group.event_shape, 0.01),n”,
”                          constraint=constraints.positive)n”,
”    cov_factor = pyro.param(&quot;state_cov_factor&quot;,n”,
”                            lambda: torch.randn(group.event_shape + (rank,)) * 0.01)n”,
”    with self.plate(&quot;data&quot;, full_size, subsample=subsample):n”,
”        # Sample local mean.n”,
”        loc = pyro.param(&quot;state_loc&quot;,n”,
”                         lambda: torch.full((full_size,) + group.event_shape, 0.5),n”,
”                         event_dim=1)n”,
”        # Automatically sample the joint latent, then unpack and replay model sites.n”,
”        group.sample(&quot;states&quot;, dist.LowRankMultivariateNormal(loc, cov_factor, cov_diag))”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Note we’ve used <cite>group.event_shape</cite> to determine the total flattened concatenated shape of all matched sites in the group.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: null,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“train(guide)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Amortized guidesn”,
“n”,
“<cite>EasyGuide</cite> also makes it easy to write amortized guides (guides where we learn a function that predicts latent variables from data, rather than learning one parameter per datapoint). Let’s modify the last guide to predict the latent <cite>loc</cite> as an affine function of observed data, rather than memorizing each data point’s latent variable. This amortized guide is more useful in practice because it can handle new data.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: null,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“&#64;easy_guide(model)n”,
“def guide(self, batch, subsample, full_size):n”,
”    num_time_steps, batch_size = batch.shapen”,
”    self.map_estimate(&quot;drift&quot;)n”,
“n”,
”    group = self.group(match=&quot;state_[0-9]*&quot;)n”,
”    cov_diag = pyro.param(&quot;state_cov_diag&quot;,n”,
”                          lambda: torch.full(group.event_shape, 0.01),n”,
”                          constraint=constraints.positive)n”,
”    cov_factor = pyro.param(&quot;state_cov_factor&quot;,n”,
”                            lambda: torch.randn(group.event_shape + (rank,)) * 0.01)n”,
“n”,
”    # Predict latent propensity as an affine function of observed data.n”,
”    if not hasattr(self, &quot;nn&quot;):n”,
”        self.nn = torch.nn.Linear(group.event_shape.numel(), group.event_shape.numel())n”,
”        self.nn.weight.data.fill_(1.0 / num_time_steps)n”,
”        self.nn.bias.data.fill_(-0.5)n”,
”    pyro.module(&quot;state_nn&quot;, self.nn)n”,
”    with self.plate(&quot;data&quot;, full_size, subsample=subsample):n”,
”        loc = self.nn(batch.t())n”,
”        group.sample(&quot;states&quot;, dist.LowRankMultivariateNormal(loc, cov_factor, cov_diag))”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: null,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“train(guide)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: null,
“metadata”: {},
“outputs”: [],
“source”: []</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>],
“metadata”: {</p>
<blockquote>
<div><dl class="simple">
<dt>“kernelspec”: {</dt><dd><p>“display_name”: “Python 3”,
“language”: “python”,
“name”: “python3”</p>
</dd>
</dl>
<p>},
“language_info”: {</p>
<blockquote>
<div><dl class="simple">
<dt>“codemirror_mode”: {</dt><dd><p>“name”: “ipython”,
“version”: 3</p>
</dd>
</dl>
<p>},
“file_extension”: “.py”,
“mimetype”: “text/x-python”,
“name”: “python”,
“nbconvert_exporter”: “python”,
“pygments_lexer”: “ipython3”,
“version”: “3.6.10”</p>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p>},
“nbformat”: 4,
“nbformat_minor”: 2</p>
</dd>
</dl>
<p>}</p>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mle_map.html" class="btn btn-neutral float-left" title="&lt;no title&gt;" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="custom_objectives.html" class="btn btn-neutral float-right" title="&lt;no title&gt;" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Pyro Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>