

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pyro.contrib.funsor, a new backend for Pyro - New primitives (Part 1) &mdash; Pyro Tutorials 1.6.0 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/pyro.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="pyro.contrib.funsor, a new backend for Pyro - Building inference algorithms (Part 2)" href="contrib_funsor_intro_ii.html" />
    <link rel="prev" title="Poutine: A Guide to Programming with Effect Handlers in Pyro" href="effect_handlers.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html">
          

          
            
            <img src="_static/pyro_logo_wide.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                1.6.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Introductory Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro_part_i.html">An Introduction to Models in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro_part_ii.html">An Introduction to Inference in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_i.html">SVI Part I: An Introduction to Stochastic Variational Inference in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_ii.html">SVI Part II: Conditional Independence, Subsampling, and Amortization</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_iii.html">SVI Part III: ELBO Gradient Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_iv.html">SVI Part IV: Tips and Tricks</a></li>
</ul>
<p class="caption"><span class="caption-text">Practical Pyro and PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="bayesian_regression.html">Bayesian Regression - Introduction (Part 1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayesian_regression_ii.html">Bayesian Regression - Inference Algorithms (Part 2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_shapes.html">Tensor shapes in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">Modules in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">Using the PyTorch JIT Compiler with Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_horovod.html">Example: distributed training via Horovod</a></li>
</ul>
<p class="caption"><span class="caption-text">Deep Generative Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="vae.html">Variational Autoencoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="ss-vae.html">The Semi-Supervised VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="cvae.html">Conditional Variational Auto-encoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="normalizing_flows_i.html">Normalizing Flows - Introduction (Part 1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dmm.html">Deep Markov Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="air.html">Attend Infer Repeat</a></li>
<li class="toctree-l1"><a class="reference internal" href="scanvi.html">Example: Single Cell RNA Sequencing Analysis with VAEs</a></li>
<li class="toctree-l1"><a class="reference internal" href="cevae.html">Example: Causal Effect VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_gamma.html">Example: Sparse Gamma Deep Exponential Family</a></li>
<li class="toctree-l1"><a class="reference internal" href="prodlda.html">Probabilistic Topic Modeling</a></li>
</ul>
<p class="caption"><span class="caption-text">Discrete Latent Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enumeration.html">Inference with Discrete Latent Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="gmm.html">Gaussian Mixture Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="dirichlet_process_mixture.html">Dirichlet Process Mixture Models in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="toy_mixture_model_discrete_enumeration.html">Example: Toy Mixture Model With Discrete Enumeration</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm.html">Example: Hidden Markov Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="capture_recapture.html">Example: Capture-Recapture Models (CJS Models)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mixed_hmm.html">Example: hierarchical mixed-effect hidden Markov models</a></li>
<li class="toctree-l1"><a class="reference internal" href="einsum.html">Example: Discrete Factor Graph Inference with Plated Einsum</a></li>
<li class="toctree-l1"><a class="reference internal" href="lda.html">Example: Amortized Latent Dirichlet Allocation</a></li>
</ul>
<p class="caption"><span class="caption-text">Customizing Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mle_map.html">MLE and MAP Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="easyguide.html">Writing guides using EasyGuide</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_objectives.html">Custom SVI Objectives</a></li>
<li class="toctree-l1"><a class="reference internal" href="boosting_bbvi.html">Boosting Black Box Variational Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="neutra.html">Example: Neural MCMC with NeuTraReparam</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_regression.html">Example: Sparse Bayesian Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="autoname_examples.html">Example: reducing boilerplate with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.autoname</span></code></a></li>
</ul>
<p class="caption"><span class="caption-text">Application: Time Series</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="forecasting_i.html">Forecasting I: univariate, heavy tailed</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_ii.html">Forecasting II: state space models</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_iii.html">Forecasting III: hierarchical models</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_dlm.html">Forecasting with Dynamic Linear Model (DLM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="stable.html">Levy Stable models of Stochastic Volatility</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecast_simple.html">Multivariate Forecasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="timeseries.html">Example: Gaussian Process Time Series Models</a></li>
</ul>
<p class="caption"><span class="caption-text">Application: Gaussian Processes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="gp.html">Gaussian Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="gplvm.html">Gaussian Process Latent Variable Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="bo.html">Bayesian Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="dkl.html">Example: Deep Kernel Learning</a></li>
</ul>
<p class="caption"><span class="caption-text">Application: Epidemiology</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="epi_intro.html">Epidemiological models: Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="epi_sir.html">Example: Univariate epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="epi_regional.html">Example: Regional epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="sir_hmc.html">Example: Epidemiological inference via HMC</a></li>
</ul>
<p class="caption"><span class="caption-text">Application: Experimental Design</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="working_memory.html">Designing Adaptive Experiments to Study Working Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="elections.html">Predicting the outcome of a US presidential election using Bayesian optimal experimental design</a></li>
</ul>
<p class="caption"><span class="caption-text">Application: Object Tracking</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tracking_1d.html">Tracking an Unknown Number of Objects</a></li>
<li class="toctree-l1"><a class="reference internal" href="ekf.html">Kalman Filter</a></li>
</ul>
<p class="caption"><span class="caption-text">Other Inference Algorithms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="baseball.html">Example: analyzing baseball stats with MCMC</a></li>
<li class="toctree-l1"><a class="reference internal" href="mcmc.html">Example: Inference with Markov Chain Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="lkj.html">Example: MCMC with an LKJ prior over covariances</a></li>
<li class="toctree-l1"><a class="reference internal" href="csis.html">Compiled Sequential Importance Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="smcfilter.html">Example: Sequential Monte Carlo Filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="inclined_plane.html">Example: importance sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="RSA-implicature.html">The Rational Speech Act framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="RSA-hyperbole.html">Understanding Hyperbole using RSA</a></li>
</ul>
<p class="caption"><span class="caption-text">Understanding Pyro's Internals</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="minipyro.html">Mini-Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="effect_handlers.html">Poutine: A Guide to Programming with Effect Handlers in Pyro</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#"><code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code>, a new backend for Pyro - New primitives (Part 1)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Reinterpreting-existing-Pyro-models-with-pyroapi">Reinterpreting existing Pyro models with <code class="docutils literal notranslate"><span class="pre">pyroapi</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#Two-new-primitives:-to_funsor-and-to_data">Two new primitives: <code class="docutils literal notranslate"><span class="pre">to_funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">to_data</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#Dealing-with-large-numbers-of-variables:-(re-)introducing-pyro.markov">Dealing with large numbers of variables: (re-)introducing <code class="docutils literal notranslate"><span class="pre">pyro.markov</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#Use-cases-beyond-enumeration:-global-and-visible-dimensions">Use cases beyond enumeration: global and visible dimensions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Global-dimensions">Global dimensions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Visible-dimensions">Visible dimensions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contrib_funsor_intro_ii.html"><code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code>, a new backend for Pyro - Building inference algorithms (Part 2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm_funsor.html">Example: hidden Markov models with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">pyroapi</span></code></a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pyro Tutorials</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li><code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code>, a new backend for Pyro - New primitives (Part 1)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/contrib_funsor_intro_i.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="pyro.contrib.funsor,-a-new-backend-for-Pyro---New-primitives-(Part-1)">
<h1><code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code>, a new backend for Pyro - New primitives (Part 1)<a class="headerlink" href="#pyro.contrib.funsor,-a-new-backend-for-Pyro---New-primitives-(Part-1)" title="Permalink to this headline">¶</a></h1>
<div class="section" id="Introduction">
<h2>Introduction<a class="headerlink" href="#Introduction" title="Permalink to this headline">¶</a></h2>
<p>In this tutorial we’ll cover the basics of <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code>, a new backend for the Pyro probabilistic programming system that is intended to replace the current internals of Pyro and significantly expand its capabilities as both a modelling tool and an inference research platform.</p>
<p>This tutorial is aimed at readers interested in developing custom inference algorithms and understanding Pyro’s current and future internals. As such, the material here assumes some familiarity with the <a class="reference external" href="https://pyro.ai/api/">generic Pyro API package</a> <code class="docutils literal notranslate"><span class="pre">pyroapi</span></code> and with Funsor. Additional documentation for Funsor can be found on <a class="reference external" href="https://funsor.pyro.ai/en/stable/">the Pyro website</a>, on <a class="reference external" href="https://github.com/pyro-ppl/funsor">GitHub</a>, and in the research paper <a class="reference external" href="https://arxiv.org/abs/1910.10775">“Functional Tensors for
Probabilistic Programming.”</a> Those who are less interested in such details should find that they can already use the general-purpose algorithms in <code class="docutils literal notranslate"><span class="pre">contrib.funsor</span></code> with their existing Pyro models via <code class="docutils literal notranslate"><span class="pre">pyroapi</span></code>.</p>
</div>
<div class="section" id="Reinterpreting-existing-Pyro-models-with-pyroapi">
<h2>Reinterpreting existing Pyro models with <code class="docutils literal notranslate"><span class="pre">pyroapi</span></code><a class="headerlink" href="#Reinterpreting-existing-Pyro-models-with-pyroapi" title="Permalink to this headline">¶</a></h2>
<p>The new backend uses the <code class="docutils literal notranslate"><span class="pre">pyroapi</span></code> package to integrate with existing Pyro code.</p>
<p>First, we import some dependencies:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">funsor</span>
<span class="kn">from</span> <span class="nn">pyro</span> <span class="kn">import</span> <span class="n">set_rng_seed</span> <span class="k">as</span> <span class="n">pyro_set_rng_seed</span>

<span class="n">funsor</span><span class="o">.</span><span class="n">set_backend</span><span class="p">(</span><span class="s2">&quot;torch&quot;</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">set_default_dtype</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">pyro_set_rng_seed</span><span class="p">(</span><span class="mi">101</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Importing <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code> registers the <code class="docutils literal notranslate"><span class="pre">&quot;contrib.funsor&quot;</span></code> backend with <code class="docutils literal notranslate"><span class="pre">pyroapi</span></code>, which can now be passed as an argument to the <code class="docutils literal notranslate"><span class="pre">pyroapi.pyro_backend</span></code> context manager.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pyro.contrib.funsor</span>
<span class="kn">import</span> <span class="nn">pyroapi</span>
<span class="kn">from</span> <span class="nn">pyroapi</span> <span class="kn">import</span> <span class="n">handlers</span><span class="p">,</span> <span class="n">infer</span><span class="p">,</span> <span class="n">ops</span><span class="p">,</span> <span class="n">optim</span><span class="p">,</span> <span class="n">pyro</span>
<span class="kn">from</span> <span class="nn">pyroapi</span> <span class="kn">import</span> <span class="n">distributions</span> <span class="k">as</span> <span class="n">dist</span>

<span class="c1"># this is already done in pyro.contrib.funsor, but we repeat it here</span>
<span class="n">pyroapi</span><span class="o">.</span><span class="n">register_backend</span><span class="p">(</span><span class="s2">&quot;contrib.funsor&quot;</span><span class="p">,</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">distributions</span><span class="o">=</span><span class="s2">&quot;pyro.distributions&quot;</span><span class="p">,</span>
    <span class="n">handlers</span><span class="o">=</span><span class="s2">&quot;pyro.contrib.funsor.handlers&quot;</span><span class="p">,</span>
    <span class="n">infer</span><span class="o">=</span><span class="s2">&quot;pyro.contrib.funsor.infer&quot;</span><span class="p">,</span>
    <span class="n">ops</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span>
    <span class="n">optim</span><span class="o">=</span><span class="s2">&quot;pyro.optim&quot;</span><span class="p">,</span>
    <span class="n">pyro</span><span class="o">=</span><span class="s2">&quot;pyro.contrib.funsor&quot;</span><span class="p">,</span>
<span class="p">))</span>
</pre></div>
</div>
</div>
<p>And we’re off! From here on, any <code class="docutils literal notranslate"><span class="pre">pyro.(...)</span></code> statement should be understood as dispatching to the new backend.</p>
</div>
<div class="section" id="Two-new-primitives:-to_funsor-and-to_data">
<h2>Two new primitives: <code class="docutils literal notranslate"><span class="pre">to_funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">to_data</span></code><a class="headerlink" href="#Two-new-primitives:-to_funsor-and-to_data" title="Permalink to this headline">¶</a></h2>
<p>The first and most important new concept in <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code> is the new pair of primitives <code class="docutils literal notranslate"><span class="pre">pyro.to_funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">pyro.to_data</span></code>.</p>
<p>These are <em>effectful</em> versions of <code class="docutils literal notranslate"><span class="pre">funsor.to_funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">funsor.to_data</span></code>, i.e. versions whose behavior can be intercepted, controlled, or used to trigger side effects by Pyro’s library of algebraic effect handlers. Let’s briefly review these two underlying functions before diving into the effectful versions in <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code>.</p>
<p>As one might expect from the name, <code class="docutils literal notranslate"><span class="pre">to_funsor</span></code> takes as inputs objects that are not <code class="docutils literal notranslate"><span class="pre">funsor.Funsor</span></code>s and attempts to convert them into Funsor terms. For example, calling <code class="docutils literal notranslate"><span class="pre">funsor.to_funsor</span></code> on a Python number converts it to a <code class="docutils literal notranslate"><span class="pre">funsor.terms.Number</span></code> object:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">funsor_one</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">to_funsor</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">funsor_one</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">funsor_one</span><span class="p">))</span>

<span class="n">funsor_two</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">to_funsor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">funsor_two</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">funsor_two</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1.0 &lt;class &#39;funsor.terms.Number&#39;&gt;
tensor(2.) &lt;class &#39;funsor.tensor.Tensor&#39;&gt;
</pre></div></div>
</div>
<p>Similarly ,calling <code class="docutils literal notranslate"><span class="pre">funsor.to_data</span></code> on an atomic <code class="docutils literal notranslate"><span class="pre">funsor.Funsor</span></code> converts it to a regular Python object like a <code class="docutils literal notranslate"><span class="pre">float</span></code> or a <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">data_one</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">funsor</span><span class="o">.</span><span class="n">terms</span><span class="o">.</span><span class="n">Number</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;real&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data_one</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">data_one</span><span class="p">))</span>

<span class="n">data_two</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.</span><span class="p">),</span> <span class="n">OrderedDict</span><span class="p">(),</span> <span class="s1">&#39;real&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data_two</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">data_two</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1.0 &lt;class &#39;float&#39;&gt;
tensor(2.) &lt;class &#39;torch.Tensor&#39;&gt;
</pre></div></div>
</div>
<p>In many cases it is necessary to provide an output type to uniquely convert a piece of data to a <code class="docutils literal notranslate"><span class="pre">funsor.Funsor</span></code>. This also means that, strictly speaking, <code class="docutils literal notranslate"><span class="pre">funsor.to_funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">funsor.to_data</span></code> are not inverses. For example, <code class="docutils literal notranslate"><span class="pre">funsor.to_funsor</span></code> will automatically convert Python strings to <code class="docutils literal notranslate"><span class="pre">funsor.Variable</span></code>s, but only when given an output <code class="docutils literal notranslate"><span class="pre">funsor.domains.Domain</span></code>, which serves as the type of the variable:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">var_x</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">to_funsor</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Reals</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">var_x</span><span class="p">,</span> <span class="n">var_x</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">var_x</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
x OrderedDict([(&#39;x&#39;, Reals[2])]) Reals[2]
</pre></div></div>
</div>
<p>However, it is often impossible to convert objects to and from Funsor expressions uniquely without additional type information about inputs, as in the following example of a <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>, which could be converted to a <code class="docutils literal notranslate"><span class="pre">funsor.Tensor</span></code> in several ways.</p>
<p>To resolve this ambiguity, we need to provide <code class="docutils literal notranslate"><span class="pre">to_funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">to_data</span></code> with type information that describes how to convert positional dimensions to and from unordered named Funsor dimensions. This information comes in the form of dictionaries mapping batch dimensions to dimension names or vice versa.</p>
<p>A key property of these mappings is that use the convention that dimension indices refer to <em>batch dimensions</em>, or dimensions not included in the <em>output shape</em>, which is treated as referring to the rightmost portion of the underlying PyTorch tensor shape, as illustrated in the example below.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">ambiguous_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Ambiguous tensor: shape = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ambiguous_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

<span class="c1"># case 1: treat all dimensions as output/event dimensions</span>
<span class="n">funsor1</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">to_funsor</span><span class="p">(</span><span class="n">ambiguous_tensor</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Reals</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Case 1: inputs = </span><span class="si">{}</span><span class="s2">, output = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">funsor1</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">funsor1</span><span class="o">.</span><span class="n">output</span><span class="p">))</span>

<span class="c1"># case 2: treat the leftmost dimension as a batch dimension</span>
<span class="c1"># note that dimension -1 in dim_to_name here refers to the rightmost *batch dimension*,</span>
<span class="c1"># i.e. dimension -3 of ambiguous_tensor, the rightmost dimension not included in the output shape.</span>
<span class="n">funsor2</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">to_funsor</span><span class="p">(</span><span class="n">ambiguous_tensor</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Reals</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dim_to_name</span><span class="o">=</span><span class="p">{</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;a&quot;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Case 2: inputs = </span><span class="si">{}</span><span class="s2">, output = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">funsor2</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">funsor2</span><span class="o">.</span><span class="n">output</span><span class="p">))</span>

<span class="c1"># case 3: treat the leftmost 2 dimensions as batch dimensions; empty batch dimensions are ignored</span>
<span class="c1"># note that dimensions -1 and -2 in dim_to_name here refer to the rightmost *batch dimensions*,</span>
<span class="c1"># i.e. dimensions -2 and -3 of ambiguous_tensor, the rightmost dimensions not included in the output shape.</span>
<span class="n">funsor3</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">to_funsor</span><span class="p">(</span><span class="n">ambiguous_tensor</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Reals</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">dim_to_name</span><span class="o">=</span><span class="p">{</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">:</span> <span class="s2">&quot;a&quot;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Case 3: inputs = </span><span class="si">{}</span><span class="s2">, output = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">funsor3</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">funsor3</span><span class="o">.</span><span class="n">output</span><span class="p">))</span>

<span class="c1"># case 4: treat all dimensions as batch dimensions; empty batch dimensions are ignored</span>
<span class="c1"># note that dimensions -1, -2 and -3 in dim_to_name here refer to the rightmost *batch dimensions*,</span>
<span class="c1"># i.e. dimensions -1, -2 and -3 of ambiguous_tensor, the rightmost dimensions not included in the output shape.</span>
<span class="n">funsor4</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">to_funsor</span><span class="p">(</span><span class="n">ambiguous_tensor</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="n">dim_to_name</span><span class="o">=</span><span class="p">{</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">:</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">:</span> <span class="s2">&quot;a&quot;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Case 4: inputs = </span><span class="si">{}</span><span class="s2">, output = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">funsor4</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">funsor4</span><span class="o">.</span><span class="n">output</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Ambiguous tensor: shape = torch.Size([3, 1, 2])
Case 1: inputs = OrderedDict(), output = Reals[3,1,2]
Case 2: inputs = OrderedDict([(&#39;a&#39;, Bint[3, ])]), output = Reals[1,2]
Case 3: inputs = OrderedDict([(&#39;a&#39;, Bint[3, ])]), output = Reals[2]
Case 4: inputs = OrderedDict([(&#39;a&#39;, Bint[3, ]), (&#39;c&#39;, Bint[2, ])]), output = Real
</pre></div></div>
</div>
<p>Similar ambiguity exists for <code class="docutils literal notranslate"><span class="pre">to_data</span></code>: the <code class="docutils literal notranslate"><span class="pre">inputs</span></code> of a <code class="docutils literal notranslate"><span class="pre">funsor.Funsor</span></code> are ordered arbitrarily, and empty dimensions in the data are squeezed away, so a mapping from names to batch dimensions must be provided to ensure unique conversion:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">ambiguous_funsor</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">b</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="s1">&#39;real&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Ambiguous funsor: inputs = </span><span class="si">{}</span><span class="s2">, shape = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ambiguous_funsor</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">ambiguous_funsor</span><span class="o">.</span><span class="n">output</span><span class="p">))</span>

<span class="c1"># case 1: the simplest version</span>
<span class="n">tensor1</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">ambiguous_funsor</span><span class="p">,</span> <span class="n">name_to_dim</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Case 1: shape = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tensor1</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

<span class="c1"># case 2: an empty dimension between a and b</span>
<span class="n">tensor2</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">ambiguous_funsor</span><span class="p">,</span> <span class="n">name_to_dim</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Case 2: shape = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tensor2</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

<span class="c1"># case 3: permuting the input dimensions</span>
<span class="n">tensor3</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">ambiguous_funsor</span><span class="p">,</span> <span class="n">name_to_dim</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">2</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Case 3: shape = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tensor3</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Ambiguous funsor: inputs = OrderedDict([(&#39;a&#39;, Bint[3, ]), (&#39;b&#39;, Bint[2, ])]), shape = Real
Case 1: shape = torch.Size([3, 2])
Case 2: shape = torch.Size([3, 1, 2])
Case 3: shape = torch.Size([2, 3])
</pre></div></div>
</div>
<p>Maintaining and updating this information efficiently becomes tedious and error-prone as the number of conversions increases. Fortunately, it can be automated away completely. Consider the following example:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">name_to_dim</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>

<span class="n">funsor_x</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,)),</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="s1">&#39;real&#39;</span><span class="p">)</span>
<span class="n">name_to_dim</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">})</span>
<span class="n">tensor_x</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">funsor_x</span><span class="p">,</span> <span class="n">name_to_dim</span><span class="o">=</span><span class="n">name_to_dim</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">name_to_dim</span><span class="p">,</span> <span class="n">funsor_x</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">tensor_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">funsor_y</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="s1">&#39;real&#39;</span><span class="p">)</span>
<span class="n">name_to_dim</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">2</span><span class="p">})</span>
<span class="n">tensor_y</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">funsor_y</span><span class="p">,</span> <span class="n">name_to_dim</span><span class="o">=</span><span class="n">name_to_dim</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">name_to_dim</span><span class="p">,</span> <span class="n">funsor_y</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">tensor_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">funsor_z</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">z</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">3</span><span class="p">]),</span> <span class="s1">&#39;real&#39;</span><span class="p">)</span>
<span class="n">name_to_dim</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;z&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">3</span><span class="p">})</span>
<span class="n">tensor_z</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">funsor_z</span><span class="p">,</span> <span class="n">name_to_dim</span><span class="o">=</span><span class="n">name_to_dim</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">name_to_dim</span><span class="p">,</span> <span class="n">funsor_z</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">tensor_z</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
OrderedDict([(&#39;x&#39;, -1)]) OrderedDict([(&#39;x&#39;, Bint[2, ])]) torch.Size([2])
OrderedDict([(&#39;x&#39;, -1), (&#39;y&#39;, -2)]) OrderedDict([(&#39;y&#39;, Bint[3, ]), (&#39;x&#39;, Bint[2, ])]) torch.Size([3, 2])
OrderedDict([(&#39;x&#39;, -1), (&#39;y&#39;, -2), (&#39;z&#39;, -3)]) OrderedDict([(&#39;z&#39;, Bint[2, ]), (&#39;y&#39;, Bint[3, ])]) torch.Size([2, 3, 1])
</pre></div></div>
</div>
<p>This is exactly the functionality provided by <code class="docutils literal notranslate"><span class="pre">pyro.to_funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">pyro.to_data</span></code>, as we can see by using them in the previous example and removing the manual updates. We must also wrap the function in a <code class="docutils literal notranslate"><span class="pre">handlers.named</span></code> effect handler to ensure that the dimension dictionaries do not persist beyond the function body.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">pyroapi</span><span class="o">.</span><span class="n">pyro_backend</span><span class="p">(</span><span class="s2">&quot;contrib.funsor&quot;</span><span class="p">),</span> <span class="n">handlers</span><span class="o">.</span><span class="n">named</span><span class="p">():</span>
    <span class="n">funsor_x</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,)),</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="s1">&#39;real&#39;</span><span class="p">)</span>
    <span class="n">tensor_x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">funsor_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">funsor_x</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">tensor_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">funsor_y</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="s1">&#39;real&#39;</span><span class="p">)</span>
    <span class="n">tensor_y</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">funsor_y</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">funsor_y</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">tensor_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">funsor_z</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">z</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">3</span><span class="p">]),</span> <span class="s1">&#39;real&#39;</span><span class="p">)</span>
    <span class="n">tensor_z</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">funsor_z</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">funsor_z</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">tensor_z</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
OrderedDict([(&#39;x&#39;, Bint[2, ])]) torch.Size([2, 1, 1, 1, 1])
OrderedDict([(&#39;y&#39;, Bint[3, ]), (&#39;x&#39;, Bint[2, ])]) torch.Size([3, 2, 1, 1, 1, 1])
OrderedDict([(&#39;z&#39;, Bint[2, ]), (&#39;y&#39;, Bint[3, ])]) torch.Size([2, 3, 1, 1, 1, 1, 1])
</pre></div></div>
</div>
<p>Critically, <code class="docutils literal notranslate"><span class="pre">pyro.to_funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">pyro.to_data</span></code> use and update the same bidirectional mapping between names and dimensions, allowing them to be combined intuitively. A typical usage pattern, and one that <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code> uses heavily in its inference algorithm implementations, is to create a <code class="docutils literal notranslate"><span class="pre">funsor.Funsor</span></code> term directly with a new named dimension and call <code class="docutils literal notranslate"><span class="pre">pyro.to_data</span></code> on it, perform some PyTorch computations, and call <code class="docutils literal notranslate"><span class="pre">pyro.to_funsor</span></code> on the result:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">pyroapi</span><span class="o">.</span><span class="n">pyro_backend</span><span class="p">(</span><span class="s2">&quot;contrib.funsor&quot;</span><span class="p">),</span> <span class="n">handlers</span><span class="o">.</span><span class="n">named</span><span class="p">():</span>

    <span class="n">probs</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]),</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">3</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">probs</span><span class="p">),</span> <span class="n">probs</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">probs</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]),</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">4</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

    <span class="n">dx</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">pyro</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">probs</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">dx</span><span class="p">),</span> <span class="n">dx</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>

    <span class="n">px</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">to_funsor</span><span class="p">(</span><span class="n">dx</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">pyro</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="n">output</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Real</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">px</span><span class="p">),</span> <span class="n">px</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">px</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;class &#39;funsor.tensor.Tensor&#39;&gt; OrderedDict([(&#39;batch&#39;, Bint[3, ])]) Real
&lt;class &#39;funsor.tensor.Tensor&#39;&gt; OrderedDict([(&#39;x&#39;, Bint[4, ])]) Real
&lt;class &#39;pyro.distributions.torch.Bernoulli&#39;&gt; torch.Size([3, 1, 1, 1, 1])
&lt;class &#39;funsor.tensor.Tensor&#39;&gt; OrderedDict([(&#39;x&#39;, Bint[4, ]), (&#39;batch&#39;, Bint[3, ])]) Real
</pre></div></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">pyro.to_funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">pyro.to_data</span></code> treat the keys in their name-to-dim mappings as references to the input’s batch shape, but treats the values as references to the globally consistent name-dim mapping. This may be useful for complicated computations that involve a mixture of PyTorch and Funsor operations.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">pyroapi</span><span class="o">.</span><span class="n">pyro_backend</span><span class="p">(</span><span class="s2">&quot;contrib.funsor&quot;</span><span class="p">),</span> <span class="n">handlers</span><span class="o">.</span><span class="n">named</span><span class="p">():</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">to_funsor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]),</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="n">dim_to_name</span><span class="o">=</span><span class="p">{</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;x&quot;</span><span class="p">})</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x: &quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

    <span class="n">px</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">to_funsor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Real</span><span class="p">,</span> <span class="n">dim_to_name</span><span class="o">=</span><span class="p">{</span><span class="o">-</span><span class="mi">2</span><span class="p">:</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;y&quot;</span><span class="p">})</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;px: &quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">px</span><span class="p">),</span> <span class="n">px</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">px</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
x:  &lt;class &#39;funsor.tensor.Tensor&#39;&gt; OrderedDict([(&#39;x&#39;, Bint[2, ])]) Real
px:  &lt;class &#39;funsor.tensor.Tensor&#39;&gt; OrderedDict([(&#39;x&#39;, Bint[2, ]), (&#39;y&#39;, Bint[3, ])]) Real
</pre></div></div>
</div>
</div>
<div class="section" id="Dealing-with-large-numbers-of-variables:-(re-)introducing-pyro.markov">
<h2>Dealing with large numbers of variables: (re-)introducing <code class="docutils literal notranslate"><span class="pre">pyro.markov</span></code><a class="headerlink" href="#Dealing-with-large-numbers-of-variables:-(re-)introducing-pyro.markov" title="Permalink to this headline">¶</a></h2>
<p>So far, so good. However, what if the number of different named dimensions continues to increase? We face two problems: first, reusing the fixed number of available positional dimensions (25 in PyTorch), and second, computing shape information with time complexity that is independent of the number of variables.</p>
<p>A fully general automated solution to this problem would require deeper integration with Python or PyTorch. Instead, as an intermediate solution, we introduce the second key concept in <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code>: the <code class="docutils literal notranslate"><span class="pre">pyro.markov</span></code> annotation, a way to indicate the shelf life of certain variables. <code class="docutils literal notranslate"><span class="pre">pyro.markov</span></code> is already part of Pyro (see enumeration tutorial) but the implementation in <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code> is fresh.</p>
<p>The primary constraint on the design of <code class="docutils literal notranslate"><span class="pre">pyro.markov</span></code> is backwards compatibility: in order for <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code> to be compatible with the large range of existing Pyro models, the new implementation had to match the shape semantics of Pyro’s existing enumeration machinery as closely as possible.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">pyroapi</span><span class="o">.</span><span class="n">pyro_backend</span><span class="p">(</span><span class="s2">&quot;contrib.funsor&quot;</span><span class="p">),</span> <span class="n">handlers</span><span class="o">.</span><span class="n">named</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">pyro</span><span class="o">.</span><span class="n">markov</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]),</span> <span class="n">OrderedDict</span><span class="p">({</span><span class="s2">&quot;x</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">):</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">2</span><span class="p">]})))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of x[</span><span class="si">{}</span><span class="s2">]: &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)),</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Shape of x[0]:  torch.Size([2, 1, 1, 1, 1])
Shape of x[1]:  torch.Size([2, 1, 1, 1, 1, 1])
Shape of x[2]:  torch.Size([2, 1, 1, 1, 1])
Shape of x[3]:  torch.Size([2, 1, 1, 1, 1, 1])
Shape of x[4]:  torch.Size([2, 1, 1, 1, 1])
Shape of x[5]:  torch.Size([2, 1, 1, 1, 1, 1])
Shape of x[6]:  torch.Size([2, 1, 1, 1, 1])
Shape of x[7]:  torch.Size([2, 1, 1, 1, 1, 1])
Shape of x[8]:  torch.Size([2, 1, 1, 1, 1])
Shape of x[9]:  torch.Size([2, 1, 1, 1, 1, 1])
</pre></div></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">pyro.markov</span></code> is a versatile piece of syntax that can be used as a context manager, a decorator, or an iterator. It is important to understand that <code class="docutils literal notranslate"><span class="pre">pyro.markov</span></code>’s only functionality at present is tracking variable usage, not directly indicating conditional independence properties to inference algorithms, and as such it is only necessary to add enough annotations to ensure that tensors have correct shapes, rather than attempting to manually encode as much dependency information as
possible.</p>
<p><code class="docutils literal notranslate"><span class="pre">pyro.markov</span></code> takes an additional argument <code class="docutils literal notranslate"><span class="pre">history</span></code> that determines the number of previous <code class="docutils literal notranslate"><span class="pre">pyro.markov</span></code> contexts to take into account when building the mapping between names and dimensions at a given <code class="docutils literal notranslate"><span class="pre">pyro.to_funsor</span></code>/<code class="docutils literal notranslate"><span class="pre">pyro.to_data</span></code> call.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">pyroapi</span><span class="o">.</span><span class="n">pyro_backend</span><span class="p">(</span><span class="s2">&quot;contrib.funsor&quot;</span><span class="p">),</span> <span class="n">handlers</span><span class="o">.</span><span class="n">named</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">pyro</span><span class="o">.</span><span class="n">markov</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">history</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]),</span> <span class="n">OrderedDict</span><span class="p">({</span><span class="s2">&quot;x</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">):</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">2</span><span class="p">]})))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of x[</span><span class="si">{}</span><span class="s2">]: &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)),</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Shape of x[0]:  torch.Size([2, 1, 1, 1, 1])
Shape of x[1]:  torch.Size([2, 1, 1, 1, 1, 1])
Shape of x[2]:  torch.Size([2, 1, 1, 1, 1, 1, 1])
Shape of x[3]:  torch.Size([2, 1, 1, 1, 1])
Shape of x[4]:  torch.Size([2, 1, 1, 1, 1, 1])
Shape of x[5]:  torch.Size([2, 1, 1, 1, 1, 1, 1])
Shape of x[6]:  torch.Size([2, 1, 1, 1, 1])
Shape of x[7]:  torch.Size([2, 1, 1, 1, 1, 1])
Shape of x[8]:  torch.Size([2, 1, 1, 1, 1, 1, 1])
Shape of x[9]:  torch.Size([2, 1, 1, 1, 1])
</pre></div></div>
</div>
</div>
<div class="section" id="Use-cases-beyond-enumeration:-global-and-visible-dimensions">
<h2>Use cases beyond enumeration: global and visible dimensions<a class="headerlink" href="#Use-cases-beyond-enumeration:-global-and-visible-dimensions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="Global-dimensions">
<h3>Global dimensions<a class="headerlink" href="#Global-dimensions" title="Permalink to this headline">¶</a></h3>
<p>It is sometimes useful to have dimensions and variables ignore the <code class="docutils literal notranslate"><span class="pre">pyro.markov</span></code> structure of a program and remain active in arbitrarily deeply nested <code class="docutils literal notranslate"><span class="pre">markov</span></code> and <code class="docutils literal notranslate"><span class="pre">named</span></code> contexts. For example, suppose we wanted to draw a batch of samples from a Pyro model’s joint distribution. To accomplish this we indicate to <code class="docutils literal notranslate"><span class="pre">pyro.to_data</span></code> that a dimension should be treated as “global” (<code class="docutils literal notranslate"><span class="pre">DimType.GLOBAL</span></code>) via the <code class="docutils literal notranslate"><span class="pre">dim_type</span></code> keyword argument.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pyro.contrib.funsor.handlers.runtime</span> <span class="kn">import</span> <span class="n">_DIM_STACK</span><span class="p">,</span> <span class="n">DimType</span>

<span class="k">with</span> <span class="n">pyroapi</span><span class="o">.</span><span class="n">pyro_backend</span><span class="p">(</span><span class="s2">&quot;contrib.funsor&quot;</span><span class="p">),</span> <span class="n">handlers</span><span class="o">.</span><span class="n">named</span><span class="p">():</span>
    <span class="n">funsor_particle_ids</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">10</span><span class="p">]))</span>
    <span class="n">tensor_particle_ids</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">funsor_particle_ids</span><span class="p">,</span> <span class="n">dim_type</span><span class="o">=</span><span class="n">DimType</span><span class="o">.</span><span class="n">GLOBAL</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;New global dimension: &quot;</span><span class="p">,</span> <span class="n">funsor_particle_ids</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">tensor_particle_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
New global dimension:  OrderedDict([(&#39;n&#39;, Bint[10, ])]) torch.Size([10, 1, 1, 1, 1])
</pre></div></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">pyro.markov</span></code> does the hard work of automatically managing local dimensions, but because global dimensions ignore this structure, they must be deallocated manually or they will persist until the last active effect handler exits, just as global variables in Python persist until a program execution finishes.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pyro.contrib.funsor.handlers.runtime</span> <span class="kn">import</span> <span class="n">_DIM_STACK</span><span class="p">,</span> <span class="n">DimType</span>

<span class="k">with</span> <span class="n">pyroapi</span><span class="o">.</span><span class="n">pyro_backend</span><span class="p">(</span><span class="s2">&quot;contrib.funsor&quot;</span><span class="p">),</span> <span class="n">handlers</span><span class="o">.</span><span class="n">named</span><span class="p">():</span>

    <span class="n">funsor_plate1_ids</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">plate1</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">10</span><span class="p">]))</span>
    <span class="n">tensor_plate1_ids</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">funsor_plate1_ids</span><span class="p">,</span> <span class="n">dim_type</span><span class="o">=</span><span class="n">DimType</span><span class="o">.</span><span class="n">GLOBAL</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;New global dimension: &quot;</span><span class="p">,</span> <span class="n">funsor_plate1_ids</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">tensor_plate1_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">funsor_plate2_ids</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">9</span><span class="p">),</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">plate2</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">9</span><span class="p">]))</span>
    <span class="n">tensor_plate2_ids</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">funsor_plate2_ids</span><span class="p">,</span> <span class="n">dim_type</span><span class="o">=</span><span class="n">DimType</span><span class="o">.</span><span class="n">GLOBAL</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Another new global dimension: &quot;</span><span class="p">,</span> <span class="n">funsor_plate2_ids</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">tensor_plate2_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">del</span> <span class="n">_DIM_STACK</span><span class="o">.</span><span class="n">global_frame</span><span class="p">[</span><span class="s2">&quot;plate1&quot;</span><span class="p">]</span>

    <span class="n">funsor_plate3_ids</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">plate3</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">10</span><span class="p">]))</span>
    <span class="n">tensor_plate3_ids</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">funsor_plate1_ids</span><span class="p">,</span> <span class="n">dim_type</span><span class="o">=</span><span class="n">DimType</span><span class="o">.</span><span class="n">GLOBAL</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A third new global dimension after recycling: &quot;</span><span class="p">,</span> <span class="n">funsor_plate3_ids</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">tensor_plate3_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
New global dimension:  OrderedDict([(&#39;plate1&#39;, Bint[10, ])]) torch.Size([10, 1, 1, 1, 1])
Another new global dimension:  OrderedDict([(&#39;plate2&#39;, Bint[9, ])]) torch.Size([9, 1, 1, 1, 1, 1])
A third new global dimension after recycling:  OrderedDict([(&#39;plate3&#39;, Bint[10, ])]) torch.Size([10, 1, 1, 1, 1])
</pre></div></div>
</div>
<p>Performing this deallocation directly is often unnecessary, and we include this interaction primarily to illuminate the internals of <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code>. Instead, effect handlers that introduce global dimensions, like <code class="docutils literal notranslate"><span class="pre">pyro.plate</span></code>, may inherit from the <code class="docutils literal notranslate"><span class="pre">GlobalNamedMessenger</span></code> effect handler which deallocates global dimensions generically upon entry and exit. We will see an example of this in the next tutorial.</p>
</div>
<div class="section" id="Visible-dimensions">
<h3>Visible dimensions<a class="headerlink" href="#Visible-dimensions" title="Permalink to this headline">¶</a></h3>
<p>We might also wish to preserve the meaning of the shape of a tensor of data. For this we indicate to <code class="docutils literal notranslate"><span class="pre">pyro.to_data</span></code> that a dimension should be treated as not merely global but “visible” (<code class="docutils literal notranslate"><span class="pre">DimTypes.VISIBLE</span></code>). By default, the 4 rightmost batch dimensions are reserved as “visible” dimensions, but this can be changed by setting the <code class="docutils literal notranslate"><span class="pre">first_available_dim</span></code> attribute of the global state object <code class="docutils literal notranslate"><span class="pre">_DIM_STACK</span></code>.</p>
<p>Users who have come across <code class="docutils literal notranslate"><span class="pre">pyro.infer.TraceEnum_ELBO</span></code>’s <code class="docutils literal notranslate"><span class="pre">max_plate_nesting</span></code> argument are already familiar with this distinction.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prev_first_available_dim</span> <span class="o">=</span> <span class="n">_DIM_STACK</span><span class="o">.</span><span class="n">set_first_available_dim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>

<span class="k">with</span> <span class="n">pyroapi</span><span class="o">.</span><span class="n">pyro_backend</span><span class="p">(</span><span class="s2">&quot;contrib.funsor&quot;</span><span class="p">),</span> <span class="n">handlers</span><span class="o">.</span><span class="n">named</span><span class="p">():</span>

    <span class="n">funsor_local_ids</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">9</span><span class="p">),</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">9</span><span class="p">]))</span>
    <span class="n">tensor_local_ids</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">funsor_local_ids</span><span class="p">,</span> <span class="n">dim_type</span><span class="o">=</span><span class="n">DimType</span><span class="o">.</span><span class="n">LOCAL</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tensor with new local dimension: &quot;</span><span class="p">,</span> <span class="n">funsor_local_ids</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">tensor_local_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">funsor_global_ids</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">10</span><span class="p">]))</span>
    <span class="n">tensor_global_ids</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">funsor_global_ids</span><span class="p">,</span> <span class="n">dim_type</span><span class="o">=</span><span class="n">DimType</span><span class="o">.</span><span class="n">GLOBAL</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tensor with new global dimension: &quot;</span><span class="p">,</span> <span class="n">funsor_global_ids</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">tensor_global_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">funsor_data_ids</span> <span class="o">=</span> <span class="n">funsor</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">11</span><span class="p">),</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">funsor</span><span class="o">.</span><span class="n">Bint</span><span class="p">[</span><span class="mi">11</span><span class="p">]))</span>
    <span class="n">tensor_data_ids</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">to_data</span><span class="p">(</span><span class="n">funsor_data_ids</span><span class="p">,</span> <span class="n">dim_type</span><span class="o">=</span><span class="n">DimType</span><span class="o">.</span><span class="n">VISIBLE</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tensor with new visible dimension: &quot;</span><span class="p">,</span> <span class="n">funsor_data_ids</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">tensor_data_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># we also need to reset the first_available_dim after we&#39;re done</span>
<span class="n">_DIM_STACK</span><span class="o">.</span><span class="n">set_first_available_dim</span><span class="p">(</span><span class="n">prev_first_available_dim</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Tensor with new local dimension:  OrderedDict([(&#39;k&#39;, Bint[9, ])]) torch.Size([9, 1])
Tensor with new global dimension:  OrderedDict([(&#39;n&#39;, Bint[10, ])]) torch.Size([10, 1, 1])
Tensor with new visible dimension:  OrderedDict([(&#39;m&#39;, Bint[11, ])]) torch.Size([11])
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-5
</pre></div></div>
</div>
<p>Visible dimensions are also global and must therefore be deallocated manually or they will persist until the last effect handler exits, as in the previous example. You may be thinking by now that Funsor’s dimension names behave sort of like Python variables, with scopes and persistent meanings across expressions; indeed, this observation is the key insight behind the design of Funsor.</p>
<p>Fortunately, interacting directly with the dimension allocator is almost always unnecessary, and as in the previous section we include it here only to illuminate the inner workings of <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code>; rather, effect handlers like <code class="docutils literal notranslate"><span class="pre">pyro.handlers.enum</span></code> that may introduce non-visible dimensions that could conflict with visible dimensions should inherit from the base <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor.handlers.named_messenger.NamedMessenger</span></code> effect handler.</p>
<p>However, building a bit of intuition for the inner workings of the dimension allocator will make it easier to use the new primitives in <code class="docutils literal notranslate"><span class="pre">contrib.funsor</span></code> to build powerful new custom inference engines. We will see an example of one such inference engine in the next tutorial.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="contrib_funsor_intro_ii.html" class="btn btn-neutral float-right" title="pyro.contrib.funsor, a new backend for Pyro - Building inference algorithms (Part 2)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="effect_handlers.html" class="btn btn-neutral float-left" title="Poutine: A Guide to Programming with Effect Handlers in Pyro" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright Pyro Contributors

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>