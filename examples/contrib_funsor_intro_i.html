<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>&lt;no title&gt; &mdash; Pyro Tutorials 1.8.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/pyro.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="&lt;no title&gt;" href="contrib_funsor_intro_ii.html" />
    <link rel="prev" title="&lt;no title&gt;" href="effect_handlers.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html">
            <img src="_static/pyro_logo_wide.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                1.8.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Practical Pyro and PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="svi_horovod.html">Example: distributed training via Horovod</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deep Generative Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cevae.html">Example: Causal Effect VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_gamma.html">Example: Sparse Gamma Deep Exponential Family</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Discrete Latent Variables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="toy_mixture_model_discrete_enumeration.html">Example: Toy Mixture Model With Discrete Enumeration</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm.html">Example: Hidden Markov Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="capture_recapture.html">Example: Capture-Recapture Models (CJS Models)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mixed_hmm.html">Example: hierarchical mixed-effect hidden Markov models</a></li>
<li class="toctree-l1"><a class="reference internal" href="einsum.html">Example: Discrete Factor Graph Inference with Plated Einsum</a></li>
<li class="toctree-l1"><a class="reference internal" href="lda.html">Example: Amortized Latent Dirichlet Allocation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Customizing Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="neutra.html">Example: Neural MCMC with NeuTraReparam</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_regression.html">Example: Sparse Bayesian Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="autoname_examples.html">Example: reducing boilerplate with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.autoname</span></code></a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Time Series</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="forecast_simple.html">Multivariate Forecasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="timeseries.html">Example: Gaussian Process Time Series Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Gaussian Processes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dkl.html">Example: Deep Kernel Learning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Epidemiology</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="epi_sir.html">Example: Univariate epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="epi_regional.html">Example: Regional epidemiological models</a></li>
<li class="toctree-l1"><a class="reference internal" href="sir_hmc.html">Example: Epidemiological inference via HMC</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Application: Biological sequences</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="mue_profile.html">Example: Constant + MuE (Profile HMM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mue_factor.html">Example: Probabilistic PCA + MuE (FactorMuE)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Inference Algorithms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="baseball.html">Example: analyzing baseball stats with MCMC</a></li>
<li class="toctree-l1"><a class="reference internal" href="mcmc.html">Example: Inference with Markov Chain Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="lkj.html">Example: MCMC with an LKJ prior over covariances</a></li>
<li class="toctree-l1"><a class="reference internal" href="smcfilter.html">Example: Sequential Monte Carlo Filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="inclined_plane.html">Example: importance sampling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Understanding Pyro's Internals</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="minipyro.html">Mini-Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm_funsor.html">Example: hidden Markov models with <code class="docutils literal notranslate"><span class="pre">pyro.contrib.funsor</span></code> and <code class="docutils literal notranslate"><span class="pre">pyroapi</span></code></a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pyro Tutorials</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>&lt;no title&gt;</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/contrib_funsor_intro_i.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<dl>
<dt>{</dt><dd><dl>
<dt>“cells”: [</dt><dd><dl>
<dt>{</dt><dd><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“# <cite>pyro.contrib.funsor</cite>, a new backend for Pyro - New primitives (Part 1)”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Introductionn”,
“n”,
“In this tutorial we’ll cover the basics of <cite>pyro.contrib.funsor</cite>, a new backend for the Pyro probabilistic programming system that is intended to replace the current internals of Pyro and significantly expand its capabilities as both a modelling tool and an inference research platform.n”,
“n”,
“This tutorial is aimed at readers interested in developing custom inference algorithms and understanding Pyro’s current and future internals. As such, the material here assumes some familiarity with the [generic Pyro API package](<a class="reference external" href="https://pyro.ai/api/">https://pyro.ai/api/</a>) <cite>pyroapi</cite> and with Funsor. Additional documentation for Funsor can be found on [the Pyro website](<a class="reference external" href="https://funsor.pyro.ai/en/stable/">https://funsor.pyro.ai/en/stable/</a>), on [GitHub](<a class="reference external" href="https://github.com/pyro-ppl/funsor">https://github.com/pyro-ppl/funsor</a>), and in the research paper [&quot;Functional Tensors for Probabilistic Programming.&quot;](<a class="reference external" href="https://arxiv.org/abs/1910.10775">https://arxiv.org/abs/1910.10775</a>) Those who are less interested in such details should find that they can already use the general-purpose algorithms in <cite>contrib.funsor</cite> with their existing Pyro models via <cite>pyroapi</cite>.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Reinterpreting existing Pyro models with <cite>pyroapi</cite>n”,
“n”,
“The new backend uses the <cite>pyroapi</cite> package to integrate with existing Pyro code.n”,
“n”,
“First, we import some dependencies:”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 1,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“from collections import OrderedDictn”,
“n”,
“import torchn”,
“import funsorn”,
“from pyro import set_rng_seed as pyro_set_rng_seedn”,
“n”,
“funsor.set_backend(&quot;torch&quot;)n”,
“torch.set_default_dtype(torch.float32)n”,
“pyro_set_rng_seed(101)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Importing <cite>pyro.contrib.funsor</cite> registers the <cite>&quot;contrib.funsor&quot;</cite> backend with <cite>pyroapi</cite>, which can now be passed as an argument to the <cite>pyroapi.pyro_backend</cite> context manager.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 2,
“metadata”: {},
“outputs”: [],
“source”: [</p>
<blockquote>
<div><p>“import pyro.contrib.funsorn”,
“import pyroapin”,
“from pyroapi import handlers, infer, ops, optim, pyron”,
“from pyroapi import distributions as distn”,
“n”,
“# this is already done in pyro.contrib.funsor, but we repeat it heren”,
“pyroapi.register_backend(&quot;contrib.funsor&quot;, dict(n”,
”    distributions=&quot;pyro.distributions&quot;,n”,
”    handlers=&quot;pyro.contrib.funsor.handlers&quot;,n”,
”    infer=&quot;pyro.contrib.funsor.infer&quot;,n”,
”    ops=&quot;torch&quot;,n”,
”    optim=&quot;pyro.optim&quot;,n”,
”    pyro=&quot;pyro.contrib.funsor&quot;,n”,
“))”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“And we’re off! From here on, any <cite>pyro.(…)</cite> statement should be understood as dispatching to the new backend.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Two new primitives: <cite>to_funsor</cite> and <cite>to_data</cite>n”,
“n”,
“The first and most important new concept in <cite>pyro.contrib.funsor</cite> is the new pair of primitives <cite>pyro.to_funsor</cite> and <cite>pyro.to_data</cite>.n”,
“n”,
“These are <em>effectful</em> versions of <cite>funsor.to_funsor</cite> and <cite>funsor.to_data</cite>, i.e. versions whose behavior can be intercepted, controlled, or used to trigger side effects by Pyro’s library of algebraic effect handlers. Let’s briefly review these two underlying functions before diving into the effectful versions in <cite>pyro.contrib.funsor</cite>.n”,
“n”,
“As one might expect from the name, <cite>to_funsor</cite> takes as inputs objects that are not <cite>funsor.Funsor`s and attempts to convert them into Funsor terms. For example, calling `funsor.to_funsor</cite> on a Python number converts it to a <cite>funsor.terms.Number</cite> object:”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 3,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“1.0 &lt;class ‘funsor.terms.Number’&gt;n”,
“tensor(2.) &lt;class ‘funsor.tensor.Tensor’&gt;n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“funsor_one = funsor.to_funsor(float(1))n”,
“print(funsor_one, type(funsor_one))n”,
“n”,
“funsor_two = funsor.to_funsor(torch.tensor(2.))n”,
“print(funsor_two, type(funsor_two))”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Similarly ,calling <cite>funsor.to_data</cite> on an atomic <cite>funsor.Funsor</cite> converts it to a regular Python object like a <cite>float</cite> or a <cite>torch.Tensor</cite>:”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 4,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“1.0 &lt;class ‘float’&gt;n”,
“tensor(2.) &lt;class ‘torch.Tensor’&gt;n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“data_one = funsor.to_data(funsor.terms.Number(float(1), ‘real’))n”,
“print(data_one, type(data_one))n”,
“n”,
“data_two = funsor.to_data(funsor.Tensor(torch.tensor(2.), OrderedDict(), ‘real’))n”,
“print(data_two, type(data_two))”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“In many cases it is necessary to provide an output type to uniquely convert a piece of data to a <cite>funsor.Funsor</cite>. This also means that, strictly speaking, <cite>funsor.to_funsor</cite> and <cite>funsor.to_data</cite> are not inverses. For example, <cite>funsor.to_funsor</cite> will automatically convert Python strings to <cite>funsor.Variable`s, but only when given an output `funsor.domains.Domain</cite>, which serves as the type of the variable:”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 5,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“x OrderedDict([(‘x’, Reals[2])]) Reals[2]n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“var_x = funsor.to_funsor(&quot;x&quot;, output=funsor.Reals[2])n”,
“print(var_x, var_x.inputs, var_x.output)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“However, it is often impossible to convert objects to and from Funsor expressions uniquely without additional type information about inputs, as in the following example of a <cite>torch.Tensor</cite>, which could be converted to a <cite>funsor.Tensor</cite> in several ways.n”,
“n”,
“To resolve this ambiguity, we need to provide <cite>to_funsor</cite> and <cite>to_data</cite> with type information that describes how to convert positional dimensions to and from unordered named Funsor dimensions. This information comes in the form of dictionaries mapping batch dimensions to dimension names or vice versa.n”,
“n”,
“A key property of these mappings is that use the convention that dimension indices refer to <em>batch dimensions</em>, or dimensions not included in the <em>output shape</em>, which is treated as referring to the rightmost portion of the underlying PyTorch tensor shape, as illustrated in the example below.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 6,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“Ambiguous tensor: shape = torch.Size([3, 1, 2])n”,
“Case 1: inputs = OrderedDict(), output = Reals[3,1,2]n”,
“Case 2: inputs = OrderedDict([(‘a’, Bint[3, ])]), output = Reals[1,2]n”,
“Case 3: inputs = OrderedDict([(‘a’, Bint[3, ])]), output = Reals[2]n”,
“Case 4: inputs = OrderedDict([(‘a’, Bint[3, ]), (‘c’, Bint[2, ])]), output = Realn”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“ambiguous_tensor = torch.zeros((3, 1, 2))n”,
“print(&quot;Ambiguous tensor: shape = {}&quot;.format(ambiguous_tensor.shape))n”,
“n”,
“# case 1: treat all dimensions as output/event dimensionsn”,
“funsor1 = funsor.to_funsor(ambiguous_tensor, output=funsor.Reals[3, 1, 2])n”,
“print(&quot;Case 1: inputs = {}, output = {}&quot;.format(funsor1.inputs, funsor1.output))n”,
“n”,
“# case 2: treat the leftmost dimension as a batch dimensionn”,
“# note that dimension -1 in dim_to_name here refers to the rightmost <em>batch dimension</em>,n”,
“# i.e. dimension -3 of ambiguous_tensor, the rightmost dimension not included in the output shape.n”,
“funsor2 = funsor.to_funsor(ambiguous_tensor, output=funsor.Reals[1, 2], dim_to_name={-1: &quot;a&quot;})n”,
“print(&quot;Case 2: inputs = {}, output = {}&quot;.format(funsor2.inputs, funsor2.output))n”,
“n”,
“# case 3: treat the leftmost 2 dimensions as batch dimensions; empty batch dimensions are ignoredn”,
“# note that dimensions -1 and -2 in dim_to_name here refer to the rightmost <em>batch dimensions</em>,n”,
“# i.e. dimensions -2 and -3 of ambiguous_tensor, the rightmost dimensions not included in the output shape.n”,
“funsor3 = funsor.to_funsor(ambiguous_tensor, output=funsor.Reals[2], dim_to_name={-1: &quot;b&quot;, -2: &quot;a&quot;})n”,
“print(&quot;Case 3: inputs = {}, output = {}&quot;.format(funsor3.inputs, funsor3.output))n”,
“n”,
“# case 4: treat all dimensions as batch dimensions; empty batch dimensions are ignoredn”,
“# note that dimensions -1, -2 and -3 in dim_to_name here refer to the rightmost <em>batch dimensions</em>,n”,
“# i.e. dimensions -1, -2 and -3 of ambiguous_tensor, the rightmost dimensions not included in the output shape.n”,
“funsor4 = funsor.to_funsor(ambiguous_tensor, output=funsor.Real, dim_to_name={-1: &quot;c&quot;, -2: &quot;b&quot;, -3: &quot;a&quot;})n”,
“print(&quot;Case 4: inputs = {}, output = {}&quot;.format(funsor4.inputs, funsor4.output))”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Similar ambiguity exists for <cite>to_data</cite>: the <cite>inputs</cite> of a <cite>funsor.Funsor</cite> are ordered arbitrarily, and empty dimensions in the data are squeezed away, so a mapping from names to batch dimensions must be provided to ensure unique conversion:”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 7,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“Ambiguous funsor: inputs = OrderedDict([(‘a’, Bint[3, ]), (‘b’, Bint[2, ])]), shape = Realn”,
“Case 1: shape = torch.Size([3, 2])n”,
“Case 2: shape = torch.Size([3, 1, 2])n”,
“Case 3: shape = torch.Size([2, 3])n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“ambiguous_funsor = funsor.Tensor(torch.zeros((3, 2)), OrderedDict(a=funsor.Bint[3], b=funsor.Bint[2]), ‘real’)n”,
“print(&quot;Ambiguous funsor: inputs = {}, shape = {}&quot;.format(ambiguous_funsor.inputs, ambiguous_funsor.output))n”,
“n”,
“# case 1: the simplest versionn”,
“tensor1 = funsor.to_data(ambiguous_funsor, name_to_dim={&quot;a&quot;: -2, &quot;b&quot;: -1})n”,
“print(&quot;Case 1: shape = {}&quot;.format(tensor1.shape))n”,
“n”,
“# case 2: an empty dimension between a and bn”,
“tensor2 = funsor.to_data(ambiguous_funsor, name_to_dim={&quot;a&quot;: -3, &quot;b&quot;: -1})n”,
“print(&quot;Case 2: shape = {}&quot;.format(tensor2.shape))n”,
“n”,
“# case 3: permuting the input dimensionsn”,
“tensor3 = funsor.to_data(ambiguous_funsor, name_to_dim={&quot;a&quot;: -1, &quot;b&quot;: -2})n”,
“print(&quot;Case 3: shape = {}&quot;.format(tensor3.shape))”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Maintaining and updating this information efficiently becomes tedious and error-prone as the number of conversions increases. Fortunately, it can be automated away completely. Consider the following example:”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 8,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“OrderedDict([(‘x’, -1)]) OrderedDict([(‘x’, Bint[2, ])]) torch.Size([2])n”,
“OrderedDict([(‘x’, -1), (‘y’, -2)]) OrderedDict([(‘y’, Bint[3, ]), (‘x’, Bint[2, ])]) torch.Size([3, 2])n”,
“OrderedDict([(‘x’, -1), (‘y’, -2), (‘z’, -3)]) OrderedDict([(‘z’, Bint[2, ]), (‘y’, Bint[3, ])]) torch.Size([2, 3, 1])n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“name_to_dim = OrderedDict()n”,
“n”,
“funsor_x = funsor.Tensor(torch.ones((2,)), OrderedDict(x=funsor.Bint[2]), ‘real’)n”,
“name_to_dim.update({&quot;x&quot;: -1})n”,
“tensor_x = funsor.to_data(funsor_x, name_to_dim=name_to_dim)n”,
“print(name_to_dim, funsor_x.inputs, tensor_x.shape)n”,
“n”,
“funsor_y = funsor.Tensor(torch.ones((3, 2)), OrderedDict(y=funsor.Bint[3], x=funsor.Bint[2]), ‘real’)n”,
“name_to_dim.update({&quot;y&quot;: -2})n”,
“tensor_y = funsor.to_data(funsor_y, name_to_dim=name_to_dim)n”,
“print(name_to_dim, funsor_y.inputs, tensor_y.shape)n”,
“n”,
“funsor_z = funsor.Tensor(torch.ones((2, 3)), OrderedDict(z=funsor.Bint[2], y=funsor.Bint[3]), ‘real’)n”,
“name_to_dim.update({&quot;z&quot;: -3})n”,
“tensor_z = funsor.to_data(funsor_z, name_to_dim=name_to_dim)n”,
“print(name_to_dim, funsor_z.inputs, tensor_z.shape)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“This is exactly the functionality provided by <cite>pyro.to_funsor</cite> and <cite>pyro.to_data</cite>, as we can see by using them in the previous example and removing the manual updates. We must also wrap the function in a <cite>handlers.named</cite> effect handler to ensure that the dimension dictionaries do not persist beyond the function body.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 9,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“OrderedDict([(‘x’, Bint[2, ])]) torch.Size([2, 1, 1, 1, 1])n”,
“OrderedDict([(‘y’, Bint[3, ]), (‘x’, Bint[2, ])]) torch.Size([3, 2, 1, 1, 1, 1])n”,
“OrderedDict([(‘z’, Bint[2, ]), (‘y’, Bint[3, ])]) torch.Size([2, 3, 1, 1, 1, 1, 1])n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“with pyroapi.pyro_backend(&quot;contrib.funsor&quot;), handlers.named():n”,
”    funsor_x = funsor.Tensor(torch.ones((2,)), OrderedDict(x=funsor.Bint[2]), ‘real’)n”,
”    tensor_x = pyro.to_data(funsor_x)n”,
”    print(funsor_x.inputs, tensor_x.shape)n”,
“n”,
”    funsor_y = funsor.Tensor(torch.ones((3, 2)), OrderedDict(y=funsor.Bint[3], x=funsor.Bint[2]), ‘real’)n”,
”    tensor_y = pyro.to_data(funsor_y)n”,
”    print(funsor_y.inputs, tensor_y.shape)n”,
“n”,
”    funsor_z = funsor.Tensor(torch.ones((2, 3)), OrderedDict(z=funsor.Bint[2], y=funsor.Bint[3]), ‘real’)n”,
”    tensor_z = pyro.to_data(funsor_z)n”,
”    print(funsor_z.inputs, tensor_z.shape)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Critically, <cite>pyro.to_funsor</cite> and <cite>pyro.to_data</cite> use and update the same bidirectional mapping between names and dimensions, allowing them to be combined intuitively. A typical usage pattern, and one that <cite>pyro.contrib.funsor</cite> uses heavily in its inference algorithm implementations, is to create a <cite>funsor.Funsor</cite> term directly with a new named dimension and call <cite>pyro.to_data</cite> on it, perform some PyTorch computations, and call <cite>pyro.to_funsor</cite> on the result:”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 10,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“&lt;class ‘funsor.tensor.Tensor’&gt; OrderedDict([(‘batch’, Bint[3, ])]) Realn”,
“&lt;class ‘funsor.tensor.Tensor’&gt; OrderedDict([(‘x’, Bint[4, ])]) Realn”,
“&lt;class ‘pyro.distributions.torch.Bernoulli’&gt; torch.Size([3, 1, 1, 1, 1])n”,
“&lt;class ‘funsor.tensor.Tensor’&gt; OrderedDict([(‘x’, Bint[4, ]), (‘batch’, Bint[3, ])]) Realn”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“with pyroapi.pyro_backend(&quot;contrib.funsor&quot;), handlers.named():n”,
”    n”,
”    probs = funsor.Tensor(torch.tensor([0.5, 0.4, 0.7]), OrderedDict(batch=funsor.Bint[3]))n”,
”    print(type(probs), probs.inputs, probs.output)n”,
”    n”,
”    x = funsor.Tensor(torch.tensor([0., 1., 0., 1.]), OrderedDict(x=funsor.Bint[4]))n”,
”    print(type(x), x.inputs, x.output)n”,
”    n”,
”    dx = dist.Bernoulli(pyro.to_data(probs))n”,
”    print(type(dx), dx.shape())n”,
”    n”,
”    px = pyro.to_funsor(dx.log_prob(pyro.to_data(x)), output=funsor.Real)n”,
”    print(type(px), px.inputs, px.output)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“<cite>pyro.to_funsor</cite> and <cite>pyro.to_data</cite> treat the keys in their name-to-dim mappings as references to the input’s batch shape, but treats the values as references to the globally consistent name-dim mapping. This may be useful for complicated computations that involve a mixture of PyTorch and Funsor operations.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 11,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“x:  &lt;class ‘funsor.tensor.Tensor’&gt; OrderedDict([(‘x’, Bint[2, ])]) Realn”,
“px:  &lt;class ‘funsor.tensor.Tensor’&gt; OrderedDict([(‘x’, Bint[2, ]), (‘y’, Bint[3, ])]) Realn”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“with pyroapi.pyro_backend(&quot;contrib.funsor&quot;), handlers.named():n”,
”    n”,
”    x = pyro.to_funsor(torch.tensor([0., 1.]), funsor.Real, dim_to_name={-1: &quot;x&quot;})n”,
”    print(&quot;x: &quot;, type(x), x.inputs, x.output)n”,
”    n”,
”    px = pyro.to_funsor(torch.ones(2, 3), funsor.Real, dim_to_name={-2: &quot;x&quot;, -1: &quot;y&quot;})n”,
”    print(&quot;px: &quot;, type(px), px.inputs, px.output)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Dealing with large numbers of variables: (re-)introducing <cite>pyro.markov</cite>n”,
“n”,
“So far, so good. However, what if the number of different named dimensions continues to increase? We face two problems: first, reusing the fixed number of available positional dimensions (25 in PyTorch), and second, computing shape information with time complexity that is independent of the number of variables.n”,
“n”,
“A fully general automated solution to this problem would require deeper integration with Python or PyTorch. Instead, as an intermediate solution, we introduce the second key concept in <cite>pyro.contrib.funsor</cite>: the <cite>pyro.markov</cite> annotation, a way to indicate the shelf life of certain variables. <cite>pyro.markov</cite> is already part of Pyro (see enumeration tutorial) but the implementation in <cite>pyro.contrib.funsor</cite> is fresh.n”,
“n”,
“The primary constraint on the design of <cite>pyro.markov</cite> is backwards compatibility: in order for <cite>pyro.contrib.funsor</cite> to be compatible with the large range of existing Pyro models, the new implementation had to match the shape semantics of Pyro’s existing enumeration machinery as closely as possible.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 12,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“Shape of x[0]:  torch.Size([2, 1, 1, 1, 1])n”,
“Shape of x[1]:  torch.Size([2, 1, 1, 1, 1, 1])n”,
“Shape of x[2]:  torch.Size([2, 1, 1, 1, 1])n”,
“Shape of x[3]:  torch.Size([2, 1, 1, 1, 1, 1])n”,
“Shape of x[4]:  torch.Size([2, 1, 1, 1, 1])n”,
“Shape of x[5]:  torch.Size([2, 1, 1, 1, 1, 1])n”,
“Shape of x[6]:  torch.Size([2, 1, 1, 1, 1])n”,
“Shape of x[7]:  torch.Size([2, 1, 1, 1, 1, 1])n”,
“Shape of x[8]:  torch.Size([2, 1, 1, 1, 1])n”,
“Shape of x[9]:  torch.Size([2, 1, 1, 1, 1, 1])n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“with pyroapi.pyro_backend(&quot;contrib.funsor&quot;), handlers.named():n”,
”    for i in pyro.markov(range(10)):n”,
”        x = pyro.to_data(funsor.Tensor(torch.tensor([0., 1.]), OrderedDict({&quot;x{}&quot;.format(i): funsor.Bint[2]})))n”,
”        print(&quot;Shape of x[{}]: &quot;.format(str(i)), x.shape)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“<cite>pyro.markov</cite> is a versatile piece of syntax that can be used as a context manager, a decorator, or an iterator. It is important to understand that <cite>pyro.markov</cite>’s only functionality at present is tracking variable usage, not directly indicating conditional independence properties to inference algorithms, and as such it is only necessary to add enough annotations to ensure that tensors have correct shapes, rather than attempting to manually encode as much dependency information as possible.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“<cite>pyro.markov</cite> takes an additional argument <cite>history</cite> that determines the number of previous <cite>pyro.markov</cite> contexts to take into account when building the mapping between names and dimensions at a given <cite>pyro.to_funsor</cite>/<cite>pyro.to_data</cite> call.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 13,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“Shape of x[0]:  torch.Size([2, 1, 1, 1, 1])n”,
“Shape of x[1]:  torch.Size([2, 1, 1, 1, 1, 1])n”,
“Shape of x[2]:  torch.Size([2, 1, 1, 1, 1, 1, 1])n”,
“Shape of x[3]:  torch.Size([2, 1, 1, 1, 1])n”,
“Shape of x[4]:  torch.Size([2, 1, 1, 1, 1, 1])n”,
“Shape of x[5]:  torch.Size([2, 1, 1, 1, 1, 1, 1])n”,
“Shape of x[6]:  torch.Size([2, 1, 1, 1, 1])n”,
“Shape of x[7]:  torch.Size([2, 1, 1, 1, 1, 1])n”,
“Shape of x[8]:  torch.Size([2, 1, 1, 1, 1, 1, 1])n”,
“Shape of x[9]:  torch.Size([2, 1, 1, 1, 1])n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“with pyroapi.pyro_backend(&quot;contrib.funsor&quot;), handlers.named():n”,
”    for i in pyro.markov(range(10), history=2):n”,
”        x = pyro.to_data(funsor.Tensor(torch.tensor([0., 1.]), OrderedDict({&quot;x{}&quot;.format(i): funsor.Bint[2]})))n”,
”        print(&quot;Shape of x[{}]: &quot;.format(str(i)), x.shape)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“## Use cases beyond enumeration: global and visible dimensionsn”,
“n”,
“### Global dimensionsn”,
“n”,
“It is sometimes useful to have dimensions and variables ignore the <cite>pyro.markov</cite> structure of a program and remain active in arbitrarily deeply nested <cite>markov</cite> and <cite>named</cite> contexts. For example, suppose we wanted to draw a batch of samples from a Pyro model’s joint distribution. To accomplish this we indicate to <cite>pyro.to_data</cite> that a dimension should be treated as &quot;global&quot; (<cite>DimType.GLOBAL</cite>) via the <cite>dim_type</cite> keyword argument.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 14,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“New global dimension:  OrderedDict([(‘n’, Bint[10, ])]) torch.Size([10, 1, 1, 1, 1])n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“from pyro.contrib.funsor.handlers.runtime import _DIM_STACK, DimTypen”,
“n”,
“with pyroapi.pyro_backend(&quot;contrib.funsor&quot;), handlers.named():n”,
”    funsor_particle_ids = funsor.Tensor(torch.arange(10), OrderedDict(n=funsor.Bint[10]))n”,
”    tensor_particle_ids = pyro.to_data(funsor_particle_ids, dim_type=DimType.GLOBAL)n”,
”    print(&quot;New global dimension: &quot;, funsor_particle_ids.inputs, tensor_particle_ids.shape)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“<cite>pyro.markov</cite> does the hard work of automatically managing local dimensions, but because global dimensions ignore this structure, they must be deallocated manually or they will persist until the last active effect handler exits, just as global variables in Python persist until a program execution finishes.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 15,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“New global dimension:  OrderedDict([(‘plate1’, Bint[10, ])]) torch.Size([10, 1, 1, 1, 1])n”,
“Another new global dimension:  OrderedDict([(‘plate2’, Bint[9, ])]) torch.Size([9, 1, 1, 1, 1, 1])n”,
“A third new global dimension after recycling:  OrderedDict([(‘plate3’, Bint[10, ])]) torch.Size([10, 1, 1, 1, 1])n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“from pyro.contrib.funsor.handlers.runtime import _DIM_STACK, DimTypen”,
“n”,
“with pyroapi.pyro_backend(&quot;contrib.funsor&quot;), handlers.named():n”,
”    n”,
”    funsor_plate1_ids = funsor.Tensor(torch.arange(10), OrderedDict(plate1=funsor.Bint[10]))n”,
”    tensor_plate1_ids = pyro.to_data(funsor_plate1_ids, dim_type=DimType.GLOBAL)n”,
”    print(&quot;New global dimension: &quot;, funsor_plate1_ids.inputs, tensor_plate1_ids.shape)n”,
”    n”,
”    funsor_plate2_ids = funsor.Tensor(torch.arange(9), OrderedDict(plate2=funsor.Bint[9]))n”,
”    tensor_plate2_ids = pyro.to_data(funsor_plate2_ids, dim_type=DimType.GLOBAL)n”,
”    print(&quot;Another new global dimension: &quot;, funsor_plate2_ids.inputs, tensor_plate2_ids.shape)n”,
”    n”,
”    del _DIM_STACK.global_frame[&quot;plate1&quot;]n”,
”    n”,
”    funsor_plate3_ids = funsor.Tensor(torch.arange(10), OrderedDict(plate3=funsor.Bint[10]))n”,
”    tensor_plate3_ids = pyro.to_data(funsor_plate1_ids, dim_type=DimType.GLOBAL)n”,
”    print(&quot;A third new global dimension after recycling: &quot;, funsor_plate3_ids.inputs, tensor_plate3_ids.shape)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Performing this deallocation directly is often unnecessary, and we include this interaction primarily to illuminate the internals of <cite>pyro.contrib.funsor</cite>. Instead, effect handlers that introduce global dimensions, like <cite>pyro.plate</cite>, may inherit from the <cite>GlobalNamedMessenger</cite> effect handler which deallocates global dimensions generically upon entry and exit. We will see an example of this in the next tutorial.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“### Visible dimensionsn”,
“n”,
“We might also wish to preserve the meaning of the shape of a tensor of data. For this we indicate to <cite>pyro.to_data</cite> that a dimension should be treated as not merely global but &quot;visible&quot; (<cite>DimTypes.VISIBLE</cite>). By default, the 4 rightmost batch dimensions are reserved as &quot;visible&quot; dimensions, but this can be changed by setting the <cite>first_available_dim</cite> attribute of the global state object <cite>_DIM_STACK</cite>.n”,
“n”,
“Users who have come across <cite>pyro.infer.TraceEnum_ELBO</cite>’s <cite>max_plate_nesting</cite> argument are already familiar with this distinction.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “code”,
“execution_count”: 16,
“metadata”: {},
“outputs”: [</p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>“name”: “stdout”,
“output_type”: “stream”,
“text”: [</p>
<blockquote>
<div><p>“Tensor with new local dimension:  OrderedDict([(‘k’, Bint[9, ])]) torch.Size([9, 1])n”,
“Tensor with new global dimension:  OrderedDict([(‘n’, Bint[10, ])]) torch.Size([10, 1, 1])n”,
“Tensor with new visible dimension:  OrderedDict([(‘m’, Bint[11, ])]) torch.Size([11])n”</p>
</div></blockquote>
<p>]</p>
</dd>
</dl>
<p>},
{</p>
<blockquote>
<div><dl>
<dt>“data”: {</dt><dd><dl class="simple">
<dt>“text/plain”: [</dt><dd><p>“-5”</p>
</dd>
</dl>
<p>]</p>
</dd>
</dl>
<p>},
“execution_count”: 16,
“metadata”: {},
“output_type”: “execute_result”</p>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p>],
“source”: [</p>
<blockquote>
<div><p>“prev_first_available_dim = _DIM_STACK.set_first_available_dim(-2)n”,
“n”,
“with pyroapi.pyro_backend(&quot;contrib.funsor&quot;), handlers.named():n”,
”    n”,
”    funsor_local_ids = funsor.Tensor(torch.arange(9), OrderedDict(k=funsor.Bint[9]))n”,
”    tensor_local_ids = pyro.to_data(funsor_local_ids, dim_type=DimType.LOCAL)n”,
”    print(&quot;Tensor with new local dimension: &quot;, funsor_local_ids.inputs, tensor_local_ids.shape)n”,
”    n”,
”    funsor_global_ids = funsor.Tensor(torch.arange(10), OrderedDict(n=funsor.Bint[10]))n”,
”    tensor_global_ids = pyro.to_data(funsor_global_ids, dim_type=DimType.GLOBAL)n”,
”    print(&quot;Tensor with new global dimension: &quot;, funsor_global_ids.inputs, tensor_global_ids.shape)n”,
”    n”,
”    funsor_data_ids = funsor.Tensor(torch.arange(11), OrderedDict(m=funsor.Bint[11]))n”,
”    tensor_data_ids = pyro.to_data(funsor_data_ids, dim_type=DimType.VISIBLE)n”,
”    print(&quot;Tensor with new visible dimension: &quot;, funsor_data_ids.inputs, tensor_data_ids.shape)n”,
”    n”,
“# we also need to reset the first_available_dim after we’re donen”,
“_DIM_STACK.set_first_available_dim(prev_first_available_dim)”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>},
{</p>
<blockquote>
<div><p>“cell_type”: “markdown”,
“metadata”: {},
“source”: [</p>
<blockquote>
<div><p>“Visible dimensions are also global and must therefore be deallocated manually or they will persist until the last effect handler exits, as in the previous example. You may be thinking by now that Funsor’s dimension names behave sort of like Python variables, with scopes and persistent meanings across expressions; indeed, this observation is the key insight behind the design of Funsor.n”,
“n”,
“Fortunately, interacting directly with the dimension allocator is almost always unnecessary, and as in the previous section we include it here only to illuminate the inner workings of <cite>pyro.contrib.funsor</cite>; rather, effect handlers like <cite>pyro.handlers.enum</cite> that may introduce non-visible dimensions that could conflict with visible dimensions should inherit from the base <cite>pyro.contrib.funsor.handlers.named_messenger.NamedMessenger</cite> effect handler. n”,
“n”,
“However, building a bit of intuition for the inner workings of the dimension allocator will make it easier to use the new primitives in <cite>contrib.funsor</cite> to build powerful new custom inference engines. We will see an example of one such inference engine in the next tutorial.”</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>],
“metadata”: {</p>
<blockquote>
<div><dl class="simple">
<dt>“kernelspec”: {</dt><dd><p>“display_name”: “Python 3”,
“language”: “python”,
“name”: “python3”</p>
</dd>
</dl>
<p>},
“language_info”: {</p>
<blockquote>
<div><dl class="simple">
<dt>“codemirror_mode”: {</dt><dd><p>“name”: “ipython”,
“version”: 3</p>
</dd>
</dl>
<p>},
“file_extension”: “.py”,
“mimetype”: “text/x-python”,
“name”: “python”,
“nbconvert_exporter”: “python”,
“pygments_lexer”: “ipython3”,
“version”: “3.7.3”</p>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p>},
“nbformat”: 4,
“nbformat_minor”: 2</p>
</dd>
</dl>
<p>}</p>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="effect_handlers.html" class="btn btn-neutral float-left" title="&lt;no title&gt;" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="contrib_funsor_intro_ii.html" class="btn btn-neutral float-right" title="&lt;no title&gt;" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Pyro Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>