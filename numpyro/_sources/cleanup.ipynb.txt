{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from matplotlib import pyplot\n",
    "from treecat_exp.util import TEST, load_object\n",
    "from treecat_exp.preprocess import load_data\n",
    "%matplotlib inline\n",
    "%config InlineBackend.rc = {'figure.facecolor': (1, 1, 1, 1)}\n",
    "# %config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following results were generated by `cleanup.py` by running\n",
    "```sh\n",
    "python main.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "paths = glob.glob(os.path.join(TEST, \"cleanup.*.pkl\"))\n",
    "paths.sort()\n",
    "print(\"Loading {} experimental results:\".format(len(paths)))\n",
    "for path in paths:\n",
    "    metrics = load_object(path)\n",
    "    results.append(metrics)\n",
    "    args = metrics[\"args\"]\n",
    "    print(\"  {} {} {}\".format(args.delete_percent,\n",
    "                              args.dataset,\n",
    "                              args.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {m[\"args\"].dataset: m[\"args\"] for m in results}\n",
    "features = {}\n",
    "sizes = {}\n",
    "for name, args in datasets.items():\n",
    "    features[name], data, mask = load_data(args)\n",
    "    sizes[name] = (len(data), len(data[0]))\n",
    "    del data, mask\n",
    "print(\"Found results for {} datasets:\".format(len(datasets)))\n",
    "for name, size in sorted(sizes.items()):\n",
    "    print(\"  {}: {} x {}\".format(name, size[1], size[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dataset in sorted(datasets, key=lambda name: sizes[name][0] * sizes[name][1]):\n",
    "    pyplot.figure(figsize=(9, 6), dpi=300)\n",
    "    for model in sorted(set(m[\"args\"].model for m in results\n",
    "                            if m[\"args\"].dataset == dataset)):\n",
    "        ms = [m for m in results if m[\"args\"].dataset == dataset if m[\"args\"].model == model]\n",
    "        ms.sort(key=lambda m: m[\"args\"].delete_percent)\n",
    "        # pyplot.violinplot([m[\"losses\"] for m in ms])\n",
    "        X = [m[\"args\"].delete_percent / 100 for m in ms]\n",
    "        Y = [np.mean(m[\"losses\"]) for m in ms]\n",
    "        p, = pyplot.plot(X, Y, label=model)\n",
    "        for f in range(len(ms[0][\"losses\"])):\n",
    "            Y = [m[\"losses\"][f] for m in ms]\n",
    "            typ = type(features[dataset][f]).__name__\n",
    "            linestyle = {\"Real\": '-', \"Boolean\": \"-.\", \"Discrete\": \"--\"}[typ]\n",
    "            pyplot.plot(X, Y, color=p.get_color(), lw=1, alpha=0.3,\n",
    "                        linestyle=linestyle)\n",
    "    X = list(sorted(set(m[\"args\"].delete_percent / 100\n",
    "                        for m in results if m[\"args\"].dataset == dataset)))\n",
    "    pyplot.yscale(\"log\")\n",
    "    pyplot.xticks(X, labels=[\"{:0.2g}\".format(x) for x in X])\n",
    "    pyplot.title(\"Accuracy of imputing {} x {} {} data (lower is better)\".format(\n",
    "        sizes[dataset][1], sizes[dataset][0], dataset))\n",
    "    pyplot.xlabel(\"Missing Probability\")\n",
    "    pyplot.ylabel(\"Error (loss / cell)\")\n",
    "    pyplot.legend(loc=\"best\")\n",
    "    pyplot.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dataset in sorted(set(m[\"args\"].dataset for m in results)):\n",
    "    for model in sorted(set(m[\"args\"].model for m in results\n",
    "                            if m[\"args\"].dataset == dataset\n",
    "                            if \"posterior_predictive\" in m)):\n",
    "        ms = [m for m in results if m[\"args\"].dataset == dataset if m[\"args\"].model == model]\n",
    "        ms.sort(key=lambda m: m[\"args\"].delete_percent)\n",
    "        X = [m[\"args\"].delete_percent / 100 for m in ms]\n",
    "        Y = np.array([m[\"posterior_predictive\"].mean().item()\n",
    "                      / sum(m[\"num_cleaned\"]) * m[\"num_rows\"]\n",
    "                      for m in ms])\n",
    "        dY = np.array([m[\"posterior_predictive\"].std().item()\n",
    "                       / sum(m[\"num_cleaned\"]) * m[\"num_rows\"]\n",
    "                       for m in ms])\n",
    "        \n",
    "        pyplot.figure(figsize=(9, 6), dpi=300)\n",
    "        pyplot.fill_between(X, Y - dY, Y + dY, alpha=0.3)\n",
    "        pyplot.plot(X, Y, 'k--')\n",
    "        pyplot.xticks(X, labels=[\"{:0.2g}\".format(x) for x in X])\n",
    "        pyplot.title(\"Accuracy of {} imputing {} data (higher is better)\"\n",
    "                     .format(model, dataset))\n",
    "        pyplot.xlabel(\"Missing Probability\")\n",
    "        pyplot.ylabel(\"Posterior Predictive  (nats / imputed cell)\")\n",
    "        pyplot.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
